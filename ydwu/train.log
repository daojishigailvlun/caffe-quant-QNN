I1221 09:41:31.318840 23235 caffe.cpp:211] Use CPU.
I1221 09:41:32.715908 23235 solver.cpp:44] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.003
display: 20
max_iter: 450000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "qnn_try1/QNN-train"
solver_mode: CPU
net: "qnn_try1/train_quantized_caffenet.prototxt"
train_state {
  level: 0
  stage: ""
}
I1221 09:41:32.716084 23235 solver.cpp:87] Creating training net from net file: qnn_try1/train_quantized_caffenet.prototxt
I1221 09:41:32.717036 23235 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1221 09:41:32.717398 23235 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/ydwu/database/imagenet/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/ydwu/database/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_train_lmdb/"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "quantized_data"
  type: "Quantization"
  bottom: "data"
  top: "quantized_data"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -129.93526
    range: 160.78912
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "quantized_data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv1"
  type: "Quantization"
  bottom: "conv1"
  top: "quantized_conv1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -2732.7351
    range: 2531.042
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "quantized_conv1"
  top: "relu1"
}
layer {
  name: "quantized_relu1"
  type: "Quantization"
  bottom: "relu1"
  top: "quantized_relu1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 2531.042
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "quantized_relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool1"
  type: "Quantization"
  bottom: "pool1"
  top: "quantized_pool1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 2531.042
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "quantized_pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "quantized_norm1"
  type: "Quantization"
  bottom: "norm1"
  top: "quantized_norm1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 138.70576
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "quantized_norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv2"
  type: "Quantization"
  bottom: "conv2"
  top: "quantized_conv2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -647.61908
    range: 492.23111
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "quantized_conv2"
  top: "relu2"
}
layer {
  name: "quantized_relu2"
  type: "Quantization"
  bottom: "relu2"
  top: "quantized_relu2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 492.23111
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "quantized_relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool2"
  type: "Quantization"
  bottom: "pool2"
  top: "quantized_pool2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 492.23111
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "quantized_pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "quantized_norm2"
  type: "Quantization"
  bottom: "norm2"
  top: "quantized_norm2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 138.72636
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "quantized_norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv3"
  type: "Quantization"
  bottom: "conv3"
  top: "quantized_conv3"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -389.56516
    range: 331.98178
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "quantized_conv3"
  top: "relu3"
}
layer {
  name: "quantized_relu3"
  type: "Quantization"
  bottom: "relu3"
  top: "quantized_relu3"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 331.98178
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "quantized_relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv4"
  type: "Quantization"
  bottom: "conv4"
  top: "quantized_conv4"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -231.20598
    range: 283.87189
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "quantized_conv4"
  top: "relu4"
}
layer {
  name: "quantized_relu4"
  type: "Quantization"
  bottom: "relu4"
  top: "quantized_relu4"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 283.87189
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "quantized_relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv5"
  type: "Quantization"
  bottom: "conv5"
  top: "quantized_conv5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -172.60567
    range: 272.57315
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "quantized_conv5"
  top: "relu5"
}
layer {
  name: "quantized_relu5"
  type: "Quantization"
  bottom: "relu5"
  top: "quantized_relu5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 272.57315
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "quantized_relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool5"
  type: "Quantization"
  bottom: "pool5"
  top: "quantized_pool5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 272.57315
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "quantized_pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1.05e+13
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "quantized_fc6"
  type: "Quantization"
  bottom: "fc6"
  top: "quantized_fc6"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -114.02487
    range: 58.541733
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "quantized_fc6"
  top: "relu6"
}
layer {
  name: "quantized_relu6"
  type: "Quantization"
  bottom: "relu6"
  top: "quantized_relu6"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 58.541733
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "quantized_relu6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1.05e+13
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "quantized_fc7"
  type: "Quantization"
  bottom: "fc7"
  top: "quantized_fc7"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -26.019335
    range: 19.125257
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "quantized_fc7"
  top: "relu7"
}
layer {
  name: "quantized_relu7"
  type: "Quantization"
  bottom: "relu7"
  top: "quantized_relu7"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 19.125257
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "quantized_relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "quantized_fc8"
  type: "Quantization"
  bottom: "fc8"
  top: "quantized_fc8"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -9.849781
    range: 45.688446
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "quantized_fc8"
  top: "probs"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc_top1"
  type: "Accuracy"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "acc_top1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc_top5"
  type: "Accuracy"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "acc_top5"
  accuracy_param {
    top_k: 5
  }
}
I1221 09:41:32.717631 23235 layer_factory.hpp:77] Creating layer data
I1221 09:41:32.717753 23235 db_lmdb.cpp:35] Opened lmdb /home/ydwu/database/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_train_lmdb/
I1221 09:41:32.717795 23235 net.cpp:84] Creating Layer data
I1221 09:41:32.717813 23235 net.cpp:380] data -> data
I1221 09:41:32.717846 23235 net.cpp:380] data -> label
I1221 09:41:32.717870 23235 data_transformer.cpp:25] Loading mean file from: /home/ydwu/database/imagenet/ilsvrc12/imagenet_mean.binaryproto
I1221 09:41:32.720374 23235 data_layer.cpp:45] output data size: 32,3,227,227
I1221 09:41:32.741004 23235 net.cpp:122] Setting up data
I1221 09:41:32.741111 23235 net.cpp:129] Top shape: 32 3 227 227 (4946784)
I1221 09:41:32.741130 23235 net.cpp:129] Top shape: 32 (32)
I1221 09:41:32.741144 23235 net.cpp:137] Memory required for data: 19787264
I1221 09:41:32.741165 23235 layer_factory.hpp:77] Creating layer label_data_1_split
I1221 09:41:32.741189 23235 net.cpp:84] Creating Layer label_data_1_split
I1221 09:41:32.741199 23235 net.cpp:406] label_data_1_split <- label
I1221 09:41:32.741220 23235 net.cpp:380] label_data_1_split -> label_data_1_split_0
I1221 09:41:32.741237 23235 net.cpp:380] label_data_1_split -> label_data_1_split_1
I1221 09:41:32.741261 23235 net.cpp:380] label_data_1_split -> label_data_1_split_2
I1221 09:41:32.741297 23235 net.cpp:122] Setting up label_data_1_split
I1221 09:41:32.741307 23235 net.cpp:129] Top shape: 32 (32)
I1221 09:41:32.741315 23235 net.cpp:129] Top shape: 32 (32)
I1221 09:41:32.741322 23235 net.cpp:129] Top shape: 32 (32)
I1221 09:41:32.741329 23235 net.cpp:137] Memory required for data: 19787648
I1221 09:41:32.741335 23235 layer_factory.hpp:77] Creating layer quantized_data
I1221 09:41:32.741351 23235 net.cpp:84] Creating Layer quantized_data
I1221 09:41:32.741358 23235 net.cpp:406] quantized_data <- data
I1221 09:41:32.741369 23235 net.cpp:380] quantized_data -> quantized_data
I1221 09:41:32.741384 23235 net.cpp:122] Setting up quantized_data
I1221 09:41:32.741394 23235 net.cpp:129] Top shape: 32 3 227 227 (4946784)
I1221 09:41:32.741400 23235 net.cpp:137] Memory required for data: 39574784
I1221 09:41:32.741406 23235 layer_factory.hpp:77] Creating layer conv1
I1221 09:41:32.741430 23235 net.cpp:84] Creating Layer conv1
I1221 09:41:32.741439 23235 net.cpp:406] conv1 <- quantized_data
I1221 09:41:32.741449 23235 net.cpp:380] conv1 -> conv1
I1221 09:41:32.742570 23235 net.cpp:122] Setting up conv1
I1221 09:41:32.742585 23235 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I1221 09:41:32.742593 23235 net.cpp:137] Memory required for data: 76745984
I1221 09:41:32.742614 23235 layer_factory.hpp:77] Creating layer quantized_conv1
I1221 09:41:32.742625 23235 net.cpp:84] Creating Layer quantized_conv1
I1221 09:41:32.742632 23235 net.cpp:406] quantized_conv1 <- conv1
I1221 09:41:32.742642 23235 net.cpp:380] quantized_conv1 -> quantized_conv1
I1221 09:41:32.742653 23235 net.cpp:122] Setting up quantized_conv1
I1221 09:41:32.742663 23235 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I1221 09:41:32.742669 23235 net.cpp:137] Memory required for data: 113917184
I1221 09:41:32.742676 23235 layer_factory.hpp:77] Creating layer relu1
I1221 09:41:32.742688 23235 net.cpp:84] Creating Layer relu1
I1221 09:41:32.742696 23235 net.cpp:406] relu1 <- quantized_conv1
I1221 09:41:32.742707 23235 net.cpp:380] relu1 -> relu1
I1221 09:41:32.742717 23235 net.cpp:122] Setting up relu1
I1221 09:41:32.742727 23235 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I1221 09:41:32.742733 23235 net.cpp:137] Memory required for data: 151088384
I1221 09:41:32.742739 23235 layer_factory.hpp:77] Creating layer quantized_relu1
I1221 09:41:32.742748 23235 net.cpp:84] Creating Layer quantized_relu1
I1221 09:41:32.742755 23235 net.cpp:406] quantized_relu1 <- relu1
I1221 09:41:32.742764 23235 net.cpp:380] quantized_relu1 -> quantized_relu1
I1221 09:41:32.742774 23235 net.cpp:122] Setting up quantized_relu1
I1221 09:41:32.742784 23235 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I1221 09:41:32.742789 23235 net.cpp:137] Memory required for data: 188259584
I1221 09:41:32.742796 23235 layer_factory.hpp:77] Creating layer pool1
I1221 09:41:32.742807 23235 net.cpp:84] Creating Layer pool1
I1221 09:41:32.742815 23235 net.cpp:406] pool1 <- quantized_relu1
I1221 09:41:32.742833 23235 net.cpp:380] pool1 -> pool1
I1221 09:41:32.742858 23235 net.cpp:122] Setting up pool1
I1221 09:41:32.742869 23235 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I1221 09:41:32.742875 23235 net.cpp:137] Memory required for data: 197217536
I1221 09:41:32.742882 23235 layer_factory.hpp:77] Creating layer quantized_pool1
I1221 09:41:32.742893 23235 net.cpp:84] Creating Layer quantized_pool1
I1221 09:41:32.742900 23235 net.cpp:406] quantized_pool1 <- pool1
I1221 09:41:32.742910 23235 net.cpp:380] quantized_pool1 -> quantized_pool1
I1221 09:41:32.742920 23235 net.cpp:122] Setting up quantized_pool1
I1221 09:41:32.742929 23235 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I1221 09:41:32.742935 23235 net.cpp:137] Memory required for data: 206175488
I1221 09:41:32.742943 23235 layer_factory.hpp:77] Creating layer norm1
I1221 09:41:32.742954 23235 net.cpp:84] Creating Layer norm1
I1221 09:41:32.742969 23235 net.cpp:406] norm1 <- quantized_pool1
I1221 09:41:32.742977 23235 net.cpp:380] norm1 -> norm1
I1221 09:41:32.743000 23235 net.cpp:122] Setting up norm1
I1221 09:41:32.743018 23235 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I1221 09:41:32.743026 23235 net.cpp:137] Memory required for data: 215133440
I1221 09:41:32.743032 23235 layer_factory.hpp:77] Creating layer quantized_norm1
I1221 09:41:32.743042 23235 net.cpp:84] Creating Layer quantized_norm1
I1221 09:41:32.743049 23235 net.cpp:406] quantized_norm1 <- norm1
I1221 09:41:32.743058 23235 net.cpp:380] quantized_norm1 -> quantized_norm1
I1221 09:41:32.743069 23235 net.cpp:122] Setting up quantized_norm1
I1221 09:41:32.743077 23235 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I1221 09:41:32.743084 23235 net.cpp:137] Memory required for data: 224091392
I1221 09:41:32.743090 23235 layer_factory.hpp:77] Creating layer conv2
I1221 09:41:32.743104 23235 net.cpp:84] Creating Layer conv2
I1221 09:41:32.743111 23235 net.cpp:406] conv2 <- quantized_norm1
I1221 09:41:32.743122 23235 net.cpp:380] conv2 -> conv2
I1221 09:41:32.752416 23235 net.cpp:122] Setting up conv2
I1221 09:41:32.752462 23235 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1221 09:41:32.752470 23235 net.cpp:137] Memory required for data: 247979264
I1221 09:41:32.752488 23235 layer_factory.hpp:77] Creating layer quantized_conv2
I1221 09:41:32.752507 23235 net.cpp:84] Creating Layer quantized_conv2
I1221 09:41:32.752517 23235 net.cpp:406] quantized_conv2 <- conv2
I1221 09:41:32.752529 23235 net.cpp:380] quantized_conv2 -> quantized_conv2
I1221 09:41:32.752545 23235 net.cpp:122] Setting up quantized_conv2
I1221 09:41:32.752554 23235 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1221 09:41:32.752562 23235 net.cpp:137] Memory required for data: 271867136
I1221 09:41:32.752568 23235 layer_factory.hpp:77] Creating layer relu2
I1221 09:41:32.752580 23235 net.cpp:84] Creating Layer relu2
I1221 09:41:32.752588 23235 net.cpp:406] relu2 <- quantized_conv2
I1221 09:41:32.752596 23235 net.cpp:380] relu2 -> relu2
I1221 09:41:32.752609 23235 net.cpp:122] Setting up relu2
I1221 09:41:32.752617 23235 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1221 09:41:32.752624 23235 net.cpp:137] Memory required for data: 295755008
I1221 09:41:32.752631 23235 layer_factory.hpp:77] Creating layer quantized_relu2
I1221 09:41:32.752640 23235 net.cpp:84] Creating Layer quantized_relu2
I1221 09:41:32.752647 23235 net.cpp:406] quantized_relu2 <- relu2
I1221 09:41:32.752661 23235 net.cpp:380] quantized_relu2 -> quantized_relu2
I1221 09:41:32.752672 23235 net.cpp:122] Setting up quantized_relu2
I1221 09:41:32.752681 23235 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1221 09:41:32.752687 23235 net.cpp:137] Memory required for data: 319642880
I1221 09:41:32.752694 23235 layer_factory.hpp:77] Creating layer pool2
I1221 09:41:32.752707 23235 net.cpp:84] Creating Layer pool2
I1221 09:41:32.752714 23235 net.cpp:406] pool2 <- quantized_relu2
I1221 09:41:32.752723 23235 net.cpp:380] pool2 -> pool2
I1221 09:41:32.752737 23235 net.cpp:122] Setting up pool2
I1221 09:41:32.752746 23235 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1221 09:41:32.752753 23235 net.cpp:137] Memory required for data: 325180672
I1221 09:41:32.752759 23235 layer_factory.hpp:77] Creating layer quantized_pool2
I1221 09:41:32.752774 23235 net.cpp:84] Creating Layer quantized_pool2
I1221 09:41:32.752780 23235 net.cpp:406] quantized_pool2 <- pool2
I1221 09:41:32.752789 23235 net.cpp:380] quantized_pool2 -> quantized_pool2
I1221 09:41:32.752799 23235 net.cpp:122] Setting up quantized_pool2
I1221 09:41:32.752809 23235 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1221 09:41:32.752815 23235 net.cpp:137] Memory required for data: 330718464
I1221 09:41:32.752822 23235 layer_factory.hpp:77] Creating layer norm2
I1221 09:41:32.752835 23235 net.cpp:84] Creating Layer norm2
I1221 09:41:32.752842 23235 net.cpp:406] norm2 <- quantized_pool2
I1221 09:41:32.752851 23235 net.cpp:380] norm2 -> norm2
I1221 09:41:32.752863 23235 net.cpp:122] Setting up norm2
I1221 09:41:32.752872 23235 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1221 09:41:32.752879 23235 net.cpp:137] Memory required for data: 336256256
I1221 09:41:32.752915 23235 layer_factory.hpp:77] Creating layer quantized_norm2
I1221 09:41:32.752928 23235 net.cpp:84] Creating Layer quantized_norm2
I1221 09:41:32.752938 23235 net.cpp:406] quantized_norm2 <- norm2
I1221 09:41:32.752945 23235 net.cpp:380] quantized_norm2 -> quantized_norm2
I1221 09:41:32.752956 23235 net.cpp:122] Setting up quantized_norm2
I1221 09:41:32.752965 23235 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1221 09:41:32.752971 23235 net.cpp:137] Memory required for data: 341794048
I1221 09:41:32.752979 23235 layer_factory.hpp:77] Creating layer conv3
I1221 09:41:32.752995 23235 net.cpp:84] Creating Layer conv3
I1221 09:41:32.753002 23235 net.cpp:406] conv3 <- quantized_norm2
I1221 09:41:32.753015 23235 net.cpp:380] conv3 -> conv3
I1221 09:41:32.779830 23235 net.cpp:122] Setting up conv3
I1221 09:41:32.779881 23235 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1221 09:41:32.779887 23235 net.cpp:137] Memory required for data: 350100736
I1221 09:41:32.779906 23235 layer_factory.hpp:77] Creating layer quantized_conv3
I1221 09:41:32.779924 23235 net.cpp:84] Creating Layer quantized_conv3
I1221 09:41:32.779933 23235 net.cpp:406] quantized_conv3 <- conv3
I1221 09:41:32.779945 23235 net.cpp:380] quantized_conv3 -> quantized_conv3
I1221 09:41:32.779963 23235 net.cpp:122] Setting up quantized_conv3
I1221 09:41:32.779971 23235 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1221 09:41:32.779978 23235 net.cpp:137] Memory required for data: 358407424
I1221 09:41:32.779984 23235 layer_factory.hpp:77] Creating layer relu3
I1221 09:41:32.779997 23235 net.cpp:84] Creating Layer relu3
I1221 09:41:32.780004 23235 net.cpp:406] relu3 <- quantized_conv3
I1221 09:41:32.780014 23235 net.cpp:380] relu3 -> relu3
I1221 09:41:32.780025 23235 net.cpp:122] Setting up relu3
I1221 09:41:32.780033 23235 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1221 09:41:32.780040 23235 net.cpp:137] Memory required for data: 366714112
I1221 09:41:32.780046 23235 layer_factory.hpp:77] Creating layer quantized_relu3
I1221 09:41:32.780057 23235 net.cpp:84] Creating Layer quantized_relu3
I1221 09:41:32.780064 23235 net.cpp:406] quantized_relu3 <- relu3
I1221 09:41:32.780073 23235 net.cpp:380] quantized_relu3 -> quantized_relu3
I1221 09:41:32.780083 23235 net.cpp:122] Setting up quantized_relu3
I1221 09:41:32.780092 23235 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1221 09:41:32.780099 23235 net.cpp:137] Memory required for data: 375020800
I1221 09:41:32.780107 23235 layer_factory.hpp:77] Creating layer conv4
I1221 09:41:32.780124 23235 net.cpp:84] Creating Layer conv4
I1221 09:41:32.780131 23235 net.cpp:406] conv4 <- quantized_relu3
I1221 09:41:32.780144 23235 net.cpp:380] conv4 -> conv4
I1221 09:41:32.800571 23235 net.cpp:122] Setting up conv4
I1221 09:41:32.800622 23235 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1221 09:41:32.800629 23235 net.cpp:137] Memory required for data: 383327488
I1221 09:41:32.800643 23235 layer_factory.hpp:77] Creating layer quantized_conv4
I1221 09:41:32.800662 23235 net.cpp:84] Creating Layer quantized_conv4
I1221 09:41:32.800671 23235 net.cpp:406] quantized_conv4 <- conv4
I1221 09:41:32.800685 23235 net.cpp:380] quantized_conv4 -> quantized_conv4
I1221 09:41:32.800703 23235 net.cpp:122] Setting up quantized_conv4
I1221 09:41:32.800710 23235 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1221 09:41:32.800717 23235 net.cpp:137] Memory required for data: 391634176
I1221 09:41:32.800724 23235 layer_factory.hpp:77] Creating layer relu4
I1221 09:41:32.800736 23235 net.cpp:84] Creating Layer relu4
I1221 09:41:32.800743 23235 net.cpp:406] relu4 <- quantized_conv4
I1221 09:41:32.800752 23235 net.cpp:380] relu4 -> relu4
I1221 09:41:32.800762 23235 net.cpp:122] Setting up relu4
I1221 09:41:32.800771 23235 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1221 09:41:32.800778 23235 net.cpp:137] Memory required for data: 399940864
I1221 09:41:32.800786 23235 layer_factory.hpp:77] Creating layer quantized_relu4
I1221 09:41:32.800793 23235 net.cpp:84] Creating Layer quantized_relu4
I1221 09:41:32.800814 23235 net.cpp:406] quantized_relu4 <- relu4
I1221 09:41:32.800842 23235 net.cpp:380] quantized_relu4 -> quantized_relu4
I1221 09:41:32.800854 23235 net.cpp:122] Setting up quantized_relu4
I1221 09:41:32.800863 23235 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1221 09:41:32.800869 23235 net.cpp:137] Memory required for data: 408247552
I1221 09:41:32.800876 23235 layer_factory.hpp:77] Creating layer conv5
I1221 09:41:32.800894 23235 net.cpp:84] Creating Layer conv5
I1221 09:41:32.800901 23235 net.cpp:406] conv5 <- quantized_relu4
I1221 09:41:32.800911 23235 net.cpp:380] conv5 -> conv5
I1221 09:41:32.814535 23235 net.cpp:122] Setting up conv5
I1221 09:41:32.814584 23235 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1221 09:41:32.814592 23235 net.cpp:137] Memory required for data: 413785344
I1221 09:41:32.814611 23235 layer_factory.hpp:77] Creating layer quantized_conv5
I1221 09:41:32.814631 23235 net.cpp:84] Creating Layer quantized_conv5
I1221 09:41:32.814641 23235 net.cpp:406] quantized_conv5 <- conv5
I1221 09:41:32.814656 23235 net.cpp:380] quantized_conv5 -> quantized_conv5
I1221 09:41:32.814671 23235 net.cpp:122] Setting up quantized_conv5
I1221 09:41:32.814680 23235 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1221 09:41:32.814687 23235 net.cpp:137] Memory required for data: 419323136
I1221 09:41:32.814694 23235 layer_factory.hpp:77] Creating layer relu5
I1221 09:41:32.814703 23235 net.cpp:84] Creating Layer relu5
I1221 09:41:32.814710 23235 net.cpp:406] relu5 <- quantized_conv5
I1221 09:41:32.814723 23235 net.cpp:380] relu5 -> relu5
I1221 09:41:32.814738 23235 net.cpp:122] Setting up relu5
I1221 09:41:32.814749 23235 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1221 09:41:32.814755 23235 net.cpp:137] Memory required for data: 424860928
I1221 09:41:32.814761 23235 layer_factory.hpp:77] Creating layer quantized_relu5
I1221 09:41:32.814774 23235 net.cpp:84] Creating Layer quantized_relu5
I1221 09:41:32.814780 23235 net.cpp:406] quantized_relu5 <- relu5
I1221 09:41:32.814790 23235 net.cpp:380] quantized_relu5 -> quantized_relu5
I1221 09:41:32.814800 23235 net.cpp:122] Setting up quantized_relu5
I1221 09:41:32.814808 23235 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1221 09:41:32.814815 23235 net.cpp:137] Memory required for data: 430398720
I1221 09:41:32.814821 23235 layer_factory.hpp:77] Creating layer pool5
I1221 09:41:32.814831 23235 net.cpp:84] Creating Layer pool5
I1221 09:41:32.814838 23235 net.cpp:406] pool5 <- quantized_relu5
I1221 09:41:32.814849 23235 net.cpp:380] pool5 -> pool5
I1221 09:41:32.814863 23235 net.cpp:122] Setting up pool5
I1221 09:41:32.814872 23235 net.cpp:129] Top shape: 32 256 6 6 (294912)
I1221 09:41:32.814879 23235 net.cpp:137] Memory required for data: 431578368
I1221 09:41:32.814887 23235 layer_factory.hpp:77] Creating layer quantized_pool5
I1221 09:41:32.814900 23235 net.cpp:84] Creating Layer quantized_pool5
I1221 09:41:32.814908 23235 net.cpp:406] quantized_pool5 <- pool5
I1221 09:41:32.814918 23235 net.cpp:380] quantized_pool5 -> quantized_pool5
I1221 09:41:32.814929 23235 net.cpp:122] Setting up quantized_pool5
I1221 09:41:32.814936 23235 net.cpp:129] Top shape: 32 256 6 6 (294912)
I1221 09:41:32.814944 23235 net.cpp:137] Memory required for data: 432758016
I1221 09:41:32.814950 23235 layer_factory.hpp:77] Creating layer fc6
I1221 09:41:32.814975 23235 net.cpp:84] Creating Layer fc6
I1221 09:41:32.814985 23235 net.cpp:406] fc6 <- quantized_pool5
I1221 09:41:32.814996 23235 net.cpp:380] fc6 -> fc6
I1221 09:41:33.908352 23235 net.cpp:122] Setting up fc6
I1221 09:41:33.908411 23235 net.cpp:129] Top shape: 32 4096 (131072)
I1221 09:41:33.908419 23235 net.cpp:137] Memory required for data: 433282304
I1221 09:41:33.908433 23235 layer_factory.hpp:77] Creating layer quantized_fc6
I1221 09:41:33.908452 23235 net.cpp:84] Creating Layer quantized_fc6
I1221 09:41:33.908460 23235 net.cpp:406] quantized_fc6 <- fc6
I1221 09:41:33.908480 23235 net.cpp:380] quantized_fc6 -> quantized_fc6
I1221 09:41:33.908499 23235 net.cpp:122] Setting up quantized_fc6
I1221 09:41:33.908519 23235 net.cpp:129] Top shape: 32 4096 (131072)
I1221 09:41:33.908540 23235 net.cpp:137] Memory required for data: 433806592
I1221 09:41:33.908546 23235 layer_factory.hpp:77] Creating layer relu6
I1221 09:41:33.908556 23235 net.cpp:84] Creating Layer relu6
I1221 09:41:33.908563 23235 net.cpp:406] relu6 <- quantized_fc6
I1221 09:41:33.908571 23235 net.cpp:380] relu6 -> relu6
I1221 09:41:33.908581 23235 net.cpp:122] Setting up relu6
I1221 09:41:33.908589 23235 net.cpp:129] Top shape: 32 4096 (131072)
I1221 09:41:33.908596 23235 net.cpp:137] Memory required for data: 434330880
I1221 09:41:33.908601 23235 layer_factory.hpp:77] Creating layer quantized_relu6
I1221 09:41:33.908610 23235 net.cpp:84] Creating Layer quantized_relu6
I1221 09:41:33.908617 23235 net.cpp:406] quantized_relu6 <- relu6
I1221 09:41:33.908625 23235 net.cpp:380] quantized_relu6 -> quantized_relu6
I1221 09:41:33.908634 23235 net.cpp:122] Setting up quantized_relu6
I1221 09:41:33.908643 23235 net.cpp:129] Top shape: 32 4096 (131072)
I1221 09:41:33.908648 23235 net.cpp:137] Memory required for data: 434855168
I1221 09:41:33.908655 23235 layer_factory.hpp:77] Creating layer fc7
I1221 09:41:33.908669 23235 net.cpp:84] Creating Layer fc7
I1221 09:41:33.908676 23235 net.cpp:406] fc7 <- quantized_relu6
I1221 09:41:33.908686 23235 net.cpp:380] fc7 -> fc7
I1221 09:41:34.375398 23235 net.cpp:122] Setting up fc7
I1221 09:41:34.375460 23235 net.cpp:129] Top shape: 32 4096 (131072)
I1221 09:41:34.375468 23235 net.cpp:137] Memory required for data: 435379456
I1221 09:41:34.375483 23235 layer_factory.hpp:77] Creating layer quantized_fc7
I1221 09:41:34.375501 23235 net.cpp:84] Creating Layer quantized_fc7
I1221 09:41:34.375511 23235 net.cpp:406] quantized_fc7 <- fc7
I1221 09:41:34.375524 23235 net.cpp:380] quantized_fc7 -> quantized_fc7
I1221 09:41:34.375540 23235 net.cpp:122] Setting up quantized_fc7
I1221 09:41:34.375550 23235 net.cpp:129] Top shape: 32 4096 (131072)
I1221 09:41:34.375555 23235 net.cpp:137] Memory required for data: 435903744
I1221 09:41:34.375561 23235 layer_factory.hpp:77] Creating layer relu7
I1221 09:41:34.375571 23235 net.cpp:84] Creating Layer relu7
I1221 09:41:34.375577 23235 net.cpp:406] relu7 <- quantized_fc7
I1221 09:41:34.375586 23235 net.cpp:380] relu7 -> relu7
I1221 09:41:34.375596 23235 net.cpp:122] Setting up relu7
I1221 09:41:34.375604 23235 net.cpp:129] Top shape: 32 4096 (131072)
I1221 09:41:34.375610 23235 net.cpp:137] Memory required for data: 436428032
I1221 09:41:34.375617 23235 layer_factory.hpp:77] Creating layer quantized_relu7
I1221 09:41:34.375625 23235 net.cpp:84] Creating Layer quantized_relu7
I1221 09:41:34.375633 23235 net.cpp:406] quantized_relu7 <- relu7
I1221 09:41:34.375643 23235 net.cpp:380] quantized_relu7 -> quantized_relu7
I1221 09:41:34.375653 23235 net.cpp:122] Setting up quantized_relu7
I1221 09:41:34.375661 23235 net.cpp:129] Top shape: 32 4096 (131072)
I1221 09:41:34.375668 23235 net.cpp:137] Memory required for data: 436952320
I1221 09:41:34.375674 23235 layer_factory.hpp:77] Creating layer fc8
I1221 09:41:34.375685 23235 net.cpp:84] Creating Layer fc8
I1221 09:41:34.375692 23235 net.cpp:406] fc8 <- quantized_relu7
I1221 09:41:34.375700 23235 net.cpp:380] fc8 -> fc8
I1221 09:41:34.382131 23235 net.cpp:122] Setting up fc8
I1221 09:41:34.382194 23235 net.cpp:129] Top shape: 32 1000 (32000)
I1221 09:41:34.382202 23235 net.cpp:137] Memory required for data: 437080320
I1221 09:41:34.382216 23235 layer_factory.hpp:77] Creating layer quantized_fc8
I1221 09:41:34.382236 23235 net.cpp:84] Creating Layer quantized_fc8
I1221 09:41:34.382246 23235 net.cpp:406] quantized_fc8 <- fc8
I1221 09:41:34.382258 23235 net.cpp:380] quantized_fc8 -> quantized_fc8
I1221 09:41:34.382275 23235 net.cpp:122] Setting up quantized_fc8
I1221 09:41:34.382287 23235 net.cpp:129] Top shape: 32 1000 (32000)
I1221 09:41:34.382292 23235 net.cpp:137] Memory required for data: 437208320
I1221 09:41:34.382298 23235 layer_factory.hpp:77] Creating layer quantized_fc8_quantized_fc8_0_split
I1221 09:41:34.382308 23235 net.cpp:84] Creating Layer quantized_fc8_quantized_fc8_0_split
I1221 09:41:34.382377 23235 net.cpp:406] quantized_fc8_quantized_fc8_0_split <- quantized_fc8
I1221 09:41:34.382386 23235 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_0
I1221 09:41:34.382396 23235 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_1
I1221 09:41:34.382406 23235 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_2
I1221 09:41:34.382418 23235 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_3
I1221 09:41:34.382429 23235 net.cpp:122] Setting up quantized_fc8_quantized_fc8_0_split
I1221 09:41:34.382438 23235 net.cpp:129] Top shape: 32 1000 (32000)
I1221 09:41:34.382446 23235 net.cpp:129] Top shape: 32 1000 (32000)
I1221 09:41:34.382452 23235 net.cpp:129] Top shape: 32 1000 (32000)
I1221 09:41:34.382458 23235 net.cpp:129] Top shape: 32 1000 (32000)
I1221 09:41:34.382464 23235 net.cpp:137] Memory required for data: 437720320
I1221 09:41:34.382472 23235 layer_factory.hpp:77] Creating layer probs
I1221 09:41:34.382480 23235 net.cpp:84] Creating Layer probs
I1221 09:41:34.382493 23235 net.cpp:406] probs <- quantized_fc8_quantized_fc8_0_split_0
I1221 09:41:34.382500 23235 net.cpp:380] probs -> probs
I1221 09:41:34.382525 23235 net.cpp:122] Setting up probs
I1221 09:41:34.382534 23235 net.cpp:129] Top shape: 32 1000 (32000)
I1221 09:41:34.382540 23235 net.cpp:137] Memory required for data: 437848320
I1221 09:41:34.382546 23235 layer_factory.hpp:77] Creating layer loss
I1221 09:41:34.382557 23235 net.cpp:84] Creating Layer loss
I1221 09:41:34.382565 23235 net.cpp:406] loss <- quantized_fc8_quantized_fc8_0_split_1
I1221 09:41:34.382573 23235 net.cpp:406] loss <- label_data_1_split_0
I1221 09:41:34.382582 23235 net.cpp:380] loss -> loss
I1221 09:41:34.382602 23235 layer_factory.hpp:77] Creating layer loss
I1221 09:41:34.382702 23235 net.cpp:122] Setting up loss
I1221 09:41:34.382714 23235 net.cpp:129] Top shape: (1)
I1221 09:41:34.382721 23235 net.cpp:132]     with loss weight 1
I1221 09:41:34.382751 23235 net.cpp:137] Memory required for data: 437848324
I1221 09:41:34.382758 23235 layer_factory.hpp:77] Creating layer acc_top1
I1221 09:41:34.382773 23235 net.cpp:84] Creating Layer acc_top1
I1221 09:41:34.382781 23235 net.cpp:406] acc_top1 <- quantized_fc8_quantized_fc8_0_split_2
I1221 09:41:34.382788 23235 net.cpp:406] acc_top1 <- label_data_1_split_1
I1221 09:41:34.382798 23235 net.cpp:380] acc_top1 -> acc_top1
I1221 09:41:34.382814 23235 net.cpp:122] Setting up acc_top1
I1221 09:41:34.382823 23235 net.cpp:129] Top shape: (1)
I1221 09:41:34.382829 23235 net.cpp:137] Memory required for data: 437848328
I1221 09:41:34.382836 23235 layer_factory.hpp:77] Creating layer acc_top5
I1221 09:41:34.382844 23235 net.cpp:84] Creating Layer acc_top5
I1221 09:41:34.382851 23235 net.cpp:406] acc_top5 <- quantized_fc8_quantized_fc8_0_split_3
I1221 09:41:34.382858 23235 net.cpp:406] acc_top5 <- label_data_1_split_2
I1221 09:41:34.382866 23235 net.cpp:380] acc_top5 -> acc_top5
I1221 09:41:34.382876 23235 net.cpp:122] Setting up acc_top5
I1221 09:41:34.382884 23235 net.cpp:129] Top shape: (1)
I1221 09:41:34.382890 23235 net.cpp:137] Memory required for data: 437848332
I1221 09:41:34.382896 23235 net.cpp:200] acc_top5 does not need backward computation.
I1221 09:41:34.382903 23235 net.cpp:200] acc_top1 does not need backward computation.
I1221 09:41:34.382910 23235 net.cpp:198] loss needs backward computation.
I1221 09:41:34.382916 23235 net.cpp:200] probs does not need backward computation.
I1221 09:41:34.382923 23235 net.cpp:198] quantized_fc8_quantized_fc8_0_split needs backward computation.
I1221 09:41:34.382930 23235 net.cpp:198] quantized_fc8 needs backward computation.
I1221 09:41:34.382936 23235 net.cpp:198] fc8 needs backward computation.
I1221 09:41:34.382943 23235 net.cpp:198] quantized_relu7 needs backward computation.
I1221 09:41:34.382951 23235 net.cpp:198] relu7 needs backward computation.
I1221 09:41:34.382973 23235 net.cpp:198] quantized_fc7 needs backward computation.
I1221 09:41:34.383078 23235 net.cpp:198] fc7 needs backward computation.
I1221 09:41:34.383095 23235 net.cpp:198] quantized_relu6 needs backward computation.
I1221 09:41:34.383105 23235 net.cpp:198] relu6 needs backward computation.
I1221 09:41:34.383111 23235 net.cpp:198] quantized_fc6 needs backward computation.
I1221 09:41:34.383118 23235 net.cpp:198] fc6 needs backward computation.
I1221 09:41:34.383126 23235 net.cpp:198] quantized_pool5 needs backward computation.
I1221 09:41:34.383137 23235 net.cpp:198] pool5 needs backward computation.
I1221 09:41:34.383146 23235 net.cpp:198] quantized_relu5 needs backward computation.
I1221 09:41:34.383152 23235 net.cpp:198] relu5 needs backward computation.
I1221 09:41:34.383159 23235 net.cpp:198] quantized_conv5 needs backward computation.
I1221 09:41:34.383167 23235 net.cpp:198] conv5 needs backward computation.
I1221 09:41:34.383173 23235 net.cpp:198] quantized_relu4 needs backward computation.
I1221 09:41:34.383180 23235 net.cpp:198] relu4 needs backward computation.
I1221 09:41:34.383188 23235 net.cpp:198] quantized_conv4 needs backward computation.
I1221 09:41:34.383194 23235 net.cpp:198] conv4 needs backward computation.
I1221 09:41:34.383203 23235 net.cpp:198] quantized_relu3 needs backward computation.
I1221 09:41:34.383209 23235 net.cpp:198] relu3 needs backward computation.
I1221 09:41:34.383216 23235 net.cpp:198] quantized_conv3 needs backward computation.
I1221 09:41:34.383224 23235 net.cpp:198] conv3 needs backward computation.
I1221 09:41:34.383230 23235 net.cpp:198] quantized_norm2 needs backward computation.
I1221 09:41:34.383237 23235 net.cpp:198] norm2 needs backward computation.
I1221 09:41:34.383244 23235 net.cpp:198] quantized_pool2 needs backward computation.
I1221 09:41:34.383251 23235 net.cpp:198] pool2 needs backward computation.
I1221 09:41:34.383258 23235 net.cpp:198] quantized_relu2 needs backward computation.
I1221 09:41:34.383265 23235 net.cpp:198] relu2 needs backward computation.
I1221 09:41:34.383272 23235 net.cpp:198] quantized_conv2 needs backward computation.
I1221 09:41:34.383280 23235 net.cpp:198] conv2 needs backward computation.
I1221 09:41:34.383286 23235 net.cpp:198] quantized_norm1 needs backward computation.
I1221 09:41:34.383293 23235 net.cpp:198] norm1 needs backward computation.
I1221 09:41:34.383301 23235 net.cpp:198] quantized_pool1 needs backward computation.
I1221 09:41:34.383308 23235 net.cpp:198] pool1 needs backward computation.
I1221 09:41:34.383316 23235 net.cpp:198] quantized_relu1 needs backward computation.
I1221 09:41:34.383322 23235 net.cpp:198] relu1 needs backward computation.
I1221 09:41:34.383329 23235 net.cpp:198] quantized_conv1 needs backward computation.
I1221 09:41:34.383337 23235 net.cpp:198] conv1 needs backward computation.
I1221 09:41:34.383344 23235 net.cpp:200] quantized_data does not need backward computation.
I1221 09:41:34.383352 23235 net.cpp:200] label_data_1_split does not need backward computation.
I1221 09:41:34.383359 23235 net.cpp:200] data does not need backward computation.
I1221 09:41:34.383368 23235 net.cpp:242] This network produces output acc_top1
I1221 09:41:34.383378 23235 net.cpp:242] This network produces output acc_top5
I1221 09:41:34.383384 23235 net.cpp:242] This network produces output loss
I1221 09:41:34.383391 23235 net.cpp:242] This network produces output probs
I1221 09:41:34.383431 23235 net.cpp:255] Network initialization done.
I1221 09:41:34.384351 23235 solver.cpp:172] Creating test net (#0) specified by net file: qnn_try1/train_quantized_caffenet.prototxt
I1221 09:41:34.384415 23235 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1221 09:41:34.384747 23235 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/ydwu/database/imagenet/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/ydwu/database/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_val_lmdb/"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "quantized_data"
  type: "Quantization"
  bottom: "data"
  top: "quantized_data"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -129.93526
    range: 160.78912
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "quantized_data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv1"
  type: "Quantization"
  bottom: "conv1"
  top: "quantized_conv1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -2732.7351
    range: 2531.042
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "quantized_conv1"
  top: "relu1"
}
layer {
  name: "quantized_relu1"
  type: "Quantization"
  bottom: "relu1"
  top: "quantized_relu1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 2531.042
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "quantized_relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool1"
  type: "Quantization"
  bottom: "pool1"
  top: "quantized_pool1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 2531.042
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "quantized_pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "quantized_norm1"
  type: "Quantization"
  bottom: "norm1"
  top: "quantized_norm1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 138.70576
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "quantized_norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv2"
  type: "Quantization"
  bottom: "conv2"
  top: "quantized_conv2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -647.61908
    range: 492.23111
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "quantized_conv2"
  top: "relu2"
}
layer {
  name: "quantized_relu2"
  type: "Quantization"
  bottom: "relu2"
  top: "quantized_relu2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 492.23111
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "quantized_relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool2"
  type: "Quantization"
  bottom: "pool2"
  top: "quantized_pool2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 492.23111
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "quantized_pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "quantized_norm2"
  type: "Quantization"
  bottom: "norm2"
  top: "quantized_norm2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 138.72636
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "quantized_norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv3"
  type: "Quantization"
  bottom: "conv3"
  top: "quantized_conv3"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -389.56516
    range: 331.98178
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "quantized_conv3"
  top: "relu3"
}
layer {
  name: "quantized_relu3"
  type: "Quantization"
  bottom: "relu3"
  top: "quantized_relu3"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 331.98178
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "quantized_relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv4"
  type: "Quantization"
  bottom: "conv4"
  top: "quantized_conv4"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -231.20598
    range: 283.87189
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "quantized_conv4"
  top: "relu4"
}
layer {
  name: "quantized_relu4"
  type: "Quantization"
  bottom: "relu4"
  top: "quantized_relu4"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 283.87189
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "quantized_relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv5"
  type: "Quantization"
  bottom: "conv5"
  top: "quantized_conv5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -172.60567
    range: 272.57315
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "quantized_conv5"
  top: "relu5"
}
layer {
  name: "quantized_relu5"
  type: "Quantization"
  bottom: "relu5"
  top: "quantized_relu5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 272.57315
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "quantized_relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool5"
  type: "Quantization"
  bottom: "pool5"
  top: "quantized_pool5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 272.57315
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "quantized_pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1.05e+13
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "quantized_fc6"
  type: "Quantization"
  bottom: "fc6"
  top: "quantized_fc6"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -114.02487
    range: 58.541733
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "quantized_fc6"
  top: "relu6"
}
layer {
  name: "quantized_relu6"
  type: "Quantization"
  bottom: "relu6"
  top: "quantized_relu6"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 58.541733
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "quantized_relu6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1.05e+13
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "quantized_fc7"
  type: "Quantization"
  bottom: "fc7"
  top: "quantized_fc7"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -26.019335
    range: 19.125257
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "quantized_fc7"
  top: "relu7"
}
layer {
  name: "quantized_relu7"
  type: "Quantization"
  bottom: "relu7"
  top: "quantized_relu7"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: 1
    range: 19.125257
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "quantized_relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "quantized_fc8"
  type: "Quantization"
  bottom: "fc8"
  top: "quantized_fc8"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 8
    range: -9.849781
    range: 45.688446
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "quantized_fc8"
  top: "probs"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc_top1"
  type: "Accuracy"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "acc_top1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc_top5"
  type: "Accuracy"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "acc_top5"
  accuracy_param {
    top_k: 5
  }
}
I1221 09:41:34.384928 23235 layer_factory.hpp:77] Creating layer data
I1221 09:41:34.385004 23235 db_lmdb.cpp:35] Opened lmdb /home/ydwu/database/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_val_lmdb/
I1221 09:41:34.385031 23235 net.cpp:84] Creating Layer data
I1221 09:41:34.385042 23235 net.cpp:380] data -> data
I1221 09:41:34.385056 23235 net.cpp:380] data -> label
I1221 09:41:34.385069 23235 data_transformer.cpp:25] Loading mean file from: /home/ydwu/database/imagenet/ilsvrc12/imagenet_mean.binaryproto
I1221 09:41:34.387209 23235 data_layer.cpp:45] output data size: 20,3,227,227
I1221 09:41:34.399811 23235 net.cpp:122] Setting up data
I1221 09:41:34.399873 23235 net.cpp:129] Top shape: 20 3 227 227 (3091740)
I1221 09:41:34.399883 23235 net.cpp:129] Top shape: 20 (20)
I1221 09:41:34.399889 23235 net.cpp:137] Memory required for data: 12367040
I1221 09:41:34.399901 23235 layer_factory.hpp:77] Creating layer label_data_1_split
I1221 09:41:34.399924 23235 net.cpp:84] Creating Layer label_data_1_split
I1221 09:41:34.399933 23235 net.cpp:406] label_data_1_split <- label
I1221 09:41:34.399946 23235 net.cpp:380] label_data_1_split -> label_data_1_split_0
I1221 09:41:34.399966 23235 net.cpp:380] label_data_1_split -> label_data_1_split_1
I1221 09:41:34.399976 23235 net.cpp:380] label_data_1_split -> label_data_1_split_2
I1221 09:41:34.399989 23235 net.cpp:122] Setting up label_data_1_split
I1221 09:41:34.399997 23235 net.cpp:129] Top shape: 20 (20)
I1221 09:41:34.400005 23235 net.cpp:129] Top shape: 20 (20)
I1221 09:41:34.400013 23235 net.cpp:129] Top shape: 20 (20)
I1221 09:41:34.400019 23235 net.cpp:137] Memory required for data: 12367280
I1221 09:41:34.400027 23235 layer_factory.hpp:77] Creating layer quantized_data
I1221 09:41:34.400038 23235 net.cpp:84] Creating Layer quantized_data
I1221 09:41:34.400045 23235 net.cpp:406] quantized_data <- data
I1221 09:41:34.400056 23235 net.cpp:380] quantized_data -> quantized_data
I1221 09:41:34.400068 23235 net.cpp:122] Setting up quantized_data
I1221 09:41:34.400076 23235 net.cpp:129] Top shape: 20 3 227 227 (3091740)
I1221 09:41:34.400082 23235 net.cpp:137] Memory required for data: 24734240
I1221 09:41:34.400089 23235 layer_factory.hpp:77] Creating layer conv1
I1221 09:41:34.400110 23235 net.cpp:84] Creating Layer conv1
I1221 09:41:34.400131 23235 net.cpp:406] conv1 <- quantized_data
I1221 09:41:34.400157 23235 net.cpp:380] conv1 -> conv1
I1221 09:41:34.401232 23235 net.cpp:122] Setting up conv1
I1221 09:41:34.401245 23235 net.cpp:129] Top shape: 20 96 55 55 (5808000)
I1221 09:41:34.401252 23235 net.cpp:137] Memory required for data: 47966240
I1221 09:41:34.401265 23235 layer_factory.hpp:77] Creating layer quantized_conv1
I1221 09:41:34.401279 23235 net.cpp:84] Creating Layer quantized_conv1
I1221 09:41:34.401288 23235 net.cpp:406] quantized_conv1 <- conv1
I1221 09:41:34.401296 23235 net.cpp:380] quantized_conv1 -> quantized_conv1
I1221 09:41:34.401306 23235 net.cpp:122] Setting up quantized_conv1
I1221 09:41:34.401315 23235 net.cpp:129] Top shape: 20 96 55 55 (5808000)
I1221 09:41:34.401321 23235 net.cpp:137] Memory required for data: 71198240
I1221 09:41:34.401327 23235 layer_factory.hpp:77] Creating layer relu1
I1221 09:41:34.401340 23235 net.cpp:84] Creating Layer relu1
I1221 09:41:34.401346 23235 net.cpp:406] relu1 <- quantized_conv1
I1221 09:41:34.401355 23235 net.cpp:380] relu1 -> relu1
I1221 09:41:34.401365 23235 net.cpp:122] Setting up relu1
I1221 09:41:34.401374 23235 net.cpp:129] Top shape: 20 96 55 55 (5808000)
I1221 09:41:34.401381 23235 net.cpp:137] Memory required for data: 94430240
I1221 09:41:34.401387 23235 layer_factory.hpp:77] Creating layer quantized_relu1
I1221 09:41:34.401396 23235 net.cpp:84] Creating Layer quantized_relu1
I1221 09:41:34.401402 23235 net.cpp:406] quantized_relu1 <- relu1
I1221 09:41:34.401417 23235 net.cpp:380] quantized_relu1 -> quantized_relu1
I1221 09:41:34.401427 23235 net.cpp:122] Setting up quantized_relu1
I1221 09:41:34.401437 23235 net.cpp:129] Top shape: 20 96 55 55 (5808000)
I1221 09:41:34.401443 23235 net.cpp:137] Memory required for data: 117662240
I1221 09:41:34.401449 23235 layer_factory.hpp:77] Creating layer pool1
I1221 09:41:34.401463 23235 net.cpp:84] Creating Layer pool1
I1221 09:41:34.401469 23235 net.cpp:406] pool1 <- quantized_relu1
I1221 09:41:34.401477 23235 net.cpp:380] pool1 -> pool1
I1221 09:41:34.401491 23235 net.cpp:122] Setting up pool1
I1221 09:41:34.401499 23235 net.cpp:129] Top shape: 20 96 27 27 (1399680)
I1221 09:41:34.401506 23235 net.cpp:137] Memory required for data: 123260960
I1221 09:41:34.401512 23235 layer_factory.hpp:77] Creating layer quantized_pool1
I1221 09:41:34.401525 23235 net.cpp:84] Creating Layer quantized_pool1
I1221 09:41:34.401643 23235 net.cpp:406] quantized_pool1 <- pool1
I1221 09:41:34.401664 23235 net.cpp:380] quantized_pool1 -> quantized_pool1
I1221 09:41:34.401682 23235 net.cpp:122] Setting up quantized_pool1
I1221 09:41:34.401692 23235 net.cpp:129] Top shape: 20 96 27 27 (1399680)
I1221 09:41:34.401698 23235 net.cpp:137] Memory required for data: 128859680
I1221 09:41:34.401705 23235 layer_factory.hpp:77] Creating layer norm1
I1221 09:41:34.401721 23235 net.cpp:84] Creating Layer norm1
I1221 09:41:34.401728 23235 net.cpp:406] norm1 <- quantized_pool1
I1221 09:41:34.401737 23235 net.cpp:380] norm1 -> norm1
I1221 09:41:34.401751 23235 net.cpp:122] Setting up norm1
I1221 09:41:34.401758 23235 net.cpp:129] Top shape: 20 96 27 27 (1399680)
I1221 09:41:34.401765 23235 net.cpp:137] Memory required for data: 134458400
I1221 09:41:34.401772 23235 layer_factory.hpp:77] Creating layer quantized_norm1
I1221 09:41:34.401783 23235 net.cpp:84] Creating Layer quantized_norm1
I1221 09:41:34.401790 23235 net.cpp:406] quantized_norm1 <- norm1
I1221 09:41:34.401799 23235 net.cpp:380] quantized_norm1 -> quantized_norm1
I1221 09:41:34.401808 23235 net.cpp:122] Setting up quantized_norm1
I1221 09:41:34.401818 23235 net.cpp:129] Top shape: 20 96 27 27 (1399680)
I1221 09:41:34.401823 23235 net.cpp:137] Memory required for data: 140057120
I1221 09:41:34.401830 23235 layer_factory.hpp:77] Creating layer conv2
I1221 09:41:34.401846 23235 net.cpp:84] Creating Layer conv2
I1221 09:41:34.401854 23235 net.cpp:406] conv2 <- quantized_norm1
I1221 09:41:34.401866 23235 net.cpp:380] conv2 -> conv2
I1221 09:41:34.411077 23235 net.cpp:122] Setting up conv2
I1221 09:41:34.411124 23235 net.cpp:129] Top shape: 20 256 27 27 (3732480)
I1221 09:41:34.411145 23235 net.cpp:137] Memory required for data: 154987040
I1221 09:41:34.411161 23235 layer_factory.hpp:77] Creating layer quantized_conv2
I1221 09:41:34.411178 23235 net.cpp:84] Creating Layer quantized_conv2
I1221 09:41:34.411187 23235 net.cpp:406] quantized_conv2 <- conv2
I1221 09:41:34.411198 23235 net.cpp:380] quantized_conv2 -> quantized_conv2
I1221 09:41:34.411212 23235 net.cpp:122] Setting up quantized_conv2
I1221 09:41:34.411221 23235 net.cpp:129] Top shape: 20 256 27 27 (3732480)
I1221 09:41:34.411227 23235 net.cpp:137] Memory required for data: 169916960
I1221 09:41:34.411234 23235 layer_factory.hpp:77] Creating layer relu2
I1221 09:41:34.411245 23235 net.cpp:84] Creating Layer relu2
I1221 09:41:34.411252 23235 net.cpp:406] relu2 <- quantized_conv2
I1221 09:41:34.411262 23235 net.cpp:380] relu2 -> relu2
I1221 09:41:34.411273 23235 net.cpp:122] Setting up relu2
I1221 09:41:34.411281 23235 net.cpp:129] Top shape: 20 256 27 27 (3732480)
I1221 09:41:34.411288 23235 net.cpp:137] Memory required for data: 184846880
I1221 09:41:34.411294 23235 layer_factory.hpp:77] Creating layer quantized_relu2
I1221 09:41:34.411306 23235 net.cpp:84] Creating Layer quantized_relu2
I1221 09:41:34.411314 23235 net.cpp:406] quantized_relu2 <- relu2
I1221 09:41:34.411321 23235 net.cpp:380] quantized_relu2 -> quantized_relu2
I1221 09:41:34.411331 23235 net.cpp:122] Setting up quantized_relu2
I1221 09:41:34.411340 23235 net.cpp:129] Top shape: 20 256 27 27 (3732480)
I1221 09:41:34.411346 23235 net.cpp:137] Memory required for data: 199776800
I1221 09:41:34.411353 23235 layer_factory.hpp:77] Creating layer pool2
I1221 09:41:34.411365 23235 net.cpp:84] Creating Layer pool2
I1221 09:41:34.411372 23235 net.cpp:406] pool2 <- quantized_relu2
I1221 09:41:34.411381 23235 net.cpp:380] pool2 -> pool2
I1221 09:41:34.411394 23235 net.cpp:122] Setting up pool2
I1221 09:41:34.411402 23235 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1221 09:41:34.411409 23235 net.cpp:137] Memory required for data: 203237920
I1221 09:41:34.411415 23235 layer_factory.hpp:77] Creating layer quantized_pool2
I1221 09:41:34.411429 23235 net.cpp:84] Creating Layer quantized_pool2
I1221 09:41:34.411437 23235 net.cpp:406] quantized_pool2 <- pool2
I1221 09:41:34.411447 23235 net.cpp:380] quantized_pool2 -> quantized_pool2
I1221 09:41:34.411456 23235 net.cpp:122] Setting up quantized_pool2
I1221 09:41:34.411464 23235 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1221 09:41:34.411470 23235 net.cpp:137] Memory required for data: 206699040
I1221 09:41:34.411478 23235 layer_factory.hpp:77] Creating layer norm2
I1221 09:41:34.411491 23235 net.cpp:84] Creating Layer norm2
I1221 09:41:34.411499 23235 net.cpp:406] norm2 <- quantized_pool2
I1221 09:41:34.411507 23235 net.cpp:380] norm2 -> norm2
I1221 09:41:34.411520 23235 net.cpp:122] Setting up norm2
I1221 09:41:34.411527 23235 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1221 09:41:34.411533 23235 net.cpp:137] Memory required for data: 210160160
I1221 09:41:34.411540 23235 layer_factory.hpp:77] Creating layer quantized_norm2
I1221 09:41:34.411550 23235 net.cpp:84] Creating Layer quantized_norm2
I1221 09:41:34.411558 23235 net.cpp:406] quantized_norm2 <- norm2
I1221 09:41:34.411566 23235 net.cpp:380] quantized_norm2 -> quantized_norm2
I1221 09:41:34.411576 23235 net.cpp:122] Setting up quantized_norm2
I1221 09:41:34.411588 23235 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1221 09:41:34.411594 23235 net.cpp:137] Memory required for data: 213621280
I1221 09:41:34.411602 23235 layer_factory.hpp:77] Creating layer conv3
I1221 09:41:34.411617 23235 net.cpp:84] Creating Layer conv3
I1221 09:41:34.411623 23235 net.cpp:406] conv3 <- quantized_norm2
I1221 09:41:34.411635 23235 net.cpp:380] conv3 -> conv3
I1221 09:41:34.437717 23235 net.cpp:122] Setting up conv3
I1221 09:41:34.437767 23235 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1221 09:41:34.437774 23235 net.cpp:137] Memory required for data: 218812960
I1221 09:41:34.437793 23235 layer_factory.hpp:77] Creating layer quantized_conv3
I1221 09:41:34.437837 23235 net.cpp:84] Creating Layer quantized_conv3
I1221 09:41:34.437847 23235 net.cpp:406] quantized_conv3 <- conv3
I1221 09:41:34.437860 23235 net.cpp:380] quantized_conv3 -> quantized_conv3
I1221 09:41:34.437875 23235 net.cpp:122] Setting up quantized_conv3
I1221 09:41:34.437885 23235 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1221 09:41:34.437891 23235 net.cpp:137] Memory required for data: 224004640
I1221 09:41:34.437897 23235 layer_factory.hpp:77] Creating layer relu3
I1221 09:41:34.437911 23235 net.cpp:84] Creating Layer relu3
I1221 09:41:34.437917 23235 net.cpp:406] relu3 <- quantized_conv3
I1221 09:41:34.437927 23235 net.cpp:380] relu3 -> relu3
I1221 09:41:34.437937 23235 net.cpp:122] Setting up relu3
I1221 09:41:34.437944 23235 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1221 09:41:34.437950 23235 net.cpp:137] Memory required for data: 229196320
I1221 09:41:34.437958 23235 layer_factory.hpp:77] Creating layer quantized_relu3
I1221 09:41:34.437968 23235 net.cpp:84] Creating Layer quantized_relu3
I1221 09:41:34.437975 23235 net.cpp:406] quantized_relu3 <- relu3
I1221 09:41:34.437984 23235 net.cpp:380] quantized_relu3 -> quantized_relu3
I1221 09:41:34.437994 23235 net.cpp:122] Setting up quantized_relu3
I1221 09:41:34.438002 23235 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1221 09:41:34.438009 23235 net.cpp:137] Memory required for data: 234388000
I1221 09:41:34.438015 23235 layer_factory.hpp:77] Creating layer conv4
I1221 09:41:34.438033 23235 net.cpp:84] Creating Layer conv4
I1221 09:41:34.438041 23235 net.cpp:406] conv4 <- quantized_relu3
I1221 09:41:34.438052 23235 net.cpp:380] conv4 -> conv4
I1221 09:41:34.457468 23235 net.cpp:122] Setting up conv4
I1221 09:41:34.457516 23235 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1221 09:41:34.457523 23235 net.cpp:137] Memory required for data: 239579680
I1221 09:41:34.457535 23235 layer_factory.hpp:77] Creating layer quantized_conv4
I1221 09:41:34.457552 23235 net.cpp:84] Creating Layer quantized_conv4
I1221 09:41:34.457561 23235 net.cpp:406] quantized_conv4 <- conv4
I1221 09:41:34.457573 23235 net.cpp:380] quantized_conv4 -> quantized_conv4
I1221 09:41:34.457589 23235 net.cpp:122] Setting up quantized_conv4
I1221 09:41:34.457598 23235 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1221 09:41:34.457604 23235 net.cpp:137] Memory required for data: 244771360
I1221 09:41:34.457610 23235 layer_factory.hpp:77] Creating layer relu4
I1221 09:41:34.457624 23235 net.cpp:84] Creating Layer relu4
I1221 09:41:34.457631 23235 net.cpp:406] relu4 <- quantized_conv4
I1221 09:41:34.457639 23235 net.cpp:380] relu4 -> relu4
I1221 09:41:34.457649 23235 net.cpp:122] Setting up relu4
I1221 09:41:34.457657 23235 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1221 09:41:34.457664 23235 net.cpp:137] Memory required for data: 249963040
I1221 09:41:34.457669 23235 layer_factory.hpp:77] Creating layer quantized_relu4
I1221 09:41:34.457679 23235 net.cpp:84] Creating Layer quantized_relu4
I1221 09:41:34.457684 23235 net.cpp:406] quantized_relu4 <- relu4
I1221 09:41:34.457695 23235 net.cpp:380] quantized_relu4 -> quantized_relu4
I1221 09:41:34.457705 23235 net.cpp:122] Setting up quantized_relu4
I1221 09:41:34.457715 23235 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1221 09:41:34.457720 23235 net.cpp:137] Memory required for data: 255154720
I1221 09:41:34.457726 23235 layer_factory.hpp:77] Creating layer conv5
I1221 09:41:34.457743 23235 net.cpp:84] Creating Layer conv5
I1221 09:41:34.457751 23235 net.cpp:406] conv5 <- quantized_relu4
I1221 09:41:34.457762 23235 net.cpp:380] conv5 -> conv5
I1221 09:41:34.470403 23235 net.cpp:122] Setting up conv5
I1221 09:41:34.470419 23235 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1221 09:41:34.470425 23235 net.cpp:137] Memory required for data: 258615840
I1221 09:41:34.470439 23235 layer_factory.hpp:77] Creating layer quantized_conv5
I1221 09:41:34.470453 23235 net.cpp:84] Creating Layer quantized_conv5
I1221 09:41:34.470459 23235 net.cpp:406] quantized_conv5 <- conv5
I1221 09:41:34.470481 23235 net.cpp:380] quantized_conv5 -> quantized_conv5
I1221 09:41:34.470505 23235 net.cpp:122] Setting up quantized_conv5
I1221 09:41:34.470515 23235 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1221 09:41:34.470520 23235 net.cpp:137] Memory required for data: 262076960
I1221 09:41:34.470527 23235 layer_factory.hpp:77] Creating layer relu5
I1221 09:41:34.470535 23235 net.cpp:84] Creating Layer relu5
I1221 09:41:34.470541 23235 net.cpp:406] relu5 <- quantized_conv5
I1221 09:41:34.470552 23235 net.cpp:380] relu5 -> relu5
I1221 09:41:34.470564 23235 net.cpp:122] Setting up relu5
I1221 09:41:34.470577 23235 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1221 09:41:34.470582 23235 net.cpp:137] Memory required for data: 265538080
I1221 09:41:34.470588 23235 layer_factory.hpp:77] Creating layer quantized_relu5
I1221 09:41:34.470597 23235 net.cpp:84] Creating Layer quantized_relu5
I1221 09:41:34.470603 23235 net.cpp:406] quantized_relu5 <- relu5
I1221 09:41:34.470612 23235 net.cpp:380] quantized_relu5 -> quantized_relu5
I1221 09:41:34.470621 23235 net.cpp:122] Setting up quantized_relu5
I1221 09:41:34.470629 23235 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1221 09:41:34.470635 23235 net.cpp:137] Memory required for data: 268999200
I1221 09:41:34.470641 23235 layer_factory.hpp:77] Creating layer pool5
I1221 09:41:34.470651 23235 net.cpp:84] Creating Layer pool5
I1221 09:41:34.470657 23235 net.cpp:406] pool5 <- quantized_relu5
I1221 09:41:34.470669 23235 net.cpp:380] pool5 -> pool5
I1221 09:41:34.470681 23235 net.cpp:122] Setting up pool5
I1221 09:41:34.470690 23235 net.cpp:129] Top shape: 20 256 6 6 (184320)
I1221 09:41:34.470696 23235 net.cpp:137] Memory required for data: 269736480
I1221 09:41:34.470702 23235 layer_factory.hpp:77] Creating layer quantized_pool5
I1221 09:41:34.470716 23235 net.cpp:84] Creating Layer quantized_pool5
I1221 09:41:34.470724 23235 net.cpp:406] quantized_pool5 <- pool5
I1221 09:41:34.470732 23235 net.cpp:380] quantized_pool5 -> quantized_pool5
I1221 09:41:34.470742 23235 net.cpp:122] Setting up quantized_pool5
I1221 09:41:34.470751 23235 net.cpp:129] Top shape: 20 256 6 6 (184320)
I1221 09:41:34.470757 23235 net.cpp:137] Memory required for data: 270473760
I1221 09:41:34.470763 23235 layer_factory.hpp:77] Creating layer fc6
I1221 09:41:34.470777 23235 net.cpp:84] Creating Layer fc6
I1221 09:41:34.470783 23235 net.cpp:406] fc6 <- quantized_pool5
I1221 09:41:34.470793 23235 net.cpp:380] fc6 -> fc6
I1221 09:41:35.525260 23235 net.cpp:122] Setting up fc6
I1221 09:41:35.525321 23235 net.cpp:129] Top shape: 20 4096 (81920)
I1221 09:41:35.525329 23235 net.cpp:137] Memory required for data: 270801440
I1221 09:41:35.525344 23235 layer_factory.hpp:77] Creating layer quantized_fc6
I1221 09:41:35.525362 23235 net.cpp:84] Creating Layer quantized_fc6
I1221 09:41:35.525370 23235 net.cpp:406] quantized_fc6 <- fc6
I1221 09:41:35.525387 23235 net.cpp:380] quantized_fc6 -> quantized_fc6
I1221 09:41:35.525403 23235 net.cpp:122] Setting up quantized_fc6
I1221 09:41:35.525413 23235 net.cpp:129] Top shape: 20 4096 (81920)
I1221 09:41:35.525418 23235 net.cpp:137] Memory required for data: 271129120
I1221 09:41:35.525424 23235 layer_factory.hpp:77] Creating layer relu6
I1221 09:41:35.525434 23235 net.cpp:84] Creating Layer relu6
I1221 09:41:35.525441 23235 net.cpp:406] relu6 <- quantized_fc6
I1221 09:41:35.525450 23235 net.cpp:380] relu6 -> relu6
I1221 09:41:35.525460 23235 net.cpp:122] Setting up relu6
I1221 09:41:35.525467 23235 net.cpp:129] Top shape: 20 4096 (81920)
I1221 09:41:35.525473 23235 net.cpp:137] Memory required for data: 271456800
I1221 09:41:35.525480 23235 layer_factory.hpp:77] Creating layer quantized_relu6
I1221 09:41:35.525490 23235 net.cpp:84] Creating Layer quantized_relu6
I1221 09:41:35.525496 23235 net.cpp:406] quantized_relu6 <- relu6
I1221 09:41:35.525507 23235 net.cpp:380] quantized_relu6 -> quantized_relu6
I1221 09:41:35.525518 23235 net.cpp:122] Setting up quantized_relu6
I1221 09:41:35.525527 23235 net.cpp:129] Top shape: 20 4096 (81920)
I1221 09:41:35.525547 23235 net.cpp:137] Memory required for data: 271784480
I1221 09:41:35.525566 23235 layer_factory.hpp:77] Creating layer fc7
I1221 09:41:35.525579 23235 net.cpp:84] Creating Layer fc7
I1221 09:41:35.525586 23235 net.cpp:406] fc7 <- quantized_relu6
I1221 09:41:35.525595 23235 net.cpp:380] fc7 -> fc7
I1221 09:41:36.025216 23235 net.cpp:122] Setting up fc7
I1221 09:41:36.025280 23235 net.cpp:129] Top shape: 20 4096 (81920)
I1221 09:41:36.025288 23235 net.cpp:137] Memory required for data: 272112160
I1221 09:41:36.025303 23235 layer_factory.hpp:77] Creating layer quantized_fc7
I1221 09:41:36.025323 23235 net.cpp:84] Creating Layer quantized_fc7
I1221 09:41:36.025334 23235 net.cpp:406] quantized_fc7 <- fc7
I1221 09:41:36.025347 23235 net.cpp:380] quantized_fc7 -> quantized_fc7
I1221 09:41:36.025364 23235 net.cpp:122] Setting up quantized_fc7
I1221 09:41:36.025373 23235 net.cpp:129] Top shape: 20 4096 (81920)
I1221 09:41:36.025379 23235 net.cpp:137] Memory required for data: 272439840
I1221 09:41:36.025387 23235 layer_factory.hpp:77] Creating layer relu7
I1221 09:41:36.025396 23235 net.cpp:84] Creating Layer relu7
I1221 09:41:36.025403 23235 net.cpp:406] relu7 <- quantized_fc7
I1221 09:41:36.025413 23235 net.cpp:380] relu7 -> relu7
I1221 09:41:36.025423 23235 net.cpp:122] Setting up relu7
I1221 09:41:36.025431 23235 net.cpp:129] Top shape: 20 4096 (81920)
I1221 09:41:36.025437 23235 net.cpp:137] Memory required for data: 272767520
I1221 09:41:36.025444 23235 layer_factory.hpp:77] Creating layer quantized_relu7
I1221 09:41:36.025454 23235 net.cpp:84] Creating Layer quantized_relu7
I1221 09:41:36.025460 23235 net.cpp:406] quantized_relu7 <- relu7
I1221 09:41:36.025472 23235 net.cpp:380] quantized_relu7 -> quantized_relu7
I1221 09:41:36.025483 23235 net.cpp:122] Setting up quantized_relu7
I1221 09:41:36.025491 23235 net.cpp:129] Top shape: 20 4096 (81920)
I1221 09:41:36.025498 23235 net.cpp:137] Memory required for data: 273095200
I1221 09:41:36.025504 23235 layer_factory.hpp:77] Creating layer fc8
I1221 09:41:36.025516 23235 net.cpp:84] Creating Layer fc8
I1221 09:41:36.025523 23235 net.cpp:406] fc8 <- quantized_relu7
I1221 09:41:36.025532 23235 net.cpp:380] fc8 -> fc8
I1221 09:41:36.032104 23235 net.cpp:122] Setting up fc8
I1221 09:41:36.032166 23235 net.cpp:129] Top shape: 20 1000 (20000)
I1221 09:41:36.032174 23235 net.cpp:137] Memory required for data: 273175200
I1221 09:41:36.032189 23235 layer_factory.hpp:77] Creating layer quantized_fc8
I1221 09:41:36.032209 23235 net.cpp:84] Creating Layer quantized_fc8
I1221 09:41:36.032219 23235 net.cpp:406] quantized_fc8 <- fc8
I1221 09:41:36.032233 23235 net.cpp:380] quantized_fc8 -> quantized_fc8
I1221 09:41:36.032253 23235 net.cpp:122] Setting up quantized_fc8
I1221 09:41:36.032263 23235 net.cpp:129] Top shape: 20 1000 (20000)
I1221 09:41:36.032269 23235 net.cpp:137] Memory required for data: 273255200
I1221 09:41:36.032275 23235 layer_factory.hpp:77] Creating layer quantized_fc8_quantized_fc8_0_split
I1221 09:41:36.032285 23235 net.cpp:84] Creating Layer quantized_fc8_quantized_fc8_0_split
I1221 09:41:36.032292 23235 net.cpp:406] quantized_fc8_quantized_fc8_0_split <- quantized_fc8
I1221 09:41:36.032300 23235 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_0
I1221 09:41:36.032310 23235 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_1
I1221 09:41:36.032320 23235 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_2
I1221 09:41:36.032332 23235 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_3
I1221 09:41:36.032344 23235 net.cpp:122] Setting up quantized_fc8_quantized_fc8_0_split
I1221 09:41:36.032353 23235 net.cpp:129] Top shape: 20 1000 (20000)
I1221 09:41:36.032361 23235 net.cpp:129] Top shape: 20 1000 (20000)
I1221 09:41:36.032367 23235 net.cpp:129] Top shape: 20 1000 (20000)
I1221 09:41:36.032375 23235 net.cpp:129] Top shape: 20 1000 (20000)
I1221 09:41:36.032382 23235 net.cpp:137] Memory required for data: 273575200
I1221 09:41:36.032409 23235 layer_factory.hpp:77] Creating layer probs
I1221 09:41:36.032436 23235 net.cpp:84] Creating Layer probs
I1221 09:41:36.032444 23235 net.cpp:406] probs <- quantized_fc8_quantized_fc8_0_split_0
I1221 09:41:36.032452 23235 net.cpp:380] probs -> probs
I1221 09:41:36.032470 23235 net.cpp:122] Setting up probs
I1221 09:41:36.032480 23235 net.cpp:129] Top shape: 20 1000 (20000)
I1221 09:41:36.032485 23235 net.cpp:137] Memory required for data: 273655200
I1221 09:41:36.032492 23235 layer_factory.hpp:77] Creating layer loss
I1221 09:41:36.032502 23235 net.cpp:84] Creating Layer loss
I1221 09:41:36.032510 23235 net.cpp:406] loss <- quantized_fc8_quantized_fc8_0_split_1
I1221 09:41:36.032517 23235 net.cpp:406] loss <- label_data_1_split_0
I1221 09:41:36.032526 23235 net.cpp:380] loss -> loss
I1221 09:41:36.032537 23235 layer_factory.hpp:77] Creating layer loss
I1221 09:41:36.032601 23235 net.cpp:122] Setting up loss
I1221 09:41:36.032613 23235 net.cpp:129] Top shape: (1)
I1221 09:41:36.032620 23235 net.cpp:132]     with loss weight 1
I1221 09:41:36.032639 23235 net.cpp:137] Memory required for data: 273655204
I1221 09:41:36.032644 23235 layer_factory.hpp:77] Creating layer acc_top1
I1221 09:41:36.032657 23235 net.cpp:84] Creating Layer acc_top1
I1221 09:41:36.032665 23235 net.cpp:406] acc_top1 <- quantized_fc8_quantized_fc8_0_split_2
I1221 09:41:36.032672 23235 net.cpp:406] acc_top1 <- label_data_1_split_1
I1221 09:41:36.032681 23235 net.cpp:380] acc_top1 -> acc_top1
I1221 09:41:36.032692 23235 net.cpp:122] Setting up acc_top1
I1221 09:41:36.032701 23235 net.cpp:129] Top shape: (1)
I1221 09:41:36.032706 23235 net.cpp:137] Memory required for data: 273655208
I1221 09:41:36.032713 23235 layer_factory.hpp:77] Creating layer acc_top5
I1221 09:41:36.032721 23235 net.cpp:84] Creating Layer acc_top5
I1221 09:41:36.032728 23235 net.cpp:406] acc_top5 <- quantized_fc8_quantized_fc8_0_split_3
I1221 09:41:36.032735 23235 net.cpp:406] acc_top5 <- label_data_1_split_2
I1221 09:41:36.032745 23235 net.cpp:380] acc_top5 -> acc_top5
I1221 09:41:36.032757 23235 net.cpp:122] Setting up acc_top5
I1221 09:41:36.032764 23235 net.cpp:129] Top shape: (1)
I1221 09:41:36.032770 23235 net.cpp:137] Memory required for data: 273655212
I1221 09:41:36.032778 23235 net.cpp:200] acc_top5 does not need backward computation.
I1221 09:41:36.032783 23235 net.cpp:200] acc_top1 does not need backward computation.
I1221 09:41:36.032790 23235 net.cpp:198] loss needs backward computation.
I1221 09:41:36.032797 23235 net.cpp:200] probs does not need backward computation.
I1221 09:41:36.032804 23235 net.cpp:198] quantized_fc8_quantized_fc8_0_split needs backward computation.
I1221 09:41:36.032810 23235 net.cpp:198] quantized_fc8 needs backward computation.
I1221 09:41:36.032817 23235 net.cpp:198] fc8 needs backward computation.
I1221 09:41:36.032824 23235 net.cpp:198] quantized_relu7 needs backward computation.
I1221 09:41:36.032830 23235 net.cpp:198] relu7 needs backward computation.
I1221 09:41:36.032837 23235 net.cpp:198] quantized_fc7 needs backward computation.
I1221 09:41:36.032845 23235 net.cpp:198] fc7 needs backward computation.
I1221 09:41:36.032851 23235 net.cpp:198] quantized_relu6 needs backward computation.
I1221 09:41:36.032858 23235 net.cpp:198] relu6 needs backward computation.
I1221 09:41:36.032866 23235 net.cpp:198] quantized_fc6 needs backward computation.
I1221 09:41:36.032871 23235 net.cpp:198] fc6 needs backward computation.
I1221 09:41:36.032879 23235 net.cpp:198] quantized_pool5 needs backward computation.
I1221 09:41:36.032886 23235 net.cpp:198] pool5 needs backward computation.
I1221 09:41:36.032892 23235 net.cpp:198] quantized_relu5 needs backward computation.
I1221 09:41:36.032899 23235 net.cpp:198] relu5 needs backward computation.
I1221 09:41:36.032907 23235 net.cpp:198] quantized_conv5 needs backward computation.
I1221 09:41:36.032913 23235 net.cpp:198] conv5 needs backward computation.
I1221 09:41:36.032920 23235 net.cpp:198] quantized_relu4 needs backward computation.
I1221 09:41:36.032927 23235 net.cpp:198] relu4 needs backward computation.
I1221 09:41:36.032938 23235 net.cpp:198] quantized_conv4 needs backward computation.
I1221 09:41:36.032954 23235 net.cpp:198] conv4 needs backward computation.
I1221 09:41:36.032963 23235 net.cpp:198] quantized_relu3 needs backward computation.
I1221 09:41:36.032969 23235 net.cpp:198] relu3 needs backward computation.
I1221 09:41:36.032975 23235 net.cpp:198] quantized_conv3 needs backward computation.
I1221 09:41:36.032982 23235 net.cpp:198] conv3 needs backward computation.
I1221 09:41:36.032989 23235 net.cpp:198] quantized_norm2 needs backward computation.
I1221 09:41:36.032996 23235 net.cpp:198] norm2 needs backward computation.
I1221 09:41:36.033004 23235 net.cpp:198] quantized_pool2 needs backward computation.
I1221 09:41:36.033010 23235 net.cpp:198] pool2 needs backward computation.
I1221 09:41:36.033017 23235 net.cpp:198] quantized_relu2 needs backward computation.
I1221 09:41:36.033025 23235 net.cpp:198] relu2 needs backward computation.
I1221 09:41:36.033031 23235 net.cpp:198] quantized_conv2 needs backward computation.
I1221 09:41:36.033038 23235 net.cpp:198] conv2 needs backward computation.
I1221 09:41:36.033044 23235 net.cpp:198] quantized_norm1 needs backward computation.
I1221 09:41:36.033051 23235 net.cpp:198] norm1 needs backward computation.
I1221 09:41:36.033058 23235 net.cpp:198] quantized_pool1 needs backward computation.
I1221 09:41:36.033066 23235 net.cpp:198] pool1 needs backward computation.
I1221 09:41:36.033072 23235 net.cpp:198] quantized_relu1 needs backward computation.
I1221 09:41:36.033078 23235 net.cpp:198] relu1 needs backward computation.
I1221 09:41:36.033085 23235 net.cpp:198] quantized_conv1 needs backward computation.
I1221 09:41:36.033092 23235 net.cpp:198] conv1 needs backward computation.
I1221 09:41:36.033099 23235 net.cpp:200] quantized_data does not need backward computation.
I1221 09:41:36.033107 23235 net.cpp:200] label_data_1_split does not need backward computation.
I1221 09:41:36.033114 23235 net.cpp:200] data does not need backward computation.
I1221 09:41:36.033120 23235 net.cpp:242] This network produces output acc_top1
I1221 09:41:36.033128 23235 net.cpp:242] This network produces output acc_top5
I1221 09:41:36.033133 23235 net.cpp:242] This network produces output loss
I1221 09:41:36.033140 23235 net.cpp:242] This network produces output probs
I1221 09:41:36.033172 23235 net.cpp:255] Network initialization done.
I1221 09:41:36.033335 23235 solver.cpp:56] Solver scaffolding done.
I1221 09:41:36.033393 23235 caffe.cpp:155] Finetuning from ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1221 09:41:36.500741 23235 upgrade_proto.cpp:44] Attempting to upgrade input file specified using deprecated transformation parameters: ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1221 09:41:36.500856 23235 upgrade_proto.cpp:47] Successfully upgraded file specified using deprecated data transformation parameters.
W1221 09:41:36.500885 23235 upgrade_proto.cpp:49] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1221 09:41:36.510185 23235 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1221 09:41:36.734669 23235 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I1221 09:41:36.776141 23235 net.cpp:744] Ignoring source layer drop6
I1221 09:41:36.792992 23235 net.cpp:744] Ignoring source layer drop7
I1221 09:41:37.276825 23235 upgrade_proto.cpp:44] Attempting to upgrade input file specified using deprecated transformation parameters: ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1221 09:41:37.276890 23235 upgrade_proto.cpp:47] Successfully upgraded file specified using deprecated data transformation parameters.
W1221 09:41:37.276899 23235 upgrade_proto.cpp:49] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1221 09:41:37.276916 23235 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1221 09:41:37.497649 23235 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I1221 09:41:37.548110 23235 net.cpp:744] Ignoring source layer drop6
I1221 09:41:37.567469 23235 net.cpp:744] Ignoring source layer drop7
I1221 09:41:37.573884 23235 caffe.cpp:248] Starting Optimization
I1221 09:41:37.573963 23235 solver.cpp:273] Solving 
I1221 09:41:37.573973 23235 solver.cpp:274] Learning Rate Policy: step
I1221 09:41:37.661433 23235 solver.cpp:331] Iteration 0, Testing net (#0)
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
max:0.402661  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512327  min:-0.185205
new--cpu_data-0.000527019
comput--weight-0.1875
max:0.353425  min:-0.14246
new--cpu_data0.00378311
comput--weight-0.125
max:0.314808  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521344  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674013  fc_min:-0.0446582
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
BP--weight-0.0134502
BP--weight0.00378311
BP--weight-0.000527019
BP--weight-0.0111258
BP--weight-0.00121359
I1221 09:44:40.565675 23235 solver.cpp:218] Iteration 0 (0.00124404 iter/s, 182.991s/20 iters), loss = 46.8125
I1221 09:44:40.565806 23235 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1221 09:44:40.565821 23235 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1221 09:44:40.565838 23235 solver.cpp:238]     Train net output #2: loss = 46.8125 (* 1 = 46.8125 loss)
I1221 09:44:40.575923 23235 sgd_solver.cpp:105] Iteration 0, lr = 0.003
max:0.40266  min:-0.373572
new--cpu_data-0.00121359
comput--weight-0.375
max:0.41551  min:-0.284751
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512326  min:-0.185205
new--cpu_data-0.000527018
comput--weight-0.1875
max:0.353424  min:-0.14246
new--cpu_data0.0037831
comput--weight-0.125
max:0.314807  min:-0.132628
new--cpu_data-0.0134502
comput--weight-0.125
fc_max:0.0484312  fc_min:-0.0351634
new--fc_cpu_data0.00639847
comput--fc_weight-0.0390625
fc_max:0.0521343  fc_min:-0.0320886
new--fc_cpu_data0.0125212
comput--fc_weight-0.03125
fc_max:0.0674012  fc_min:-0.0446581
new--fc_cpu_data0.000160601
comput--fc_weight-0.046875
BP--weight-0.0134502
BP--weight0.0037831
BP--weight-0.000527018
BP--weight-0.0111258
BP--weight-0.00121359
max:0.402659  min:-0.373571
new--cpu_data-0.00121358
comput--weight-0.375
max:0.415508  min:-0.28475
new--cpu_data-0.0111258
comput--weight-0.3125
max:0.512325  min:-0.185204
new--cpu_data-0.000527017
comput--weight-0.1875
max:0.353423  min:-0.14246
new--cpu_data0.00378309
comput--weight-0.125
max:0.314806  min:-0.132628
new--cpu_data-0.0134501
comput--weight-0.125
fc_max:0.048431  fc_min:-0.0351633
new--fc_cpu_data0.00639845
comput--fc_weight-0.0390625
fc_max:0.0521341  fc_min:-0.0320885
new--fc_cpu_data0.0125211
comput--fc_weight-0.03125
fc_max:0.067401  fc_min:-0.044658
new--fc_cpu_data0.0001606
comput--fc_weight-0.046875
BP--weight-0.0134501
BP--weight0.00378309
BP--weight-0.000527017
BP--weight-0.0111258
BP--weight-0.00121358
max:0.402658  min:-0.373569
new--cpu_data-0.00121358
comput--weight-0.375
max:0.415507  min:-0.284749
new--cpu_data-0.0111257
comput--weight-0.3125
max:0.512323  min:-0.185203
new--cpu_data-0.000527014
comput--weight-0.1875
max:0.353422  min:-0.142459
new--cpu_data0.00378308
comput--weight-0.125
max:0.314805  min:-0.132627
new--cpu_data-0.0134501
comput--weight-0.125
fc_max:0.0484308  fc_min:-0.0351631
new--fc_cpu_data0.00639842
comput--fc_weight-0.0390625
fc_max:0.0521339  fc_min:-0.0320884
new--fc_cpu_data0.0125211
comput--fc_weight-0.03125
fc_max:0.0674008  fc_min:-0.0446578
new--fc_cpu_data0.0001606
comput--fc_weight-0.046875
BP--weight-0.0134501
BP--weight0.00378308
BP--weight-0.000527014
BP--weight-0.0111257
BP--weight-0.00121358
max:0.402656  min:-0.373567
new--cpu_data-0.00121357
comput--weight-0.375
max:0.415505  min:-0.284747
new--cpu_data-0.0111257
comput--weight-0.3125
max:0.51232  min:-0.185202
new--cpu_data-0.000527012
comput--weight-0.1875
max:0.35342  min:-0.142458
new--cpu_data0.00378306
comput--weight-0.125
max:0.314804  min:-0.132627
new--cpu_data-0.01345
comput--weight-0.125
fc_max:0.0484306  fc_min:-0.0351629
new--fc_cpu_data0.00639839
comput--fc_weight-0.0390625
fc_max:0.0521337  fc_min:-0.0320882
new--fc_cpu_data0.012521
comput--fc_weight-0.03125
fc_max:0.0674004  fc_min:-0.0446576
new--fc_cpu_data0.000160599
comput--fc_weight-0.046875
BP--weight-0.01345
BP--weight0.00378306
BP--weight-0.000527012
BP--weight-0.0111257
BP--weight-0.00121357
max:0.402653  min:-0.373565
new--cpu_data-0.00121356
comput--weight-0.375
max:0.415502  min:-0.284746
new--cpu_data-0.0111256
comput--weight-0.3125
max:0.512317  min:-0.185201
new--cpu_data-0.000527008
comput--weight-0.1875
max:0.353418  min:-0.142457
new--cpu_data0.00378303
comput--weight-0.125
max:0.314802  min:-0.132626
new--cpu_data-0.0134499
comput--weight-0.125
fc_max:0.0484303  fc_min:-0.0351627
new--fc_cpu_data0.00639835
comput--fc_weight-0.0390625
fc_max:0.0521333  fc_min:-0.032088
new--fc_cpu_data0.0125209
comput--fc_weight-0.03125
fc_max:0.0674  fc_min:-0.0446573
new--fc_cpu_data0.000160598
comput--fc_weight-0.046875
BP--weight-0.0134499
BP--weight0.00378303
BP--weight-0.000527008
BP--weight-0.0111256
BP--weight-0.00121356
max:0.40265  min:-0.373562
new--cpu_data-0.00121355
comput--weight-0.375
max:0.415499  min:-0.284744
new--cpu_data-0.0111255
comput--weight-0.3125
max:0.512313  min:-0.1852
new--cpu_data-0.000527005
comput--weight-0.1875
max:0.353416  min:-0.142456
new--cpu_data0.00378301
comput--weight-0.125
max:0.314799  min:-0.132625
new--cpu_data-0.0134498
comput--weight-0.125
fc_max:0.0484299  fc_min:-0.0351625
new--fc_cpu_data0.0063983
comput--fc_weight-0.0390625
fc_max:0.052133  fc_min:-0.0320878
new--fc_cpu_data0.0125209
comput--fc_weight-0.03125
fc_max:0.0673995  fc_min:-0.044657
new--fc_cpu_data0.000160597
comput--fc_weight-0.046875
BP--weight-0.0134498
BP--weight0.00378301
BP--weight-0.000527005
BP--weight-0.0111255
BP--weight-0.00121355
max:0.402647  min:-0.373559
new--cpu_data-0.00121354
comput--weight-0.375
max:0.415496  min:-0.284741
new--cpu_data-0.0111254
comput--weight-0.3125
max:0.512309  min:-0.185199
new--cpu_data-0.000527001
comput--weight-0.1875
max:0.353413  min:-0.142455
new--cpu_data0.00378298
comput--weight-0.125
max:0.314797  min:-0.132624
new--cpu_data-0.0134497
comput--weight-0.125
fc_max:0.0484296  fc_min:-0.0351622
new--fc_cpu_data0.00639825
comput--fc_weight-0.0390625
fc_max:0.0521326  fc_min:-0.0320875
new--fc_cpu_data0.0125208
comput--fc_weight-0.03125
fc_max:0.067399  fc_min:-0.0446566
new--fc_cpu_data0.000160595
comput--fc_weight-0.046875
BP--weight-0.0134497
BP--weight0.00378298
BP--weight-0.000527001
BP--weight-0.0111254
BP--weight-0.00121354
max:0.402644  min:-0.373556
new--cpu_data-0.00121353
comput--weight-0.375
max:0.415492  min:-0.284739
new--cpu_data-0.0111253
comput--weight-0.3125
max:0.512305  min:-0.185197
new--cpu_data-0.000526996
comput--weight-0.1875
max:0.35341  min:-0.142454
new--cpu_data0.00378294
comput--weight-0.125
max:0.314794  min:-0.132623
new--cpu_data-0.0134496
comput--weight-0.125
fc_max:0.0484291  fc_min:-0.0351619
new--fc_cpu_data0.0063982
comput--fc_weight-0.0390625
fc_max:0.0521321  fc_min:-0.0320873
new--fc_cpu_data0.0125207
comput--fc_weight-0.03125
fc_max:0.0673984  fc_min:-0.0446563
new--fc_cpu_data0.000160594
comput--fc_weight-0.046875
BP--weight-0.0134496
BP--weight0.00378294
BP--weight-0.000526996
BP--weight-0.0111253
BP--weight-0.00121353
max:0.40264  min:-0.373553
new--cpu_data-0.00121352
comput--weight-0.375
max:0.415488  min:-0.284736
new--cpu_data-0.0111252
comput--weight-0.3125
max:0.5123  min:-0.185195
new--cpu_data-0.000526991
comput--weight-0.1875
max:0.353407  min:-0.142453
new--cpu_data0.00378291
comput--weight-0.125
max:0.314791  min:-0.132621
new--cpu_data-0.0134495
comput--weight-0.125
fc_max:0.0484287  fc_min:-0.0351616
new--fc_cpu_data0.00639814
comput--fc_weight-0.0390625
fc_max:0.0521316  fc_min:-0.032087
new--fc_cpu_data0.0125205
comput--fc_weight-0.03125
fc_max:0.0673978  fc_min:-0.0446559
new--fc_cpu_data0.000160593
comput--fc_weight-0.046875
BP--weight-0.0134495
BP--weight0.00378291
BP--weight-0.000526991
BP--weight-0.0111252
BP--weight-0.00121352
max:0.402636  min:-0.373549
new--cpu_data-0.00121351
comput--weight-0.375
max:0.415484  min:-0.284734
new--cpu_data-0.0111251
comput--weight-0.3125
max:0.512295  min:-0.185193
new--cpu_data-0.000526986
comput--weight-0.1875
max:0.353403  min:-0.142451
new--cpu_data0.00378287
comput--weight-0.125
max:0.314788  min:-0.13262
new--cpu_data-0.0134493
comput--weight-0.125
fc_max:0.0484282  fc_min:-0.0351612
new--fc_cpu_data0.00639808
comput--fc_weight-0.0390625
fc_max:0.0521311  fc_min:-0.0320867
new--fc_cpu_data0.0125204
comput--fc_weight-0.03125
fc_max:0.0673971  fc_min:-0.0446554
new--fc_cpu_data0.000160591
comput--fc_weight-0.046875
BP--weight-0.0134493
BP--weight0.00378287
BP--weight-0.000526986
BP--weight-0.0111251
BP--weight-0.00121351
max:0.402632  min:-0.373545
new--cpu_data-0.0012135
comput--weight-0.375
max:0.41548  min:-0.284731
new--cpu_data-0.011125
comput--weight-0.3125
max:0.51229  min:-0.185192
new--cpu_data-0.000526981
comput--weight-0.1875
max:0.353399  min:-0.14245
new--cpu_data0.00378283
comput--weight-0.125
max:0.314785  min:-0.132619
new--cpu_data-0.0134492
comput--weight-0.125
fc_max:0.0484277  fc_min:-0.0351609
new--fc_cpu_data0.00639801
comput--fc_weight-0.0390625
fc_max:0.0521306  fc_min:-0.0320863
new--fc_cpu_data0.0125203
comput--fc_weight-0.03125
fc_max:0.0673964  fc_min:-0.044655
new--fc_cpu_data0.000160589
comput--fc_weight-0.046875
BP--weight-0.0134492
BP--weight0.00378283
BP--weight-0.000526981
BP--weight-0.011125
BP--weight-0.0012135
max:0.402628  min:-0.373541
new--cpu_data-0.00121349
comput--weight-0.375
max:0.415476  min:-0.284728
new--cpu_data-0.0111249
comput--weight-0.3125
max:0.512285  min:-0.18519
new--cpu_data-0.000526975
comput--weight-0.1875
max:0.353396  min:-0.142448
new--cpu_data0.00378279
comput--weight-0.125
max:0.314782  min:-0.132617
new--cpu_data-0.0134491
comput--weight-0.125
fc_max:0.0484272  fc_min:-0.0351605
new--fc_cpu_data0.00639794
comput--fc_weight-0.0390625
fc_max:0.05213  fc_min:-0.032086
new--fc_cpu_data0.0125202
comput--fc_weight-0.03125
fc_max:0.0673957  fc_min:-0.0446545
new--fc_cpu_data0.000160588
comput--fc_weight-0.046875
BP--weight-0.0134491
BP--weight0.00378279
BP--weight-0.000526975
BP--weight-0.0111249
BP--weight-0.00121349
max:0.402623  min:-0.373537
new--cpu_data-0.00121347
comput--weight-0.375
max:0.415471  min:-0.284724
new--cpu_data-0.0111248
comput--weight-0.3125
max:0.512279  min:-0.185187
new--cpu_data-0.000526969
comput--weight-0.1875
max:0.353392  min:-0.142447
new--cpu_data0.00378275
comput--weight-0.125
max:0.314778  min:-0.132616
new--cpu_data-0.0134489
comput--weight-0.125
fc_max:0.0484267  fc_min:-0.0351601
new--fc_cpu_data0.00639787
comput--fc_weight-0.0390625
fc_max:0.0521294  fc_min:-0.0320856
new--fc_cpu_data0.01252
comput--fc_weight-0.03125
fc_max:0.067395  fc_min:-0.044654
new--fc_cpu_data0.000160586
comput--fc_weight-0.046875
BP--weight-0.0134489
BP--weight0.00378275
BP--weight-0.000526969
BP--weight-0.0111248
BP--weight-0.00121347
max:0.402618  min:-0.373533
new--cpu_data-0.00121346
comput--weight-0.375
max:0.415466  min:-0.284721
new--cpu_data-0.0111246
comput--weight-0.3125
max:0.512273  min:-0.185185
new--cpu_data-0.000526963
comput--weight-0.1875
max:0.353388  min:-0.142445
new--cpu_data0.00378271
comput--weight-0.125
max:0.314775  min:-0.132614
new--cpu_data-0.0134487
comput--weight-0.125
fc_max:0.0484261  fc_min:-0.0351597
new--fc_cpu_data0.0063978
comput--fc_weight-0.0390625
fc_max:0.0521288  fc_min:-0.0320852
new--fc_cpu_data0.0125199
comput--fc_weight-0.03125
fc_max:0.0673942  fc_min:-0.0446535
new--fc_cpu_data0.000160584
comput--fc_weight-0.046875
BP--weight-0.0134487
BP--weight0.00378271
BP--weight-0.000526963
BP--weight-0.0111246
BP--weight-0.00121346
max:0.402614  min:-0.373528
new--cpu_data-0.00121344
comput--weight-0.375
max:0.415461  min:-0.284718
new--cpu_data-0.0111245
comput--weight-0.3125
max:0.512267  min:-0.185183
new--cpu_data-0.000526957
comput--weight-0.1875
max:0.353383  min:-0.142443
new--cpu_data0.00378266
comput--weight-0.125
max:0.314771  min:-0.132613
new--cpu_data-0.0134486
comput--weight-0.125
fc_max:0.0484255  fc_min:-0.0351593
new--fc_cpu_data0.00639772
comput--fc_weight-0.0390625
fc_max:0.0521282  fc_min:-0.0320849
new--fc_cpu_data0.0125197
comput--fc_weight-0.03125
fc_max:0.0673934  fc_min:-0.0446529
new--fc_cpu_data0.000160582
comput--fc_weight-0.046875
BP--weight-0.0134486
BP--weight0.00378266
BP--weight-0.000526957
BP--weight-0.0111245
BP--weight-0.00121344
max:0.402609  min:-0.373524
new--cpu_data-0.00121343
comput--weight-0.375
max:0.415456  min:-0.284714
new--cpu_data-0.0111244
comput--weight-0.3125
max:0.512261  min:-0.185181
new--cpu_data-0.00052695
comput--weight-0.1875
max:0.353379  min:-0.142442
new--cpu_data0.00378262
comput--weight-0.125
max:0.314767  min:-0.132611
new--cpu_data-0.0134484
comput--weight-0.125
fc_max:0.0484249  fc_min:-0.0351588
new--fc_cpu_data0.00639764
comput--fc_weight-0.0390625
fc_max:0.0521276  fc_min:-0.0320845
new--fc_cpu_data0.0125196
comput--fc_weight-0.03125
fc_max:0.0673926  fc_min:-0.0446524
new--fc_cpu_data0.00016058
comput--fc_weight-0.046875
BP--weight-0.0134484
BP--weight0.00378262
BP--weight-0.00052695
BP--weight-0.0111244
BP--weight-0.00121343
max:0.402604  min:-0.373519
new--cpu_data-0.00121341
comput--weight-0.375
max:0.415451  min:-0.284711
new--cpu_data-0.0111242
comput--weight-0.3125
max:0.512254  min:-0.185179
new--cpu_data-0.000526944
comput--weight-0.1875
max:0.353375  min:-0.14244
new--cpu_data0.00378257
comput--weight-0.125
max:0.314763  min:-0.13261
new--cpu_data-0.0134483
comput--weight-0.125
fc_max:0.0484243  fc_min:-0.0351584
new--fc_cpu_data0.00639756
comput--fc_weight-0.0390625
fc_max:0.0521269  fc_min:-0.0320841
new--fc_cpu_data0.0125194
comput--fc_weight-0.03125
fc_max:0.0673917  fc_min:-0.0446518
new--fc_cpu_data0.000160578
comput--fc_weight-0.046875
BP--weight-0.0134483
BP--weight0.00378257
BP--weight-0.000526944
BP--weight-0.0111242
BP--weight-0.00121341
max:0.402599  min:-0.373514
new--cpu_data-0.0012134
comput--weight-0.375
max:0.415446  min:-0.284707
new--cpu_data-0.0111241
comput--weight-0.3125
max:0.512248  min:-0.185176
new--cpu_data-0.000526937
comput--weight-0.1875
max:0.35337  min:-0.142438
new--cpu_data0.00378252
comput--weight-0.125
max:0.314759  min:-0.132608
new--cpu_data-0.0134481
comput--weight-0.125
fc_max:0.0484237  fc_min:-0.035158
new--fc_cpu_data0.00639748
comput--fc_weight-0.0390625
fc_max:0.0521263  fc_min:-0.0320837
new--fc_cpu_data0.0125192
comput--fc_weight-0.03125
fc_max:0.0673909  fc_min:-0.0446513
new--fc_cpu_data0.000160576
comput--fc_weight-0.046875
BP--weight-0.0134481
BP--weight0.00378252
BP--weight-0.000526937
BP--weight-0.0111241
BP--weight-0.0012134
max:0.402593  min:-0.373509
new--cpu_data-0.00121338
comput--weight-0.375
max:0.41544  min:-0.284703
new--cpu_data-0.0111239
comput--weight-0.3125
max:0.512241  min:-0.185174
new--cpu_data-0.00052693
comput--weight-0.1875
max:0.353366  min:-0.142436
new--cpu_data0.00378247
comput--weight-0.125
max:0.314755  min:-0.132606
new--cpu_data-0.0134479
comput--weight-0.125
fc_max:0.0484231  fc_min:-0.0351575
new--fc_cpu_data0.0063974
comput--fc_weight-0.0390625
fc_max:0.0521256  fc_min:-0.0320832
new--fc_cpu_data0.0125191
comput--fc_weight-0.03125
fc_max:0.06739  fc_min:-0.0446507
new--fc_cpu_data0.000160574
comput--fc_weight-0.046875
BP--weight-0.0134479
BP--weight0.00378247
BP--weight-0.00052693
BP--weight-0.0111239
BP--weight-0.00121338
max:0.402588  min:-0.373505
new--cpu_data-0.00121337
comput--weight-0.375
max:0.415435  min:-0.2847
new--cpu_data-0.0111238
comput--weight-0.3125
max:0.512234  min:-0.185171
new--cpu_data-0.000526923
comput--weight-0.1875
max:0.353361  min:-0.142434
new--cpu_data0.00378242
comput--weight-0.125
max:0.314751  min:-0.132604
new--cpu_data-0.0134477
comput--weight-0.125
fc_max:0.0484225  fc_min:-0.035157
new--fc_cpu_data0.00639731
comput--fc_weight-0.0390625
fc_max:0.0521249  fc_min:-0.0320828
new--fc_cpu_data0.0125189
comput--fc_weight-0.03125
fc_max:0.0673891  fc_min:-0.0446501
new--fc_cpu_data0.000160572
comput--fc_weight-0.046875
BP--weight-0.0134477
BP--weight0.00378242
BP--weight-0.000526923
BP--weight-0.0111238
BP--weight-0.00121337
I1221 09:52:37.608109 23235 solver.cpp:218] Iteration 20 (0.041925 iter/s, 477.042s/20 iters), loss = 37.8594
I1221 09:52:37.608402 23235 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1221 09:52:37.608434 23235 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1221 09:52:37.608469 23235 solver.cpp:238]     Train net output #2: loss = 37.8594 (* 1 = 37.8594 loss)
I1221 09:52:37.619155 23235 sgd_solver.cpp:105] Iteration 20, lr = 0.003
max:0.402583  min:-0.3735
new--cpu_data-0.00121335
comput--weight-0.375
max:0.415429  min:-0.284696
new--cpu_data-0.0111236
comput--weight-0.3125
max:0.512227  min:-0.185169
new--cpu_data-0.000526916
comput--weight-0.1875
max:0.353356  min:-0.142433
new--cpu_data0.00378237
comput--weight-0.125
max:0.314747  min:-0.132603
new--cpu_data-0.0134476
comput--weight-0.125
fc_max:0.0484218  fc_min:-0.0351566
new--fc_cpu_data0.00639723
comput--fc_weight-0.0390625
fc_max:0.0521242  fc_min:-0.0320824
new--fc_cpu_data0.0125188
comput--fc_weight-0.03125
fc_max:0.0673882  fc_min:-0.0446495
new--fc_cpu_data0.00016057
comput--fc_weight-0.046875
BP--weight-0.0134476
BP--weight0.00378237
BP--weight-0.000526916
BP--weight-0.0111236
BP--weight-0.00121335
max:0.402577  min:-0.373495
new--cpu_data-0.00121333
comput--weight-0.375
max:0.415424  min:-0.284692
new--cpu_data-0.0111235
comput--weight-0.3125
max:0.512221  min:-0.185166
new--cpu_data-0.000526909
comput--weight-0.1875
max:0.353351  min:-0.142431
new--cpu_data0.00378232
comput--weight-0.125
max:0.314742  min:-0.132601
new--cpu_data-0.0134474
comput--weight-0.125
fc_max:0.0484211  fc_min:-0.0351561
new--fc_cpu_data0.00639714
comput--fc_weight-0.03125
fc_max:0.0521235  fc_min:-0.032082
new--fc_cpu_data0.0125186
comput--fc_weight-0.03125
fc_max:0.0673873  fc_min:-0.0446489
new--fc_cpu_data0.000160568
comput--fc_weight-0.046875
BP--weight-0.0134474
BP--weight0.00378232
BP--weight-0.000526909
BP--weight-0.0111235
BP--weight-0.00121333
max:0.402572  min:-0.373489
new--cpu_data-0.00121332
comput--weight-0.375
max:0.415418  min:-0.284688
new--cpu_data-0.0111233
comput--weight-0.3125
max:0.512214  min:-0.185164
new--cpu_data-0.000526902
comput--weight-0.1875
max:0.353347  min:-0.142429
new--cpu_data0.00378227
comput--weight-0.125
max:0.314738  min:-0.132599
new--cpu_data-0.0134472
comput--weight-0.125
fc_max:0.0484205  fc_min:-0.0351556
new--fc_cpu_data0.00639705
comput--fc_weight-0.03125
fc_max:0.0521228  fc_min:-0.0320815
new--fc_cpu_data0.0125184
comput--fc_weight-0.03125
fc_max:0.0673864  fc_min:-0.0446483
new--fc_cpu_data0.000160565
comput--fc_weight-0.046875
BP--weight-0.0134472
BP--weight0.00378227
BP--weight-0.000526902
BP--weight-0.0111233
BP--weight-0.00121332
max:0.402566  min:-0.373484
new--cpu_data-0.0012133
comput--weight-0.375
max:0.415412  min:-0.284684
new--cpu_data-0.0111232
comput--weight-0.3125
max:0.512206  min:-0.185161
new--cpu_data-0.000526895
comput--weight-0.1875
max:0.353342  min:-0.142427
new--cpu_data0.00378222
comput--weight-0.125
max:0.314734  min:-0.132597
new--cpu_data-0.013447
comput--weight-0.125
fc_max:0.0484198  fc_min:-0.0351551
new--fc_cpu_data0.00639697
comput--fc_weight-0.03125
fc_max:0.0521221  fc_min:-0.0320811
new--fc_cpu_data0.0125182
comput--fc_weight-0.03125
fc_max:0.0673854  fc_min:-0.0446477
new--fc_cpu_data0.000160563
comput--fc_weight-0.046875
BP--weight-0.013447
BP--weight0.00378222
BP--weight-0.000526895
BP--weight-0.0111232
BP--weight-0.0012133
max:0.402561  min:-0.373479
new--cpu_data-0.00121328
comput--weight-0.375
max:0.415406  min:-0.28468
new--cpu_data-0.011123
comput--weight-0.3125
max:0.512199  min:-0.185159
new--cpu_data-0.000526887
comput--weight-0.1875
max:0.353337  min:-0.142425
new--cpu_data0.00378216
comput--weight-0.125
max:0.314729  min:-0.132595
new--cpu_data-0.0134468
comput--weight-0.125
fc_max:0.0484191  fc_min:-0.0351546
new--fc_cpu_data0.00639688
comput--fc_weight-0.03125
fc_max:0.0521213  fc_min:-0.0320806
new--fc_cpu_data0.0125181
comput--fc_weight-0.03125
fc_max:0.0673845  fc_min:-0.044647
new--fc_cpu_data0.000160561
comput--fc_weight-0.046875
BP--weight-0.0134468
BP--weight0.00378216
BP--weight-0.000526887
BP--weight-0.011123
BP--weight-0.00121328
max:0.402555  min:-0.373474
new--cpu_data-0.00121327
comput--weight-0.375
max:0.415401  min:-0.284676
new--cpu_data-0.0111229
comput--weight-0.3125
max:0.512192  min:-0.185156
new--cpu_data-0.00052688
comput--weight-0.1875
max:0.353332  min:-0.142423
new--cpu_data0.00378211
comput--weight-0.125
max:0.314725  min:-0.132593
new--cpu_data-0.0134466
comput--weight-0.125
fc_max:0.0484185  fc_min:-0.0351541
new--fc_cpu_data0.00639679
comput--fc_weight-0.03125
fc_max:0.0521206  fc_min:-0.0320802
new--fc_cpu_data0.0125179
comput--fc_weight-0.03125
fc_max:0.0673835  fc_min:-0.0446464
new--fc_cpu_data0.000160559
comput--fc_weight-0.046875
BP--weight-0.0134466
BP--weight0.00378211
BP--weight-0.00052688
BP--weight-0.0111229
BP--weight-0.00121327
max:0.402549  min:-0.373469
new--cpu_data-0.00121325
comput--weight-0.375
max:0.415395  min:-0.284672
new--cpu_data-0.0111227
comput--weight-0.3125
max:0.512185  min:-0.185153
new--cpu_data-0.000526873
comput--weight-0.1875
max:0.353327  min:-0.142421
new--cpu_data0.00378206
comput--weight-0.125
max:0.31472  min:-0.132592
new--cpu_data-0.0134464
comput--weight-0.125
fc_max:0.0484178  fc_min:-0.0351536
new--fc_cpu_data0.0063967
comput--fc_weight-0.03125
fc_max:0.0521199  fc_min:-0.0320797
new--fc_cpu_data0.0125177
comput--fc_weight-0.03125
fc_max:0.0673826  fc_min:-0.0446458
new--fc_cpu_data0.000160556
comput--fc_weight-0.046875
BP--weight-0.0134464
BP--weight0.00378206
BP--weight-0.000526873
BP--weight-0.0111227
BP--weight-0.00121325
max:0.402543  min:-0.373463
new--cpu_data-0.00121323
comput--weight-0.375
max:0.415389  min:-0.284668
new--cpu_data-0.0111226
comput--weight-0.3125
max:0.512178  min:-0.185151
new--cpu_data-0.000526865
comput--weight-0.1875
max:0.353322  min:-0.142419
new--cpu_data0.003782
comput--weight-0.125
max:0.314716  min:-0.13259
new--cpu_data-0.0134462
comput--weight-0.125
fc_max:0.0484171  fc_min:-0.0351532
new--fc_cpu_data0.00639661
comput--fc_weight-0.03125
fc_max:0.0521191  fc_min:-0.0320793
new--fc_cpu_data0.0125175
comput--fc_weight-0.03125
fc_max:0.0673816  fc_min:-0.0446451
new--fc_cpu_data0.000160554
comput--fc_weight-0.046875
BP--weight-0.0134462
BP--weight0.003782
BP--weight-0.000526865
BP--weight-0.0111226
BP--weight-0.00121323
max:0.402538  min:-0.373458
new--cpu_data-0.00121322
comput--weight-0.375
max:0.415383  min:-0.284664
new--cpu_data-0.0111224
comput--weight-0.3125
max:0.51217  min:-0.185148
new--cpu_data-0.000526858
comput--weight-0.1875
max:0.353317  min:-0.142417
new--cpu_data0.00378195
comput--weight-0.125
max:0.314711  min:-0.132588
new--cpu_data-0.0134461
comput--weight-0.125
fc_max:0.0484164  fc_min:-0.0351526
new--fc_cpu_data0.00639651
comput--fc_weight-0.03125
fc_max:0.0521184  fc_min:-0.0320788
new--fc_cpu_data0.0125174
comput--fc_weight-0.03125
fc_max:0.0673807  fc_min:-0.0446445
new--fc_cpu_data0.000160552
comput--fc_weight-0.046875
BP--weight-0.0134461
BP--weight0.00378195
BP--weight-0.000526858
BP--weight-0.0111224
BP--weight-0.00121322
max:0.402532  min:-0.373453
new--cpu_data-0.0012132
comput--weight-0.375
max:0.415377  min:-0.28466
new--cpu_data-0.0111222
comput--weight-0.3125
max:0.512163  min:-0.185146
new--cpu_data-0.00052685
comput--weight-0.1875
max:0.353312  min:-0.142415
new--cpu_data0.00378189
comput--weight-0.125
max:0.314707  min:-0.132586
new--cpu_data-0.0134459
comput--weight-0.125
fc_max:0.0484157  fc_min:-0.0351521
new--fc_cpu_data0.00639642
comput--fc_weight-0.03125
fc_max:0.0521176  fc_min:-0.0320784
new--fc_cpu_data0.0125172
comput--fc_weight-0.03125
fc_max:0.0673797  fc_min:-0.0446439
new--fc_cpu_data0.000160549
comput--fc_weight-0.046875
BP--weight-0.0134459
BP--weight0.00378189
BP--weight-0.00052685
BP--weight-0.0111222
BP--weight-0.0012132
max:0.402526  min:-0.373447
new--cpu_data-0.00121318
comput--weight-0.375
max:0.415371  min:-0.284656
new--cpu_data-0.0111221
comput--weight-0.3125
max:0.512156  min:-0.185143
new--cpu_data-0.000526842
comput--weight-0.1875
max:0.353307  min:-0.142413
new--cpu_data0.00378184
comput--weight-0.125
max:0.314702  min:-0.132584
new--cpu_data-0.0134457
comput--weight-0.125
fc_max:0.048415  fc_min:-0.0351516
new--fc_cpu_data0.00639633
comput--fc_weight-0.03125
fc_max:0.0521169  fc_min:-0.0320779
new--fc_cpu_data0.012517
comput--fc_weight-0.03125
fc_max:0.0673787  fc_min:-0.0446432
new--fc_cpu_data0.000160547
comput--fc_weight-0.046875
BP--weight-0.0134457
BP--weight0.00378184
BP--weight-0.000526842
BP--weight-0.0111221
BP--weight-0.00121318
max:0.40252  min:-0.373442
new--cpu_data-0.00121316
comput--weight-0.375
max:0.415365  min:-0.284652
new--cpu_data-0.0111219
comput--weight-0.3125
max:0.512148  min:-0.18514
new--cpu_data-0.000526835
comput--weight-0.1875
max:0.353301  min:-0.14241
new--cpu_data0.00378178
comput--weight-0.125
max:0.314698  min:-0.132582
new--cpu_data-0.0134455
comput--weight-0.125
fc_max:0.0484143  fc_min:-0.0351511
new--fc_cpu_data0.00639624
comput--fc_weight-0.03125
fc_max:0.0521161  fc_min:-0.0320774
new--fc_cpu_data0.0125168
comput--fc_weight-0.03125
fc_max:0.0673778  fc_min:-0.0446426
new--fc_cpu_data0.000160545
comput--fc_weight-0.046875
BP--weight-0.0134455
BP--weight0.00378178
BP--weight-0.000526835
BP--weight-0.0111219
BP--weight-0.00121316
max:0.402514  min:-0.373436
new--cpu_data-0.00121315
comput--weight-0.375
max:0.415359  min:-0.284648
new--cpu_data-0.0111218
comput--weight-0.3125
max:0.512141  min:-0.185138
new--cpu_data-0.000526827
comput--weight-0.1875
max:0.353296  min:-0.142408
new--cpu_data0.00378173
comput--weight-0.125
max:0.314693  min:-0.13258
new--cpu_data-0.0134453
comput--weight-0.125
fc_max:0.0484136  fc_min:-0.0351506
new--fc_cpu_data0.00639614
comput--fc_weight-0.03125
fc_max:0.0521154  fc_min:-0.032077
new--fc_cpu_data0.0125166
comput--fc_weight-0.03125
fc_max:0.0673768  fc_min:-0.0446419
new--fc_cpu_data0.000160543
comput--fc_weight-0.046875
BP--weight-0.0134453
BP--weight0.00378173
BP--weight-0.000526827
BP--weight-0.0111218
BP--weight-0.00121315
max:0.402509  min:-0.373431
new--cpu_data-0.00121313
comput--weight-0.375
max:0.415353  min:-0.284643
new--cpu_data-0.0111216
comput--weight-0.3125
max:0.512133  min:-0.185135
new--cpu_data-0.000526819
comput--weight-0.1875
max:0.353291  min:-0.142406
new--cpu_data0.00378167
comput--weight-0.125
max:0.314689  min:-0.132578
new--cpu_data-0.0134451
comput--weight-0.125
fc_max:0.0484129  fc_min:-0.0351501
new--fc_cpu_data0.00639605
comput--fc_weight-0.03125
fc_max:0.0521146  fc_min:-0.0320765
new--fc_cpu_data0.0125165
comput--fc_weight-0.03125
fc_max:0.0673758  fc_min:-0.0446413
new--fc_cpu_data0.00016054
comput--fc_weight-0.046875
BP--weight-0.0134451
BP--weight0.00378167
BP--weight-0.000526819
BP--weight-0.0111216
BP--weight-0.00121313
max:0.402503  min:-0.373425
new--cpu_data-0.00121311
comput--weight-0.375
max:0.415347  min:-0.284639
new--cpu_data-0.0111214
comput--weight-0.3125
max:0.512126  min:-0.185132
new--cpu_data-0.000526812
comput--weight-0.1875
max:0.353286  min:-0.142404
new--cpu_data0.00378162
comput--weight-0.125
max:0.314684  min:-0.132576
new--cpu_data-0.0134449
comput--weight-0.125
fc_max:0.0484122  fc_min:-0.0351496
new--fc_cpu_data0.00639596
comput--fc_weight-0.03125
fc_max:0.0521139  fc_min:-0.032076
new--fc_cpu_data0.0125163
comput--fc_weight-0.03125
fc_max:0.0673748  fc_min:-0.0446406
new--fc_cpu_data0.000160538
comput--fc_weight-0.046875
BP--weight-0.0134449
BP--weight0.00378162
BP--weight-0.000526812
BP--weight-0.0111214
BP--weight-0.00121311
max:0.402497  min:-0.37342
new--cpu_data-0.00121309
comput--weight-0.375
max:0.415341  min:-0.284635
new--cpu_data-0.0111213
comput--weight-0.3125
max:0.512118  min:-0.185129
new--cpu_data-0.000526804
comput--weight-0.1875
max:0.353281  min:-0.142402
new--cpu_data0.00378156
comput--weight-0.125
max:0.314679  min:-0.132574
new--cpu_data-0.0134447
comput--weight-0.125
fc_max:0.0484115  fc_min:-0.0351491
new--fc_cpu_data0.00639586
comput--fc_weight-0.03125
fc_max:0.0521131  fc_min:-0.0320756
new--fc_cpu_data0.0125161
comput--fc_weight-0.03125
fc_max:0.0673738  fc_min:-0.04464
new--fc_cpu_data0.000160535
comput--fc_weight-0.046875
BP--weight-0.0134447
BP--weight0.00378156
BP--weight-0.000526804
BP--weight-0.0111213
BP--weight-0.00121309
max:0.402491  min:-0.373414
new--cpu_data-0.00121307
comput--weight-0.375
max:0.415335  min:-0.284631
new--cpu_data-0.0111211
comput--weight-0.3125
max:0.512111  min:-0.185127
new--cpu_data-0.000526796
comput--weight-0.1875
max:0.353276  min:-0.1424
new--cpu_data0.00378151
comput--weight-0.125
max:0.314675  min:-0.132572
new--cpu_data-0.0134445
comput--weight-0.125
fc_max:0.0484108  fc_min:-0.0351486
new--fc_cpu_data0.00639577
comput--fc_weight-0.03125
fc_max:0.0521123  fc_min:-0.0320751
new--fc_cpu_data0.0125159
comput--fc_weight-0.03125
fc_max:0.0673728  fc_min:-0.0446393
new--fc_cpu_data0.000160533
comput--fc_weight-0.046875
BP--weight-0.0134445
BP--weight0.00378151
BP--weight-0.000526796
BP--weight-0.0111211
BP--weight-0.00121307
max:0.402485  min:-0.373409
new--cpu_data-0.00121306
comput--weight-0.375
max:0.415328  min:-0.284627
new--cpu_data-0.0111209
comput--weight-0.3125
max:0.512103  min:-0.185124
new--cpu_data-0.000526788
comput--weight-0.1875
max:0.35327  min:-0.142398
new--cpu_data0.00378145
comput--weight-0.125
max:0.31467  min:-0.13257
new--cpu_data-0.0134443
comput--weight-0.125
fc_max:0.04841  fc_min:-0.035148
new--fc_cpu_data0.00639568
comput--fc_weight-0.03125
fc_max:0.0521116  fc_min:-0.0320746
new--fc_cpu_data0.0125157
comput--fc_weight-0.03125
fc_max:0.0673718  fc_min:-0.0446387
new--fc_cpu_data0.000160531
comput--fc_weight-0.046875
BP--weight-0.0134443
BP--weight0.00378145
BP--weight-0.000526788
BP--weight-0.0111209
BP--weight-0.00121306
max:0.402479  min:-0.373403
new--cpu_data-0.00121304
comput--weight-0.375
max:0.415322  min:-0.284622
new--cpu_data-0.0111208
comput--weight-0.3125
max:0.512096  min:-0.185121
new--cpu_data-0.000526781
comput--weight-0.1875
max:0.353265  min:-0.142396
new--cpu_data0.0037814
comput--weight-0.125
max:0.314665  min:-0.132568
new--cpu_data-0.0134441
comput--weight-0.125
fc_max:0.0484093  fc_min:-0.0351475
new--fc_cpu_data0.00639558
comput--fc_weight-0.03125
fc_max:0.0521108  fc_min:-0.0320741
new--fc_cpu_data0.0125155
comput--fc_weight-0.03125
fc_max:0.0673708  fc_min:-0.044638
new--fc_cpu_data0.000160528
comput--fc_weight-0.046875
BP--weight-0.0134441
BP--weight0.0037814
BP--weight-0.000526781
BP--weight-0.0111208
BP--weight-0.00121304
max:0.402473  min:-0.373398
new--cpu_data-0.00121302
comput--weight-0.375
max:0.415316  min:-0.284618
new--cpu_data-0.0111206
comput--weight-0.3125
max:0.512088  min:-0.185118
new--cpu_data-0.000526773
comput--weight-0.1875
max:0.35326  min:-0.142394
new--cpu_data0.00378134
comput--weight-0.125
max:0.314661  min:-0.132567
new--cpu_data-0.0134439
comput--weight-0.125
fc_max:0.0484086  fc_min:-0.035147
new--fc_cpu_data0.00639549
comput--fc_weight-0.03125
fc_max:0.05211  fc_min:-0.0320737
new--fc_cpu_data0.0125153
comput--fc_weight-0.03125
fc_max:0.0673698  fc_min:-0.0446373
new--fc_cpu_data0.000160526
comput--fc_weight-0.046875
BP--weight-0.0134439
BP--weight0.00378134
BP--weight-0.000526773
BP--weight-0.0111206
BP--weight-0.00121302
I1221 10:00:35.917551 23235 solver.cpp:218] Iteration 40 (0.041814 iter/s, 478.309s/20 iters), loss = 39.0391
I1221 10:00:35.917816 23235 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1221 10:00:35.917834 23235 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1221 10:00:35.917852 23235 solver.cpp:238]     Train net output #2: loss = 39.0391 (* 1 = 39.0391 loss)
I1221 10:00:35.929412 23235 sgd_solver.cpp:105] Iteration 40, lr = 0.003
max:0.402467  min:-0.373392
new--cpu_data-0.001213
comput--weight-0.375
max:0.41531  min:-0.284614
new--cpu_data-0.0111205
comput--weight-0.3125
max:0.51208  min:-0.185116
new--cpu_data-0.000526765
comput--weight-0.1875
max:0.353255  min:-0.142392
new--cpu_data0.00378128
comput--weight-0.125
max:0.314656  min:-0.132565
new--cpu_data-0.0134437
comput--weight-0.125
fc_max:0.0484079  fc_min:-0.0351465
new--fc_cpu_data0.00639539
comput--fc_weight-0.03125
fc_max:0.0521092  fc_min:-0.0320732
new--fc_cpu_data0.0125152
comput--fc_weight-0.03125
fc_max:0.0673689  fc_min:-0.0446367
new--fc_cpu_data0.000160524
comput--fc_weight-0.046875
BP--weight-0.0134437
BP--weight0.00378128
BP--weight-0.000526765
BP--weight-0.0111205
BP--weight-0.001213
max:0.402461  min:-0.373387
new--cpu_data-0.00121298
comput--weight-0.375
max:0.415304  min:-0.28461
new--cpu_data-0.0111203
comput--weight-0.3125
max:0.512073  min:-0.185113
new--cpu_data-0.000526757
comput--weight-0.1875
max:0.35325  min:-0.14239
new--cpu_data0.00378123
comput--weight-0.125
max:0.314652  min:-0.132563
new--cpu_data-0.0134435
comput--weight-0.125
fc_max:0.0484072  fc_min:-0.035146
new--fc_cpu_data0.0063953
comput--fc_weight-0.03125
fc_max:0.0521085  fc_min:-0.0320727
new--fc_cpu_data0.012515
comput--fc_weight-0.03125
fc_max:0.0673679  fc_min:-0.044636
new--fc_cpu_data0.000160521
comput--fc_weight-0.046875
BP--weight-0.0134435
BP--weight0.00378123
BP--weight-0.000526757
BP--weight-0.0111203
BP--weight-0.00121298
max:0.402455  min:-0.373381
new--cpu_data-0.00121297
comput--weight-0.375
max:0.415298  min:-0.284606
new--cpu_data-0.0111201
comput--weight-0.3125
max:0.512065  min:-0.18511
new--cpu_data-0.000526749
comput--weight-0.1875
max:0.353244  min:-0.142387
new--cpu_data0.00378117
comput--weight-0.125
max:0.314647  min:-0.132561
new--cpu_data-0.0134433
comput--weight-0.125
fc_max:0.0484065  fc_min:-0.0351454
new--fc_cpu_data0.0063952
comput--fc_weight-0.03125
fc_max:0.0521077  fc_min:-0.0320722
new--fc_cpu_data0.0125148
comput--fc_weight-0.03125
fc_max:0.0673669  fc_min:-0.0446354
new--fc_cpu_data0.000160519
comput--fc_weight-0.046875
BP--weight-0.0134433
BP--weight0.00378117
BP--weight-0.000526749
BP--weight-0.0111201
BP--weight-0.00121297
max:0.402449  min:-0.373376
new--cpu_data-0.00121295
comput--weight-0.375
max:0.415292  min:-0.284601
new--cpu_data-0.01112
comput--weight-0.3125
max:0.512058  min:-0.185107
new--cpu_data-0.000526742
comput--weight-0.1875
max:0.353239  min:-0.142385
new--cpu_data0.00378112
comput--weight-0.125
max:0.314642  min:-0.132559
new--cpu_data-0.0134431
comput--weight-0.125
fc_max:0.0484057  fc_min:-0.0351449
new--fc_cpu_data0.00639511
comput--fc_weight-0.03125
fc_max:0.0521069  fc_min:-0.0320718
new--fc_cpu_data0.0125146
comput--fc_weight-0.03125
fc_max:0.0673659  fc_min:-0.0446347
new--fc_cpu_data0.000160516
comput--fc_weight-0.046875
BP--weight-0.0134431
BP--weight0.00378112
BP--weight-0.000526742
BP--weight-0.01112
BP--weight-0.00121295
max:0.402443  min:-0.37337
new--cpu_data-0.00121293
comput--weight-0.375
max:0.415285  min:-0.284597
new--cpu_data-0.0111198
comput--weight-0.3125
max:0.51205  min:-0.185105
new--cpu_data-0.000526734
comput--weight-0.1875
max:0.353234  min:-0.142383
new--cpu_data0.00378106
comput--weight-0.125
max:0.314638  min:-0.132557
new--cpu_data-0.0134429
comput--weight-0.125
fc_max:0.048405  fc_min:-0.0351444
new--fc_cpu_data0.00639501
comput--fc_weight-0.03125
fc_max:0.0521061  fc_min:-0.0320713
new--fc_cpu_data0.0125144
comput--fc_weight-0.03125
fc_max:0.0673649  fc_min:-0.044634
new--fc_cpu_data0.000160514
comput--fc_weight-0.046875
BP--weight-0.0134429
BP--weight0.00378106
BP--weight-0.000526734
BP--weight-0.0111198
BP--weight-0.00121293
max:0.402437  min:-0.373365
new--cpu_data-0.00121291
comput--weight-0.375
max:0.415279  min:-0.284593
new--cpu_data-0.0111196
comput--weight-0.3125
max:0.512042  min:-0.185102
new--cpu_data-0.000526726
comput--weight-0.1875
max:0.353229  min:-0.142381
new--cpu_data0.003781
comput--weight-0.125
max:0.314633  min:-0.132555
new--cpu_data-0.0134427
comput--weight-0.125
fc_max:0.0484043  fc_min:-0.0351439
new--fc_cpu_data0.00639492
comput--fc_weight-0.03125
fc_max:0.0521054  fc_min:-0.0320708
new--fc_cpu_data0.0125142
comput--fc_weight-0.03125
fc_max:0.0673639  fc_min:-0.0446334
new--fc_cpu_data0.000160512
comput--fc_weight-0.046875
BP--weight-0.0134427
BP--weight0.003781
BP--weight-0.000526726
BP--weight-0.0111196
BP--weight-0.00121291
max:0.402431  min:-0.373359
new--cpu_data-0.00121289
comput--weight-0.375
max:0.415273  min:-0.284589
new--cpu_data-0.0111195
comput--weight-0.3125
max:0.512035  min:-0.185099
new--cpu_data-0.000526718
comput--weight-0.1875
max:0.353223  min:-0.142379
new--cpu_data0.00378095
comput--weight-0.125
max:0.314628  min:-0.132553
new--cpu_data-0.0134425
comput--weight-0.125
fc_max:0.0484036  fc_min:-0.0351433
new--fc_cpu_data0.00639482
comput--fc_weight-0.03125
fc_max:0.0521046  fc_min:-0.0320703
new--fc_cpu_data0.012514
comput--fc_weight-0.03125
fc_max:0.0673628  fc_min:-0.0446327
new--fc_cpu_data0.000160509
comput--fc_weight-0.046875
BP--weight-0.0134425
BP--weight0.00378095
BP--weight-0.000526718
BP--weight-0.0111195
BP--weight-0.00121289
max:0.402425  min:-0.373353
new--cpu_data-0.00121288
comput--weight-0.375
max:0.415267  min:-0.284584
new--cpu_data-0.0111193
comput--weight-0.3125
max:0.512027  min:-0.185096
new--cpu_data-0.00052671
comput--weight-0.1875
max:0.353218  min:-0.142377
new--cpu_data0.00378089
comput--weight-0.125
max:0.314623  min:-0.132551
new--cpu_data-0.0134423
comput--weight-0.125
fc_max:0.0484029  fc_min:-0.0351428
new--fc_cpu_data0.00639473
comput--fc_weight-0.03125
fc_max:0.0521038  fc_min:-0.0320698
new--fc_cpu_data0.0125139
comput--fc_weight-0.03125
fc_max:0.0673618  fc_min:-0.044632
new--fc_cpu_data0.000160507
comput--fc_weight-0.046875
BP--weight-0.0134423
BP--weight0.00378089
BP--weight-0.00052671
BP--weight-0.0111193
BP--weight-0.00121288
max:0.402419  min:-0.373348
new--cpu_data-0.00121286
comput--weight-0.375
max:0.415261  min:-0.28458
new--cpu_data-0.0111191
comput--weight-0.3125
max:0.51202  min:-0.185094
new--cpu_data-0.000526702
comput--weight-0.1875
max:0.353213  min:-0.142375
new--cpu_data0.00378083
comput--weight-0.125
max:0.314619  min:-0.132549
new--cpu_data-0.0134421
comput--weight-0.125
fc_max:0.0484021  fc_min:-0.0351423
new--fc_cpu_data0.00639463
comput--fc_weight-0.03125
fc_max:0.052103  fc_min:-0.0320694
new--fc_cpu_data0.0125137
comput--fc_weight-0.03125
fc_max:0.0673608  fc_min:-0.0446314
new--fc_cpu_data0.000160505
comput--fc_weight-0.046875
BP--weight-0.0134421
BP--weight0.00378083
BP--weight-0.000526702
BP--weight-0.0111191
BP--weight-0.00121286
max:0.402413  min:-0.373342
new--cpu_data-0.00121284
comput--weight-0.375
max:0.415254  min:-0.284576
new--cpu_data-0.011119
comput--weight-0.3125
max:0.512012  min:-0.185091
new--cpu_data-0.000526694
comput--weight-0.1875
max:0.353207  min:-0.142373
new--cpu_data0.00378078
comput--weight-0.125
max:0.314614  min:-0.132547
new--cpu_data-0.0134419
comput--weight-0.125
fc_max:0.0484014  fc_min:-0.0351418
new--fc_cpu_data0.00639454
comput--fc_weight-0.03125
fc_max:0.0521023  fc_min:-0.0320689
new--fc_cpu_data0.0125135
comput--fc_weight-0.03125
fc_max:0.0673598  fc_min:-0.0446307
new--fc_cpu_data0.000160502
comput--fc_weight-0.046875
BP--weight-0.0134419
BP--weight0.00378078
BP--weight-0.000526694
BP--weight-0.011119
BP--weight-0.00121284
max:0.402407  min:-0.373337
new--cpu_data-0.00121282
comput--weight-0.375
max:0.415248  min:-0.284572
new--cpu_data-0.0111188
comput--weight-0.3125
max:0.512004  min:-0.185088
new--cpu_data-0.000526687
comput--weight-0.1875
max:0.353202  min:-0.14237
new--cpu_data0.00378072
comput--weight-0.125
max:0.314609  min:-0.132545
new--cpu_data-0.0134417
comput--weight-0.125
fc_max:0.0484007  fc_min:-0.0351412
new--fc_cpu_data0.00639444
comput--fc_weight-0.03125
fc_max:0.0521015  fc_min:-0.0320684
new--fc_cpu_data0.0125133
comput--fc_weight-0.03125
fc_max:0.0673588  fc_min:-0.04463
new--fc_cpu_data0.0001605
comput--fc_weight-0.046875
BP--weight-0.0134417
BP--weight0.00378072
BP--weight-0.000526687
BP--weight-0.0111188
BP--weight-0.00121282
max:0.402401  min:-0.373331
new--cpu_data-0.0012128
comput--weight-0.375
max:0.415242  min:-0.284567
new--cpu_data-0.0111186
comput--weight-0.3125
max:0.511997  min:-0.185085
new--cpu_data-0.000526679
comput--weight-0.1875
max:0.353197  min:-0.142368
new--cpu_data0.00378067
comput--weight-0.125
max:0.314605  min:-0.132543
new--cpu_data-0.0134415
comput--weight-0.125
fc_max:0.0484  fc_min:-0.0351407
new--fc_cpu_data0.00639434
comput--fc_weight-0.03125
fc_max:0.0521007  fc_min:-0.0320679
new--fc_cpu_data0.0125131
comput--fc_weight-0.03125
fc_max:0.0673578  fc_min:-0.0446294
new--fc_cpu_data0.000160497
comput--fc_weight-0.046875
BP--weight-0.0134415
BP--weight0.00378067
BP--weight-0.000526679
BP--weight-0.0111186
BP--weight-0.0012128
max:0.402395  min:-0.373326
new--cpu_data-0.00121279
comput--weight-0.375
max:0.415236  min:-0.284563
new--cpu_data-0.0111185
comput--weight-0.3125
max:0.511989  min:-0.185083
new--cpu_data-0.000526671
comput--weight-0.1875
max:0.353192  min:-0.142366
new--cpu_data0.00378061
comput--weight-0.125
max:0.3146  min:-0.132541
new--cpu_data-0.0134413
comput--weight-0.125
fc_max:0.0483992  fc_min:-0.0351402
new--fc_cpu_data0.00639425
comput--fc_weight-0.03125
fc_max:0.0520999  fc_min:-0.0320675
new--fc_cpu_data0.0125129
comput--fc_weight-0.03125
fc_max:0.0673568  fc_min:-0.0446287
new--fc_cpu_data0.000160495
comput--fc_weight-0.046875
BP--weight-0.0134413
BP--weight0.00378061
BP--weight-0.000526671
BP--weight-0.0111185
BP--weight-0.00121279
max:0.402389  min:-0.37332
new--cpu_data-0.00121277
comput--weight-0.375
max:0.41523  min:-0.284559
new--cpu_data-0.0111183
comput--weight-0.3125
max:0.511981  min:-0.18508
new--cpu_data-0.000526663
comput--weight-0.1875
max:0.353186  min:-0.142364
new--cpu_data0.00378055
comput--weight-0.125
max:0.314595  min:-0.132539
new--cpu_data-0.0134411
comput--weight-0.125
fc_max:0.0483985  fc_min:-0.0351397
new--fc_cpu_data0.00639415
comput--fc_weight-0.03125
fc_max:0.0520992  fc_min:-0.032067
new--fc_cpu_data0.0125127
comput--fc_weight-0.03125
fc_max:0.0673558  fc_min:-0.044628
new--fc_cpu_data0.000160493
comput--fc_weight-0.046875
BP--weight-0.0134411
BP--weight0.00378055
BP--weight-0.000526663
BP--weight-0.0111183
BP--weight-0.00121277
max:0.402383  min:-0.373314
new--cpu_data-0.00121275
comput--weight-0.375
max:0.415223  min:-0.284555
new--cpu_data-0.0111181
comput--weight-0.3125
max:0.511974  min:-0.185077
new--cpu_data-0.000526655
comput--weight-0.1875
max:0.353181  min:-0.142362
new--cpu_data0.0037805
comput--weight-0.125
max:0.314591  min:-0.132537
new--cpu_data-0.0134409
comput--weight-0.125
fc_max:0.0483978  fc_min:-0.0351391
new--fc_cpu_data0.00639406
comput--fc_weight-0.03125
fc_max:0.0520984  fc_min:-0.0320665
new--fc_cpu_data0.0125125
comput--fc_weight-0.03125
fc_max:0.0673548  fc_min:-0.0446274
new--fc_cpu_data0.00016049
comput--fc_weight-0.046875
BP--weight-0.0134409
BP--weight0.0037805
BP--weight-0.000526655
BP--weight-0.0111181
BP--weight-0.00121275
max:0.402377  min:-0.373309
new--cpu_data-0.00121273
comput--weight-0.375
max:0.415217  min:-0.28455
new--cpu_data-0.011118
comput--weight-0.3125
max:0.511966  min:-0.185074
new--cpu_data-0.000526647
comput--weight-0.1875
max:0.353176  min:-0.14236
new--cpu_data0.00378044
comput--weight-0.125
max:0.314586  min:-0.132535
new--cpu_data-0.0134407
comput--weight-0.125
fc_max:0.0483971  fc_min:-0.0351386
new--fc_cpu_data0.00639396
comput--fc_weight-0.03125
fc_max:0.0520976  fc_min:-0.032066
new--fc_cpu_data0.0125124
comput--fc_weight-0.03125
fc_max:0.0673538  fc_min:-0.0446267
new--fc_cpu_data0.000160488
comput--fc_weight-0.046875
BP--weight-0.0134407
BP--weight0.00378044
BP--weight-0.000526647
BP--weight-0.011118
BP--weight-0.00121273
max:0.402371  min:-0.373303
new--cpu_data-0.00121271
comput--weight-0.375
max:0.415211  min:-0.284546
new--cpu_data-0.0111178
comput--weight-0.3125
max:0.511958  min:-0.185072
new--cpu_data-0.000526639
comput--weight-0.1875
max:0.353171  min:-0.142358
new--cpu_data0.00378038
comput--weight-0.125
max:0.314581  min:-0.132533
new--cpu_data-0.0134405
comput--weight-0.125
fc_max:0.0483964  fc_min:-0.0351381
new--fc_cpu_data0.00639387
comput--fc_weight-0.03125
fc_max:0.0520968  fc_min:-0.0320655
new--fc_cpu_data0.0125122
comput--fc_weight-0.03125
fc_max:0.0673528  fc_min:-0.044626
new--fc_cpu_data0.000160485
comput--fc_weight-0.046875
BP--weight-0.0134405
BP--weight0.00378038
BP--weight-0.000526639
BP--weight-0.0111178
BP--weight-0.00121271
max:0.402365  min:-0.373298
new--cpu_data-0.00121269
comput--weight-0.375
max:0.415205  min:-0.284542
new--cpu_data-0.0111176
comput--weight-0.3125
max:0.511951  min:-0.185069
new--cpu_data-0.000526632
comput--weight-0.1875
max:0.353165  min:-0.142356
new--cpu_data0.00378033
comput--weight-0.125
max:0.314576  min:-0.132531
new--cpu_data-0.0134403
comput--weight-0.125
fc_max:0.0483956  fc_min:-0.0351376
new--fc_cpu_data0.00639377
comput--fc_weight-0.03125
fc_max:0.052096  fc_min:-0.032065
new--fc_cpu_data0.012512
comput--fc_weight-0.03125
fc_max:0.0673518  fc_min:-0.0446254
new--fc_cpu_data0.000160483
comput--fc_weight-0.046875
BP--weight-0.0134403
BP--weight0.00378033
BP--weight-0.000526632
BP--weight-0.0111176
BP--weight-0.00121269
max:0.402359  min:-0.373292
new--cpu_data-0.00121268
comput--weight-0.375
max:0.415199  min:-0.284538
new--cpu_data-0.0111175
comput--weight-0.3125
max:0.511943  min:-0.185066
new--cpu_data-0.000526624
comput--weight-0.1875
max:0.35316  min:-0.142353
new--cpu_data0.00378027
comput--weight-0.125
max:0.314572  min:-0.132529
new--cpu_data-0.0134401
comput--weight-0.125
fc_max:0.0483949  fc_min:-0.035137
new--fc_cpu_data0.00639368
comput--fc_weight-0.03125
fc_max:0.0520953  fc_min:-0.0320646
new--fc_cpu_data0.0125118
comput--fc_weight-0.03125
fc_max:0.0673508  fc_min:-0.0446247
new--fc_cpu_data0.000160481
comput--fc_weight-0.046875
BP--weight-0.0134401
BP--weight0.00378027
BP--weight-0.000526624
BP--weight-0.0111175
BP--weight-0.00121268
max:0.402353  min:-0.373287
new--cpu_data-0.00121266
comput--weight-0.375
max:0.415192  min:-0.284533
new--cpu_data-0.0111173
comput--weight-0.3125
max:0.511935  min:-0.185063
new--cpu_data-0.000526616
comput--weight-0.1875
max:0.353155  min:-0.142351
new--cpu_data0.00378021
comput--weight-0.125
max:0.314567  min:-0.132527
new--cpu_data-0.0134399
comput--weight-0.125
fc_max:0.0483942  fc_min:-0.0351365
new--fc_cpu_data0.00639358
comput--fc_weight-0.03125
fc_max:0.0520945  fc_min:-0.0320641
new--fc_cpu_data0.0125116
comput--fc_weight-0.03125
fc_max:0.0673498  fc_min:-0.044624
new--fc_cpu_data0.000160478
comput--fc_weight-0.046875
BP--weight-0.0134399
BP--weight0.00378021
BP--weight-0.000526616
BP--weight-0.0111173
BP--weight-0.00121266
I1221 10:08:33.154103 23235 solver.cpp:218] Iteration 60 (0.041908 iter/s, 477.236s/20 iters), loss = 39.1328
I1221 10:08:33.154388 23235 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1221 10:08:33.154428 23235 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1221 10:08:33.154459 23235 solver.cpp:238]     Train net output #2: loss = 39.1328 (* 1 = 39.1328 loss)
I1221 10:08:33.165138 23235 sgd_solver.cpp:105] Iteration 60, lr = 0.003
max:0.402347  min:-0.373281
new--cpu_data-0.00121264
comput--weight-0.375
max:0.415186  min:-0.284529
new--cpu_data-0.0111171
comput--weight-0.3125
max:0.511928  min:-0.18506
new--cpu_data-0.000526608
comput--weight-0.1875
max:0.353149  min:-0.142349
new--cpu_data0.00378016
comput--weight-0.125
max:0.314562  min:-0.132525
new--cpu_data-0.0134397
comput--weight-0.125
fc_max:0.0483935  fc_min:-0.035136
new--fc_cpu_data0.00639348
comput--fc_weight-0.03125
fc_max:0.0520937  fc_min:-0.0320636
new--fc_cpu_data0.0125114
comput--fc_weight-0.03125
fc_max:0.0673488  fc_min:-0.0446234
new--fc_cpu_data0.000160476
comput--fc_weight-0.046875
BP--weight-0.0134397
BP--weight0.00378016
BP--weight-0.000526608
BP--weight-0.0111171
BP--weight-0.00121264
max:0.402341  min:-0.373275
new--cpu_data-0.00121262
comput--weight-0.375
max:0.41518  min:-0.284525
new--cpu_data-0.011117
comput--weight-0.3125
max:0.51192  min:-0.185058
new--cpu_data-0.0005266
comput--weight-0.1875
max:0.353144  min:-0.142347
new--cpu_data0.0037801
comput--weight-0.125
max:0.314558  min:-0.132523
new--cpu_data-0.0134395
comput--weight-0.125
fc_max:0.0483927  fc_min:-0.0351355
new--fc_cpu_data0.00639339
comput--fc_weight-0.03125
fc_max:0.0520929  fc_min:-0.0320631
new--fc_cpu_data0.0125112
comput--fc_weight-0.03125
fc_max:0.0673478  fc_min:-0.0446227
new--fc_cpu_data0.000160473
comput--fc_weight-0.046875
BP--weight-0.0134395
BP--weight0.0037801
BP--weight-0.0005266
BP--weight-0.011117
BP--weight-0.00121262
max:0.402335  min:-0.37327
new--cpu_data-0.0012126
comput--weight-0.375
max:0.415174  min:-0.284521
new--cpu_data-0.0111168
comput--weight-0.3125
max:0.511912  min:-0.185055
new--cpu_data-0.000526592
comput--weight-0.1875
max:0.353139  min:-0.142345
new--cpu_data0.00378004
comput--weight-0.125
max:0.314553  min:-0.132521
new--cpu_data-0.0134393
comput--weight-0.125
fc_max:0.048392  fc_min:-0.0351349
new--fc_cpu_data0.00639329
comput--fc_weight-0.03125
fc_max:0.0520921  fc_min:-0.0320626
new--fc_cpu_data0.0125111
comput--fc_weight-0.03125
fc_max:0.0673468  fc_min:-0.044622
new--fc_cpu_data0.000160471
comput--fc_weight-0.046875
BP--weight-0.0134393
BP--weight0.00378004
BP--weight-0.000526592
BP--weight-0.0111168
BP--weight-0.0012126
max:0.402329  min:-0.373264
new--cpu_data-0.00121259
comput--weight-0.375
max:0.415167  min:-0.284516
new--cpu_data-0.0111166
comput--weight-0.3125
max:0.511905  min:-0.185052
new--cpu_data-0.000526584
comput--weight-0.1875
max:0.353134  min:-0.142343
new--cpu_data0.00377999
comput--weight-0.125
max:0.314548  min:-0.132519
new--cpu_data-0.0134391
comput--weight-0.125
fc_max:0.0483913  fc_min:-0.0351344
new--fc_cpu_data0.0063932
comput--fc_weight-0.03125
fc_max:0.0520914  fc_min:-0.0320622
new--fc_cpu_data0.0125109
comput--fc_weight-0.03125
fc_max:0.0673457  fc_min:-0.0446214
new--fc_cpu_data0.000160469
comput--fc_weight-0.046875
BP--weight-0.0134391
BP--weight0.00377999
BP--weight-0.000526584
BP--weight-0.0111166
BP--weight-0.00121259
max:0.402323  min:-0.373259
new--cpu_data-0.00121257
comput--weight-0.375
max:0.415161  min:-0.284512
new--cpu_data-0.0111165
comput--weight-0.3125
max:0.511897  min:-0.185049
new--cpu_data-0.000526576
comput--weight-0.1875
max:0.353128  min:-0.142341
new--cpu_data0.00377993
comput--weight-0.125
max:0.314543  min:-0.132517
new--cpu_data-0.0134389
comput--weight-0.125
fc_max:0.0483905  fc_min:-0.0351339
new--fc_cpu_data0.0063931
comput--fc_weight-0.03125
fc_max:0.0520906  fc_min:-0.0320617
new--fc_cpu_data0.0125107
comput--fc_weight-0.03125
fc_max:0.0673447  fc_min:-0.0446207
new--fc_cpu_data0.000160466
comput--fc_weight-0.046875
BP--weight-0.0134389
BP--weight0.00377993
BP--weight-0.000526576
BP--weight-0.0111165
BP--weight-0.00121257
max:0.402317  min:-0.373253
new--cpu_data-0.00121255
comput--weight-0.375
max:0.415155  min:-0.284508
new--cpu_data-0.0111163
comput--weight-0.3125
max:0.511889  min:-0.185047
new--cpu_data-0.000526568
comput--weight-0.1875
max:0.353123  min:-0.142338
new--cpu_data0.00377987
comput--weight-0.125
max:0.314539  min:-0.132515
new--cpu_data-0.0134387
comput--weight-0.125
fc_max:0.0483898  fc_min:-0.0351334
new--fc_cpu_data0.006393
comput--fc_weight-0.03125
fc_max:0.0520898  fc_min:-0.0320612
new--fc_cpu_data0.0125105
comput--fc_weight-0.03125
fc_max:0.0673437  fc_min:-0.04462
new--fc_cpu_data0.000160464
comput--fc_weight-0.046875
BP--weight-0.0134387
BP--weight0.00377987
BP--weight-0.000526568
BP--weight-0.0111163
BP--weight-0.00121255
max:0.402311  min:-0.373247
new--cpu_data-0.00121253
comput--weight-0.375
max:0.415149  min:-0.284504
new--cpu_data-0.0111161
comput--weight-0.3125
max:0.511882  min:-0.185044
new--cpu_data-0.00052656
comput--weight-0.1875
max:0.353118  min:-0.142336
new--cpu_data0.00377982
comput--weight-0.125
max:0.314534  min:-0.132513
new--cpu_data-0.0134385
comput--weight-0.125
fc_max:0.0483891  fc_min:-0.0351328
new--fc_cpu_data0.00639291
comput--fc_weight-0.03125
fc_max:0.052089  fc_min:-0.0320607
new--fc_cpu_data0.0125103
comput--fc_weight-0.03125
fc_max:0.0673427  fc_min:-0.0446194
new--fc_cpu_data0.000160461
comput--fc_weight-0.046875
BP--weight-0.0134385
BP--weight0.00377982
BP--weight-0.00052656
BP--weight-0.0111161
BP--weight-0.00121253
max:0.402305  min:-0.373242
new--cpu_data-0.00121251
comput--weight-0.375
max:0.415142  min:-0.284499
new--cpu_data-0.011116
comput--weight-0.3125
max:0.511874  min:-0.185041
new--cpu_data-0.000526553
comput--weight-0.1875
max:0.353112  min:-0.142334
new--cpu_data0.00377976
comput--weight-0.125
max:0.314529  min:-0.132511
new--cpu_data-0.0134383
comput--weight-0.125
fc_max:0.0483884  fc_min:-0.0351323
new--fc_cpu_data0.00639281
comput--fc_weight-0.03125
fc_max:0.0520882  fc_min:-0.0320602
new--fc_cpu_data0.0125101
comput--fc_weight-0.03125
fc_max:0.0673417  fc_min:-0.0446187
new--fc_cpu_data0.000160459
comput--fc_weight-0.046875
BP--weight-0.0134383
BP--weight0.00377976
BP--weight-0.000526553
BP--weight-0.011116
BP--weight-0.00121251
max:0.402299  min:-0.373236
new--cpu_data-0.0012125
comput--weight-0.375
max:0.415136  min:-0.284495
new--cpu_data-0.0111158
comput--weight-0.3125
max:0.511866  min:-0.185038
new--cpu_data-0.000526545
comput--weight-0.1875
max:0.353107  min:-0.142332
new--cpu_data0.0037797
comput--weight-0.125
max:0.314525  min:-0.132509
new--cpu_data-0.0134381
comput--weight-0.125
fc_max:0.0483876  fc_min:-0.0351318
new--fc_cpu_data0.00639272
comput--fc_weight-0.03125
fc_max:0.0520874  fc_min:-0.0320598
new--fc_cpu_data0.0125099
comput--fc_weight-0.03125
fc_max:0.0673407  fc_min:-0.044618
new--fc_cpu_data0.000160457
comput--fc_weight-0.046875
BP--weight-0.0134381
BP--weight0.0037797
BP--weight-0.000526545
BP--weight-0.0111158
BP--weight-0.0012125
max:0.402293  min:-0.373231
new--cpu_data-0.00121248
comput--weight-0.375
max:0.41513  min:-0.284491
new--cpu_data-0.0111156
comput--weight-0.3125
max:0.511858  min:-0.185036
new--cpu_data-0.000526537
comput--weight-0.1875
max:0.353102  min:-0.14233
new--cpu_data0.00377965
comput--weight-0.125
max:0.31452  min:-0.132507
new--cpu_data-0.0134379
comput--weight-0.125
fc_max:0.0483869  fc_min:-0.0351313
new--fc_cpu_data0.00639262
comput--fc_weight-0.03125
fc_max:0.0520867  fc_min:-0.0320593
new--fc_cpu_data0.0125097
comput--fc_weight-0.03125
fc_max:0.0673397  fc_min:-0.0446173
new--fc_cpu_data0.000160454
comput--fc_weight-0.046875
BP--weight-0.0134379
BP--weight0.00377965
BP--weight-0.000526537
BP--weight-0.0111156
BP--weight-0.00121248
max:0.402287  min:-0.373225
new--cpu_data-0.00121246
comput--weight-0.375
max:0.415124  min:-0.284486
new--cpu_data-0.0111155
comput--weight-0.3125
max:0.511851  min:-0.185033
new--cpu_data-0.000526529
comput--weight-0.1875
max:0.353096  min:-0.142328
new--cpu_data0.00377959
comput--weight-0.125
max:0.314515  min:-0.132505
new--cpu_data-0.0134377
comput--weight-0.125
fc_max:0.0483862  fc_min:-0.0351307
new--fc_cpu_data0.00639252
comput--fc_weight-0.03125
fc_max:0.0520859  fc_min:-0.0320588
new--fc_cpu_data0.0125096
comput--fc_weight-0.03125
fc_max:0.0673387  fc_min:-0.0446167
new--fc_cpu_data0.000160452
comput--fc_weight-0.046875
BP--weight-0.0134377
BP--weight0.00377959
BP--weight-0.000526529
BP--weight-0.0111155
BP--weight-0.00121246
max:0.402281  min:-0.373219
new--cpu_data-0.00121244
comput--weight-0.375
max:0.415118  min:-0.284482
new--cpu_data-0.0111153
comput--weight-0.3125
max:0.511843  min:-0.18503
new--cpu_data-0.000526521
comput--weight-0.1875
max:0.353091  min:-0.142326
new--cpu_data0.00377953
comput--weight-0.125
max:0.31451  min:-0.132503
new--cpu_data-0.0134375
comput--weight-0.125
fc_max:0.0483855  fc_min:-0.0351302
new--fc_cpu_data0.00639243
comput--fc_weight-0.03125
fc_max:0.0520851  fc_min:-0.0320583
new--fc_cpu_data0.0125094
comput--fc_weight-0.03125
fc_max:0.0673377  fc_min:-0.044616
new--fc_cpu_data0.000160449
comput--fc_weight-0.046875
BP--weight-0.0134375
BP--weight0.00377953
BP--weight-0.000526521
BP--weight-0.0111153
BP--weight-0.00121244
max:0.402275  min:-0.373214
new--cpu_data-0.00121242
comput--weight-0.375
max:0.415111  min:-0.284478
new--cpu_data-0.0111151
comput--weight-0.3125
max:0.511835  min:-0.185027
new--cpu_data-0.000526513
comput--weight-0.1875
max:0.353086  min:-0.142324
new--cpu_data0.00377948
comput--weight-0.125
max:0.314506  min:-0.132501
new--cpu_data-0.0134373
comput--weight-0.125
fc_max:0.0483847  fc_min:-0.0351297
new--fc_cpu_data0.00639233
comput--fc_weight-0.03125
fc_max:0.0520843  fc_min:-0.0320578
new--fc_cpu_data0.0125092
comput--fc_weight-0.03125
fc_max:0.0673367  fc_min:-0.0446153
new--fc_cpu_data0.000160447
comput--fc_weight-0.046875
BP--weight-0.0134373
BP--weight0.00377948
BP--weight-0.000526513
BP--weight-0.0111151
BP--weight-0.00121242
max:0.402269  min:-0.373208
new--cpu_data-0.0012124
comput--weight-0.375
max:0.415105  min:-0.284474
new--cpu_data-0.011115
comput--weight-0.3125
max:0.511828  min:-0.185024
new--cpu_data-0.000526505
comput--weight-0.1875
max:0.353081  min:-0.142321
new--cpu_data0.00377942
comput--weight-0.125
max:0.314501  min:-0.132499
new--cpu_data-0.0134371
comput--weight-0.125
fc_max:0.048384  fc_min:-0.0351292
new--fc_cpu_data0.00639224
comput--fc_weight-0.03125
fc_max:0.0520835  fc_min:-0.0320574
new--fc_cpu_data0.012509
comput--fc_weight-0.03125
fc_max:0.0673356  fc_min:-0.0446147
new--fc_cpu_data0.000160445
comput--fc_weight-0.046875
BP--weight-0.0134371
BP--weight0.00377942
BP--weight-0.000526505
BP--weight-0.011115
BP--weight-0.0012124
max:0.402263  min:-0.373203
new--cpu_data-0.00121239
comput--weight-0.375
max:0.415099  min:-0.284469
new--cpu_data-0.0111148
comput--weight-0.3125
max:0.51182  min:-0.185022
new--cpu_data-0.000526497
comput--weight-0.1875
max:0.353075  min:-0.142319
new--cpu_data0.00377936
comput--weight-0.125
max:0.314496  min:-0.132497
new--cpu_data-0.0134369
comput--weight-0.125
fc_max:0.0483833  fc_min:-0.0351286
new--fc_cpu_data0.00639214
comput--fc_weight-0.03125
fc_max:0.0520828  fc_min:-0.0320569
new--fc_cpu_data0.0125088
comput--fc_weight-0.03125
fc_max:0.0673346  fc_min:-0.044614
new--fc_cpu_data0.000160442
comput--fc_weight-0.046875
BP--weight-0.0134369
BP--weight0.00377936
BP--weight-0.000526497
BP--weight-0.0111148
BP--weight-0.00121239
max:0.402257  min:-0.373197
new--cpu_data-0.00121237
comput--weight-0.375
max:0.415093  min:-0.284465
new--cpu_data-0.0111146
comput--weight-0.3125
max:0.511812  min:-0.185019
new--cpu_data-0.000526489
comput--weight-0.1875
max:0.35307  min:-0.142317
new--cpu_data0.00377931
comput--weight-0.125
max:0.314492  min:-0.132495
new--cpu_data-0.0134367
comput--weight-0.125
fc_max:0.0483826  fc_min:-0.0351281
new--fc_cpu_data0.00639204
comput--fc_weight-0.03125
fc_max:0.052082  fc_min:-0.0320564
new--fc_cpu_data0.0125086
comput--fc_weight-0.03125
fc_max:0.0673336  fc_min:-0.0446133
new--fc_cpu_data0.00016044
comput--fc_weight-0.046875
BP--weight-0.0134367
BP--weight0.00377931
BP--weight-0.000526489
BP--weight-0.0111146
BP--weight-0.00121237
max:0.402251  min:-0.373191
new--cpu_data-0.00121235
comput--weight-0.375
max:0.415086  min:-0.284461
new--cpu_data-0.0111145
comput--weight-0.3125
max:0.511805  min:-0.185016
new--cpu_data-0.000526481
comput--weight-0.1875
max:0.353065  min:-0.142315
new--cpu_data0.00377925
comput--weight-0.125
max:0.314487  min:-0.132493
new--cpu_data-0.0134365
comput--weight-0.125
fc_max:0.0483818  fc_min:-0.0351276
new--fc_cpu_data0.00639195
comput--fc_weight-0.03125
fc_max:0.0520812  fc_min:-0.0320559
new--fc_cpu_data0.0125084
comput--fc_weight-0.03125
fc_max:0.0673326  fc_min:-0.0446126
new--fc_cpu_data0.000160437
comput--fc_weight-0.046875
BP--weight-0.0134365
BP--weight0.00377925
BP--weight-0.000526481
BP--weight-0.0111145
BP--weight-0.00121235
max:0.402245  min:-0.373186
new--cpu_data-0.00121233
comput--weight-0.375
max:0.41508  min:-0.284457
new--cpu_data-0.0111143
comput--weight-0.3125
max:0.511797  min:-0.185013
new--cpu_data-0.000526473
comput--weight-0.1875
max:0.353059  min:-0.142313
new--cpu_data0.00377919
comput--weight-0.125
max:0.314482  min:-0.132491
new--cpu_data-0.0134363
comput--weight-0.125
fc_max:0.0483811  fc_min:-0.0351271
new--fc_cpu_data0.00639185
comput--fc_weight-0.03125
fc_max:0.0520804  fc_min:-0.0320554
new--fc_cpu_data0.0125082
comput--fc_weight-0.03125
fc_max:0.0673316  fc_min:-0.044612
new--fc_cpu_data0.000160435
comput--fc_weight-0.046875
BP--weight-0.0134363
BP--weight0.00377919
BP--weight-0.000526473
BP--weight-0.0111143
BP--weight-0.00121233
max:0.402239  min:-0.37318
new--cpu_data-0.00121231
comput--weight-0.375
max:0.415074  min:-0.284452
new--cpu_data-0.0111141
comput--weight-0.3125
max:0.511789  min:-0.185011
new--cpu_data-0.000526465
comput--weight-0.1875
max:0.353054  min:-0.142311
new--cpu_data0.00377914
comput--weight-0.125
max:0.314478  min:-0.132489
new--cpu_data-0.0134361
comput--weight-0.125
fc_max:0.0483804  fc_min:-0.0351265
new--fc_cpu_data0.00639176
comput--fc_weight-0.03125
fc_max:0.0520796  fc_min:-0.032055
new--fc_cpu_data0.0125081
comput--fc_weight-0.03125
fc_max:0.0673306  fc_min:-0.0446113
new--fc_cpu_data0.000160433
comput--fc_weight-0.046875
BP--weight-0.0134361
BP--weight0.00377914
BP--weight-0.000526465
BP--weight-0.0111141
BP--weight-0.00121231
max:0.402233  min:-0.373174
new--cpu_data-0.0012123
comput--weight-0.375
max:0.415068  min:-0.284448
new--cpu_data-0.011114
comput--weight-0.3125
max:0.511782  min:-0.185008
new--cpu_data-0.000526458
comput--weight-0.1875
max:0.353049  min:-0.142309
new--cpu_data0.00377908
comput--weight-0.125
max:0.314473  min:-0.132487
new--cpu_data-0.0134359
comput--weight-0.125
fc_max:0.0483797  fc_min:-0.035126
new--fc_cpu_data0.00639166
comput--fc_weight-0.03125
fc_max:0.0520788  fc_min:-0.0320545
new--fc_cpu_data0.0125079
comput--fc_weight-0.03125
fc_max:0.0673296  fc_min:-0.0446106
new--fc_cpu_data0.00016043
comput--fc_weight-0.046875
BP--weight-0.0134359
BP--weight0.00377908
BP--weight-0.000526458
BP--weight-0.011114
BP--weight-0.0012123
I1221 10:16:44.049893 23235 solver.cpp:218] Iteration 80 (0.0407419 iter/s, 490.895s/20 iters), loss = 38.0703
I1221 10:16:44.050191 23235 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1221 10:16:44.050223 23235 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1221 10:16:44.050257 23235 solver.cpp:238]     Train net output #2: loss = 38.0703 (* 1 = 38.0703 loss)
I1221 10:16:44.060961 23235 sgd_solver.cpp:105] Iteration 80, lr = 0.003
max:0.402227  min:-0.373169
new--cpu_data-0.00121228
comput--weight-0.375
max:0.415062  min:-0.284444
new--cpu_data-0.0111138
comput--weight-0.3125
max:0.511774  min:-0.185005
new--cpu_data-0.00052645
comput--weight-0.1875
max:0.353043  min:-0.142307
new--cpu_data0.00377902
comput--weight-0.125
max:0.314468  min:-0.132485
new--cpu_data-0.0134357
comput--weight-0.125
fc_max:0.0483789  fc_min:-0.0351255
new--fc_cpu_data0.00639157
comput--fc_weight-0.03125
fc_max:0.0520781  fc_min:-0.032054
new--fc_cpu_data0.0125077
comput--fc_weight-0.03125
fc_max:0.0673285  fc_min:-0.04461
new--fc_cpu_data0.000160428
comput--fc_weight-0.046875
BP--weight-0.0134357
BP--weight0.00377902
BP--weight-0.00052645
BP--weight-0.0111138
BP--weight-0.00121228
max:0.402221  min:-0.373163
new--cpu_data-0.00121226
comput--weight-0.375
max:0.415055  min:-0.28444
new--cpu_data-0.0111136
comput--weight-0.3125
max:0.511766  min:-0.185002
new--cpu_data-0.000526442
comput--weight-0.1875
max:0.353038  min:-0.142304
new--cpu_data0.00377897
comput--weight-0.125
max:0.314463  min:-0.132483
new--cpu_data-0.0134355
comput--weight-0.125
fc_max:0.0483782  fc_min:-0.035125
new--fc_cpu_data0.00639147
comput--fc_weight-0.03125
fc_max:0.0520773  fc_min:-0.0320535
new--fc_cpu_data0.0125075
comput--fc_weight-0.03125
fc_max:0.0673275  fc_min:-0.0446093
new--fc_cpu_data0.000160425
comput--fc_weight-0.046875
BP--weight-0.0134355
BP--weight0.00377897
BP--weight-0.000526442
BP--weight-0.0111136
BP--weight-0.00121226
max:0.402215  min:-0.373158
new--cpu_data-0.00121224
comput--weight-0.375
max:0.415049  min:-0.284435
new--cpu_data-0.0111135
comput--weight-0.3125
max:0.511759  min:-0.184999
new--cpu_data-0.000526434
comput--weight-0.1875
max:0.353033  min:-0.142302
new--cpu_data0.00377891
comput--weight-0.125
max:0.314459  min:-0.132481
new--cpu_data-0.0134353
comput--weight-0.125
