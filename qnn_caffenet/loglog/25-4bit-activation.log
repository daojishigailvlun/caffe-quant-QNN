ydwu@aries:~/work/QNN-Caffe/caffe$ ./4bit-train.sh 
I1225 16:48:09.885251 61713 caffe.cpp:211] Use CPU.
I1225 16:48:10.427445 61713 solver.cpp:44] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.0001
display: 50
max_iter: 450000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 1000
snapshot_prefix: "qnn_try1/QNN-train"
solver_mode: CPU
net: "qnn_try1/4bit-v1_train_quantized_caffenet.prototxt"
train_state {
  level: 0
  stage: ""
}
I1225 16:48:10.427639 61713 solver.cpp:87] Creating training net from net file: qnn_try1/4bit-v1_train_quantized_caffenet.prototxt
I1225 16:48:10.428560 61713 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1225 16:48:10.428917 61713 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/ydwu/database/imagenet/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/ydwu/database/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_train_lmdb/"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "quantized_data"
  type: "Quantization"
  bottom: "data"
  top: "quantized_data"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -129.93526
    range: 160.78912
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "quantized_data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv1"
  type: "Quantization"
  bottom: "conv1"
  top: "quantized_conv1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -2732.7351
    range: 2531.042
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "quantized_conv1"
  top: "relu1"
}
layer {
  name: "quantized_relu1"
  type: "Quantization"
  bottom: "relu1"
  top: "quantized_relu1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 2531.042
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "quantized_relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool1"
  type: "Quantization"
  bottom: "pool1"
  top: "quantized_pool1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 2531.042
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "quantized_pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "quantized_norm1"
  type: "Quantization"
  bottom: "norm1"
  top: "quantized_norm1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 138.70576
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "quantized_norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv2"
  type: "Quantization"
  bottom: "conv2"
  top: "quantized_conv2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -647.61908
    range: 492.23111
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "quantized_conv2"
  top: "relu2"
}
layer {
  name: "quantized_relu2"
  type: "Quantization"
  bottom: "relu2"
  top: "quantized_relu2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 492.23111
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "quantized_relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool2"
  type: "Quantization"
  bottom: "pool2"
  top: "quantized_pool2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 492.23111
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "quantized_pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "quantized_norm2"
  type: "Quantization"
  bottom: "norm2"
  top: "quantized_norm2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 138.72636
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "quantized_norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv3"
  type: "Quantization"
  bottom: "conv3"
  top: "quantized_conv3"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -389.56516
    range: 331.98178
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "quantized_conv3"
  top: "relu3"
}
layer {
  name: "quantized_relu3"
  type: "Quantization"
  bottom: "relu3"
  top: "quantized_relu3"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 331.98178
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "quantized_relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv4"
  type: "Quantization"
  bottom: "conv4"
  top: "quantized_conv4"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -231.20598
    range: 283.87189
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "quantized_conv4"
  top: "relu4"
}
layer {
  name: "quantized_relu4"
  type: "Quantization"
  bottom: "relu4"
  top: "quantized_relu4"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 283.87189
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "quantized_relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv5"
  type: "Quantization"
  bottom: "conv5"
  top: "quantized_conv5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -172.60567
    range: 272.57315
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "quantized_conv5"
  top: "relu5"
}
layer {
  name: "quantized_relu5"
  type: "Quantization"
  bottom: "relu5"
  top: "quantized_relu5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 272.57315
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "quantized_relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool5"
  type: "Quantization"
  bottom: "pool5"
  top: "quantized_pool5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 272.57315
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "quantized_pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1.05e+13
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "quantized_fc6"
  type: "Quantization"
  bottom: "fc6"
  top: "quantized_fc6"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -114.02487
    range: 58.541733
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "quantized_fc6"
  top: "relu6"
}
layer {
  name: "quantized_relu6"
  type: "Quantization"
  bottom: "relu6"
  top: "quantized_relu6"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 58.541733
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "quantized_relu6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1.05e+13
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "quantized_fc7"
  type: "Quantization"
  bottom: "fc7"
  top: "quantized_fc7"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -26.019335
    range: 19.125257
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "quantized_fc7"
  top: "relu7"
}
layer {
  name: "quantized_relu7"
  type: "Quantization"
  bottom: "relu7"
  top: "quantized_relu7"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 19.125257
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "quantized_relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "quantized_fc8"
  type: "Quantization"
  bottom: "fc8"
  top: "quantized_fc8"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -9.849781
    range: 45.688446
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "quantized_fc8"
  top: "probs"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc_top1"
  type: "Accuracy"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "acc_top1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc_top5"
  type: "Accuracy"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "acc_top5"
  accuracy_param {
    top_k: 5
  }
}
I1225 16:48:10.429200 61713 layer_factory.hpp:77] Creating layer data
I1225 16:48:10.429316 61713 db_lmdb.cpp:35] Opened lmdb /home/ydwu/database/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_train_lmdb/
I1225 16:48:10.429368 61713 net.cpp:84] Creating Layer data
I1225 16:48:10.429388 61713 net.cpp:380] data -> data
I1225 16:48:10.429422 61713 net.cpp:380] data -> label
I1225 16:48:10.429446 61713 data_transformer.cpp:25] Loading mean file from: /home/ydwu/database/imagenet/ilsvrc12/imagenet_mean.binaryproto
I1225 16:48:10.431957 61713 data_layer.cpp:45] output data size: 32,3,227,227
I1225 16:48:10.453814 61713 net.cpp:122] Setting up data
I1225 16:48:10.453886 61713 net.cpp:129] Top shape: 32 3 227 227 (4946784)
I1225 16:48:10.453899 61713 net.cpp:129] Top shape: 32 (32)
I1225 16:48:10.453908 61713 net.cpp:137] Memory required for data: 19787264
I1225 16:48:10.453927 61713 layer_factory.hpp:77] Creating layer label_data_1_split
I1225 16:48:10.453951 61713 net.cpp:84] Creating Layer label_data_1_split
I1225 16:48:10.453963 61713 net.cpp:406] label_data_1_split <- label
I1225 16:48:10.453990 61713 net.cpp:380] label_data_1_split -> label_data_1_split_0
I1225 16:48:10.454010 61713 net.cpp:380] label_data_1_split -> label_data_1_split_1
I1225 16:48:10.454066 61713 net.cpp:380] label_data_1_split -> label_data_1_split_2
I1225 16:48:10.454089 61713 net.cpp:122] Setting up label_data_1_split
I1225 16:48:10.454102 61713 net.cpp:129] Top shape: 32 (32)
I1225 16:48:10.454111 61713 net.cpp:129] Top shape: 32 (32)
I1225 16:48:10.454120 61713 net.cpp:129] Top shape: 32 (32)
I1225 16:48:10.454128 61713 net.cpp:137] Memory required for data: 19787648
I1225 16:48:10.454136 61713 layer_factory.hpp:77] Creating layer quantized_data
I1225 16:48:10.454152 61713 net.cpp:84] Creating Layer quantized_data
I1225 16:48:10.454161 61713 net.cpp:406] quantized_data <- data
I1225 16:48:10.454172 61713 net.cpp:380] quantized_data -> quantized_data
I1225 16:48:10.454190 61713 net.cpp:122] Setting up quantized_data
I1225 16:48:10.454202 61713 net.cpp:129] Top shape: 32 3 227 227 (4946784)
I1225 16:48:10.454210 61713 net.cpp:137] Memory required for data: 39574784
I1225 16:48:10.454218 61713 layer_factory.hpp:77] Creating layer conv1
I1225 16:48:10.454244 61713 net.cpp:84] Creating Layer conv1
I1225 16:48:10.454254 61713 net.cpp:406] conv1 <- quantized_data
I1225 16:48:10.454267 61713 net.cpp:380] conv1 -> conv1
I1225 16:48:10.455358 61713 net.cpp:122] Setting up conv1
I1225 16:48:10.455375 61713 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I1225 16:48:10.455384 61713 net.cpp:137] Memory required for data: 76745984
I1225 16:48:10.455405 61713 layer_factory.hpp:77] Creating layer quantized_conv1
I1225 16:48:10.455420 61713 net.cpp:84] Creating Layer quantized_conv1
I1225 16:48:10.455430 61713 net.cpp:406] quantized_conv1 <- conv1
I1225 16:48:10.455440 61713 net.cpp:380] quantized_conv1 -> quantized_conv1
I1225 16:48:10.455453 61713 net.cpp:122] Setting up quantized_conv1
I1225 16:48:10.455464 61713 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I1225 16:48:10.455473 61713 net.cpp:137] Memory required for data: 113917184
I1225 16:48:10.455482 61713 layer_factory.hpp:77] Creating layer relu1
I1225 16:48:10.455495 61713 net.cpp:84] Creating Layer relu1
I1225 16:48:10.455505 61713 net.cpp:406] relu1 <- quantized_conv1
I1225 16:48:10.455515 61713 net.cpp:380] relu1 -> relu1
I1225 16:48:10.455528 61713 net.cpp:122] Setting up relu1
I1225 16:48:10.455539 61713 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I1225 16:48:10.455549 61713 net.cpp:137] Memory required for data: 151088384
I1225 16:48:10.455556 61713 layer_factory.hpp:77] Creating layer quantized_relu1
I1225 16:48:10.455569 61713 net.cpp:84] Creating Layer quantized_relu1
I1225 16:48:10.455577 61713 net.cpp:406] quantized_relu1 <- relu1
I1225 16:48:10.455588 61713 net.cpp:380] quantized_relu1 -> quantized_relu1
I1225 16:48:10.455600 61713 net.cpp:122] Setting up quantized_relu1
I1225 16:48:10.455610 61713 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I1225 16:48:10.455618 61713 net.cpp:137] Memory required for data: 188259584
I1225 16:48:10.455626 61713 layer_factory.hpp:77] Creating layer pool1
I1225 16:48:10.455638 61713 net.cpp:84] Creating Layer pool1
I1225 16:48:10.455647 61713 net.cpp:406] pool1 <- quantized_relu1
I1225 16:48:10.455657 61713 net.cpp:380] pool1 -> pool1
I1225 16:48:10.455684 61713 net.cpp:122] Setting up pool1
I1225 16:48:10.455698 61713 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I1225 16:48:10.455706 61713 net.cpp:137] Memory required for data: 197217536
I1225 16:48:10.455714 61713 layer_factory.hpp:77] Creating layer quantized_pool1
I1225 16:48:10.455727 61713 net.cpp:84] Creating Layer quantized_pool1
I1225 16:48:10.455736 61713 net.cpp:406] quantized_pool1 <- pool1
I1225 16:48:10.455746 61713 net.cpp:380] quantized_pool1 -> quantized_pool1
I1225 16:48:10.455760 61713 net.cpp:122] Setting up quantized_pool1
I1225 16:48:10.455770 61713 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I1225 16:48:10.455777 61713 net.cpp:137] Memory required for data: 206175488
I1225 16:48:10.455785 61713 layer_factory.hpp:77] Creating layer norm1
I1225 16:48:10.455798 61713 net.cpp:84] Creating Layer norm1
I1225 16:48:10.455807 61713 net.cpp:406] norm1 <- quantized_pool1
I1225 16:48:10.455817 61713 net.cpp:380] norm1 -> norm1
I1225 16:48:10.455852 61713 net.cpp:122] Setting up norm1
I1225 16:48:10.455865 61713 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I1225 16:48:10.455873 61713 net.cpp:137] Memory required for data: 215133440
I1225 16:48:10.455881 61713 layer_factory.hpp:77] Creating layer quantized_norm1
I1225 16:48:10.455893 61713 net.cpp:84] Creating Layer quantized_norm1
I1225 16:48:10.455901 61713 net.cpp:406] quantized_norm1 <- norm1
I1225 16:48:10.455912 61713 net.cpp:380] quantized_norm1 -> quantized_norm1
I1225 16:48:10.455924 61713 net.cpp:122] Setting up quantized_norm1
I1225 16:48:10.455935 61713 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I1225 16:48:10.455942 61713 net.cpp:137] Memory required for data: 224091392
I1225 16:48:10.455950 61713 layer_factory.hpp:77] Creating layer conv2
I1225 16:48:10.455965 61713 net.cpp:84] Creating Layer conv2
I1225 16:48:10.455976 61713 net.cpp:406] conv2 <- quantized_norm1
I1225 16:48:10.455986 61713 net.cpp:380] conv2 -> conv2
I1225 16:48:10.464933 61713 net.cpp:122] Setting up conv2
I1225 16:48:10.464958 61713 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1225 16:48:10.464967 61713 net.cpp:137] Memory required for data: 247979264
I1225 16:48:10.464982 61713 layer_factory.hpp:77] Creating layer quantized_conv2
I1225 16:48:10.464995 61713 net.cpp:84] Creating Layer quantized_conv2
I1225 16:48:10.465004 61713 net.cpp:406] quantized_conv2 <- conv2
I1225 16:48:10.465019 61713 net.cpp:380] quantized_conv2 -> quantized_conv2
I1225 16:48:10.465034 61713 net.cpp:122] Setting up quantized_conv2
I1225 16:48:10.465045 61713 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1225 16:48:10.465054 61713 net.cpp:137] Memory required for data: 271867136
I1225 16:48:10.465061 61713 layer_factory.hpp:77] Creating layer relu2
I1225 16:48:10.465071 61713 net.cpp:84] Creating Layer relu2
I1225 16:48:10.465080 61713 net.cpp:406] relu2 <- quantized_conv2
I1225 16:48:10.465091 61713 net.cpp:380] relu2 -> relu2
I1225 16:48:10.465106 61713 net.cpp:122] Setting up relu2
I1225 16:48:10.465116 61713 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1225 16:48:10.465124 61713 net.cpp:137] Memory required for data: 295755008
I1225 16:48:10.465132 61713 layer_factory.hpp:77] Creating layer quantized_relu2
I1225 16:48:10.465143 61713 net.cpp:84] Creating Layer quantized_relu2
I1225 16:48:10.465152 61713 net.cpp:406] quantized_relu2 <- relu2
I1225 16:48:10.465163 61713 net.cpp:380] quantized_relu2 -> quantized_relu2
I1225 16:48:10.465176 61713 net.cpp:122] Setting up quantized_relu2
I1225 16:48:10.465186 61713 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I1225 16:48:10.465194 61713 net.cpp:137] Memory required for data: 319642880
I1225 16:48:10.465203 61713 layer_factory.hpp:77] Creating layer pool2
I1225 16:48:10.465212 61713 net.cpp:84] Creating Layer pool2
I1225 16:48:10.465221 61713 net.cpp:406] pool2 <- quantized_relu2
I1225 16:48:10.465234 61713 net.cpp:380] pool2 -> pool2
I1225 16:48:10.465247 61713 net.cpp:122] Setting up pool2
I1225 16:48:10.465258 61713 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1225 16:48:10.465266 61713 net.cpp:137] Memory required for data: 325180672
I1225 16:48:10.465275 61713 layer_factory.hpp:77] Creating layer quantized_pool2
I1225 16:48:10.465286 61713 net.cpp:84] Creating Layer quantized_pool2
I1225 16:48:10.465296 61713 net.cpp:406] quantized_pool2 <- pool2
I1225 16:48:10.465309 61713 net.cpp:380] quantized_pool2 -> quantized_pool2
I1225 16:48:10.465322 61713 net.cpp:122] Setting up quantized_pool2
I1225 16:48:10.465332 61713 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1225 16:48:10.465340 61713 net.cpp:137] Memory required for data: 330718464
I1225 16:48:10.465348 61713 layer_factory.hpp:77] Creating layer norm2
I1225 16:48:10.465361 61713 net.cpp:84] Creating Layer norm2
I1225 16:48:10.465370 61713 net.cpp:406] norm2 <- quantized_pool2
I1225 16:48:10.465380 61713 net.cpp:380] norm2 -> norm2
I1225 16:48:10.465394 61713 net.cpp:122] Setting up norm2
I1225 16:48:10.465404 61713 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1225 16:48:10.465411 61713 net.cpp:137] Memory required for data: 336256256
I1225 16:48:10.465436 61713 layer_factory.hpp:77] Creating layer quantized_norm2
I1225 16:48:10.465451 61713 net.cpp:84] Creating Layer quantized_norm2
I1225 16:48:10.465461 61713 net.cpp:406] quantized_norm2 <- norm2
I1225 16:48:10.465471 61713 net.cpp:380] quantized_norm2 -> quantized_norm2
I1225 16:48:10.465482 61713 net.cpp:122] Setting up quantized_norm2
I1225 16:48:10.465493 61713 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1225 16:48:10.465502 61713 net.cpp:137] Memory required for data: 341794048
I1225 16:48:10.465509 61713 layer_factory.hpp:77] Creating layer conv3
I1225 16:48:10.465525 61713 net.cpp:84] Creating Layer conv3
I1225 16:48:10.465535 61713 net.cpp:406] conv3 <- quantized_norm2
I1225 16:48:10.465553 61713 net.cpp:380] conv3 -> conv3
I1225 16:48:10.491866 61713 net.cpp:122] Setting up conv3
I1225 16:48:10.491916 61713 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1225 16:48:10.491925 61713 net.cpp:137] Memory required for data: 350100736
I1225 16:48:10.491945 61713 layer_factory.hpp:77] Creating layer quantized_conv3
I1225 16:48:10.491964 61713 net.cpp:84] Creating Layer quantized_conv3
I1225 16:48:10.491974 61713 net.cpp:406] quantized_conv3 <- conv3
I1225 16:48:10.491989 61713 net.cpp:380] quantized_conv3 -> quantized_conv3
I1225 16:48:10.492008 61713 net.cpp:122] Setting up quantized_conv3
I1225 16:48:10.492018 61713 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1225 16:48:10.492027 61713 net.cpp:137] Memory required for data: 358407424
I1225 16:48:10.492035 61713 layer_factory.hpp:77] Creating layer relu3
I1225 16:48:10.492048 61713 net.cpp:84] Creating Layer relu3
I1225 16:48:10.492058 61713 net.cpp:406] relu3 <- quantized_conv3
I1225 16:48:10.492069 61713 net.cpp:380] relu3 -> relu3
I1225 16:48:10.492080 61713 net.cpp:122] Setting up relu3
I1225 16:48:10.492090 61713 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1225 16:48:10.492099 61713 net.cpp:137] Memory required for data: 366714112
I1225 16:48:10.492106 61713 layer_factory.hpp:77] Creating layer quantized_relu3
I1225 16:48:10.492120 61713 net.cpp:84] Creating Layer quantized_relu3
I1225 16:48:10.492128 61713 net.cpp:406] quantized_relu3 <- relu3
I1225 16:48:10.492138 61713 net.cpp:380] quantized_relu3 -> quantized_relu3
I1225 16:48:10.492151 61713 net.cpp:122] Setting up quantized_relu3
I1225 16:48:10.492161 61713 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1225 16:48:10.492169 61713 net.cpp:137] Memory required for data: 375020800
I1225 16:48:10.492177 61713 layer_factory.hpp:77] Creating layer conv4
I1225 16:48:10.492195 61713 net.cpp:84] Creating Layer conv4
I1225 16:48:10.492205 61713 net.cpp:406] conv4 <- quantized_relu3
I1225 16:48:10.492218 61713 net.cpp:380] conv4 -> conv4
I1225 16:48:10.511668 61713 net.cpp:122] Setting up conv4
I1225 16:48:10.511719 61713 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1225 16:48:10.511729 61713 net.cpp:137] Memory required for data: 383327488
I1225 16:48:10.511742 61713 layer_factory.hpp:77] Creating layer quantized_conv4
I1225 16:48:10.511760 61713 net.cpp:84] Creating Layer quantized_conv4
I1225 16:48:10.511771 61713 net.cpp:406] quantized_conv4 <- conv4
I1225 16:48:10.511790 61713 net.cpp:380] quantized_conv4 -> quantized_conv4
I1225 16:48:10.511807 61713 net.cpp:122] Setting up quantized_conv4
I1225 16:48:10.511818 61713 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1225 16:48:10.511826 61713 net.cpp:137] Memory required for data: 391634176
I1225 16:48:10.511834 61713 layer_factory.hpp:77] Creating layer relu4
I1225 16:48:10.511848 61713 net.cpp:84] Creating Layer relu4
I1225 16:48:10.511857 61713 net.cpp:406] relu4 <- quantized_conv4
I1225 16:48:10.511868 61713 net.cpp:380] relu4 -> relu4
I1225 16:48:10.511879 61713 net.cpp:122] Setting up relu4
I1225 16:48:10.511889 61713 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1225 16:48:10.511898 61713 net.cpp:137] Memory required for data: 399940864
I1225 16:48:10.511906 61713 layer_factory.hpp:77] Creating layer quantized_relu4
I1225 16:48:10.511916 61713 net.cpp:84] Creating Layer quantized_relu4
I1225 16:48:10.511972 61713 net.cpp:406] quantized_relu4 <- relu4
I1225 16:48:10.511987 61713 net.cpp:380] quantized_relu4 -> quantized_relu4
I1225 16:48:10.512001 61713 net.cpp:122] Setting up quantized_relu4
I1225 16:48:10.512012 61713 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I1225 16:48:10.512020 61713 net.cpp:137] Memory required for data: 408247552
I1225 16:48:10.512028 61713 layer_factory.hpp:77] Creating layer conv5
I1225 16:48:10.512046 61713 net.cpp:84] Creating Layer conv5
I1225 16:48:10.512056 61713 net.cpp:406] conv5 <- quantized_relu4
I1225 16:48:10.512068 61713 net.cpp:380] conv5 -> conv5
I1225 16:48:10.525223 61713 net.cpp:122] Setting up conv5
I1225 16:48:10.525259 61713 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1225 16:48:10.525269 61713 net.cpp:137] Memory required for data: 413785344
I1225 16:48:10.525287 61713 layer_factory.hpp:77] Creating layer quantized_conv5
I1225 16:48:10.525301 61713 net.cpp:84] Creating Layer quantized_conv5
I1225 16:48:10.525315 61713 net.cpp:406] quantized_conv5 <- conv5
I1225 16:48:10.525326 61713 net.cpp:380] quantized_conv5 -> quantized_conv5
I1225 16:48:10.525342 61713 net.cpp:122] Setting up quantized_conv5
I1225 16:48:10.525352 61713 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1225 16:48:10.525362 61713 net.cpp:137] Memory required for data: 419323136
I1225 16:48:10.525369 61713 layer_factory.hpp:77] Creating layer relu5
I1225 16:48:10.525379 61713 net.cpp:84] Creating Layer relu5
I1225 16:48:10.525388 61713 net.cpp:406] relu5 <- quantized_conv5
I1225 16:48:10.525400 61713 net.cpp:380] relu5 -> relu5
I1225 16:48:10.525415 61713 net.cpp:122] Setting up relu5
I1225 16:48:10.525426 61713 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1225 16:48:10.525435 61713 net.cpp:137] Memory required for data: 424860928
I1225 16:48:10.525442 61713 layer_factory.hpp:77] Creating layer quantized_relu5
I1225 16:48:10.525455 61713 net.cpp:84] Creating Layer quantized_relu5
I1225 16:48:10.525465 61713 net.cpp:406] quantized_relu5 <- relu5
I1225 16:48:10.525475 61713 net.cpp:380] quantized_relu5 -> quantized_relu5
I1225 16:48:10.525486 61713 net.cpp:122] Setting up quantized_relu5
I1225 16:48:10.525497 61713 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I1225 16:48:10.525506 61713 net.cpp:137] Memory required for data: 430398720
I1225 16:48:10.525514 61713 layer_factory.hpp:77] Creating layer pool5
I1225 16:48:10.525527 61713 net.cpp:84] Creating Layer pool5
I1225 16:48:10.525537 61713 net.cpp:406] pool5 <- quantized_relu5
I1225 16:48:10.525550 61713 net.cpp:380] pool5 -> pool5
I1225 16:48:10.525568 61713 net.cpp:122] Setting up pool5
I1225 16:48:10.525579 61713 net.cpp:129] Top shape: 32 256 6 6 (294912)
I1225 16:48:10.525588 61713 net.cpp:137] Memory required for data: 431578368
I1225 16:48:10.525595 61713 layer_factory.hpp:77] Creating layer quantized_pool5
I1225 16:48:10.525612 61713 net.cpp:84] Creating Layer quantized_pool5
I1225 16:48:10.525621 61713 net.cpp:406] quantized_pool5 <- pool5
I1225 16:48:10.525632 61713 net.cpp:380] quantized_pool5 -> quantized_pool5
I1225 16:48:10.525645 61713 net.cpp:122] Setting up quantized_pool5
I1225 16:48:10.525655 61713 net.cpp:129] Top shape: 32 256 6 6 (294912)
I1225 16:48:10.525663 61713 net.cpp:137] Memory required for data: 432758016
I1225 16:48:10.525671 61713 layer_factory.hpp:77] Creating layer fc6
I1225 16:48:10.525693 61713 net.cpp:84] Creating Layer fc6
I1225 16:48:10.525702 61713 net.cpp:406] fc6 <- quantized_pool5
I1225 16:48:10.525715 61713 net.cpp:380] fc6 -> fc6
I1225 16:48:11.603844 61713 net.cpp:122] Setting up fc6
I1225 16:48:11.603907 61713 net.cpp:129] Top shape: 32 4096 (131072)
I1225 16:48:11.603917 61713 net.cpp:137] Memory required for data: 433282304
I1225 16:48:11.603935 61713 layer_factory.hpp:77] Creating layer quantized_fc6
I1225 16:48:11.603955 61713 net.cpp:84] Creating Layer quantized_fc6
I1225 16:48:11.603966 61713 net.cpp:406] quantized_fc6 <- fc6
I1225 16:48:11.603984 61713 net.cpp:380] quantized_fc6 -> quantized_fc6
I1225 16:48:11.604004 61713 net.cpp:122] Setting up quantized_fc6
I1225 16:48:11.604015 61713 net.cpp:129] Top shape: 32 4096 (131072)
I1225 16:48:11.604059 61713 net.cpp:137] Memory required for data: 433806592
I1225 16:48:11.604068 61713 layer_factory.hpp:77] Creating layer relu6
I1225 16:48:11.604080 61713 net.cpp:84] Creating Layer relu6
I1225 16:48:11.604089 61713 net.cpp:406] relu6 <- quantized_fc6
I1225 16:48:11.604100 61713 net.cpp:380] relu6 -> relu6
I1225 16:48:11.604112 61713 net.cpp:122] Setting up relu6
I1225 16:48:11.604122 61713 net.cpp:129] Top shape: 32 4096 (131072)
I1225 16:48:11.604131 61713 net.cpp:137] Memory required for data: 434330880
I1225 16:48:11.604140 61713 layer_factory.hpp:77] Creating layer quantized_relu6
I1225 16:48:11.604151 61713 net.cpp:84] Creating Layer quantized_relu6
I1225 16:48:11.604158 61713 net.cpp:406] quantized_relu6 <- relu6
I1225 16:48:11.604171 61713 net.cpp:380] quantized_relu6 -> quantized_relu6
I1225 16:48:11.604182 61713 net.cpp:122] Setting up quantized_relu6
I1225 16:48:11.604192 61713 net.cpp:129] Top shape: 32 4096 (131072)
I1225 16:48:11.604200 61713 net.cpp:137] Memory required for data: 434855168
I1225 16:48:11.604208 61713 layer_factory.hpp:77] Creating layer fc7
I1225 16:48:11.604225 61713 net.cpp:84] Creating Layer fc7
I1225 16:48:11.604235 61713 net.cpp:406] fc7 <- quantized_relu6
I1225 16:48:11.604245 61713 net.cpp:380] fc7 -> fc7
I1225 16:48:12.082723 61713 net.cpp:122] Setting up fc7
I1225 16:48:12.082787 61713 net.cpp:129] Top shape: 32 4096 (131072)
I1225 16:48:12.082798 61713 net.cpp:137] Memory required for data: 435379456
I1225 16:48:12.082815 61713 layer_factory.hpp:77] Creating layer quantized_fc7
I1225 16:48:12.082837 61713 net.cpp:84] Creating Layer quantized_fc7
I1225 16:48:12.082850 61713 net.cpp:406] quantized_fc7 <- fc7
I1225 16:48:12.082865 61713 net.cpp:380] quantized_fc7 -> quantized_fc7
I1225 16:48:12.082885 61713 net.cpp:122] Setting up quantized_fc7
I1225 16:48:12.082896 61713 net.cpp:129] Top shape: 32 4096 (131072)
I1225 16:48:12.082904 61713 net.cpp:137] Memory required for data: 435903744
I1225 16:48:12.082912 61713 layer_factory.hpp:77] Creating layer relu7
I1225 16:48:12.082924 61713 net.cpp:84] Creating Layer relu7
I1225 16:48:12.082933 61713 net.cpp:406] relu7 <- quantized_fc7
I1225 16:48:12.082943 61713 net.cpp:380] relu7 -> relu7
I1225 16:48:12.083001 61713 net.cpp:122] Setting up relu7
I1225 16:48:12.083014 61713 net.cpp:129] Top shape: 32 4096 (131072)
I1225 16:48:12.083021 61713 net.cpp:137] Memory required for data: 436428032
I1225 16:48:12.083029 61713 layer_factory.hpp:77] Creating layer quantized_relu7
I1225 16:48:12.083040 61713 net.cpp:84] Creating Layer quantized_relu7
I1225 16:48:12.083050 61713 net.cpp:406] quantized_relu7 <- relu7
I1225 16:48:12.083063 61713 net.cpp:380] quantized_relu7 -> quantized_relu7
I1225 16:48:12.083076 61713 net.cpp:122] Setting up quantized_relu7
I1225 16:48:12.083087 61713 net.cpp:129] Top shape: 32 4096 (131072)
I1225 16:48:12.083096 61713 net.cpp:137] Memory required for data: 436952320
I1225 16:48:12.083103 61713 layer_factory.hpp:77] Creating layer fc8
I1225 16:48:12.083117 61713 net.cpp:84] Creating Layer fc8
I1225 16:48:12.083125 61713 net.cpp:406] fc8 <- quantized_relu7
I1225 16:48:12.083137 61713 net.cpp:380] fc8 -> fc8
I1225 16:48:12.090368 61713 net.cpp:122] Setting up fc8
I1225 16:48:12.090427 61713 net.cpp:129] Top shape: 32 1000 (32000)
I1225 16:48:12.090437 61713 net.cpp:137] Memory required for data: 437080320
I1225 16:48:12.090453 61713 layer_factory.hpp:77] Creating layer quantized_fc8
I1225 16:48:12.090476 61713 net.cpp:84] Creating Layer quantized_fc8
I1225 16:48:12.090488 61713 net.cpp:406] quantized_fc8 <- fc8
I1225 16:48:12.090507 61713 net.cpp:380] quantized_fc8 -> quantized_fc8
I1225 16:48:12.090526 61713 net.cpp:122] Setting up quantized_fc8
I1225 16:48:12.090538 61713 net.cpp:129] Top shape: 32 1000 (32000)
I1225 16:48:12.090545 61713 net.cpp:137] Memory required for data: 437208320
I1225 16:48:12.090553 61713 layer_factory.hpp:77] Creating layer quantized_fc8_quantized_fc8_0_split
I1225 16:48:12.090565 61713 net.cpp:84] Creating Layer quantized_fc8_quantized_fc8_0_split
I1225 16:48:12.090612 61713 net.cpp:406] quantized_fc8_quantized_fc8_0_split <- quantized_fc8
I1225 16:48:12.090625 61713 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_0
I1225 16:48:12.090637 61713 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_1
I1225 16:48:12.090649 61713 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_2
I1225 16:48:12.090667 61713 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_3
I1225 16:48:12.090682 61713 net.cpp:122] Setting up quantized_fc8_quantized_fc8_0_split
I1225 16:48:12.090692 61713 net.cpp:129] Top shape: 32 1000 (32000)
I1225 16:48:12.090701 61713 net.cpp:129] Top shape: 32 1000 (32000)
I1225 16:48:12.090710 61713 net.cpp:129] Top shape: 32 1000 (32000)
I1225 16:48:12.090719 61713 net.cpp:129] Top shape: 32 1000 (32000)
I1225 16:48:12.090726 61713 net.cpp:137] Memory required for data: 437720320
I1225 16:48:12.090735 61713 layer_factory.hpp:77] Creating layer probs
I1225 16:48:12.090749 61713 net.cpp:84] Creating Layer probs
I1225 16:48:12.090757 61713 net.cpp:406] probs <- quantized_fc8_quantized_fc8_0_split_0
I1225 16:48:12.090768 61713 net.cpp:380] probs -> probs
I1225 16:48:12.090795 61713 net.cpp:122] Setting up probs
I1225 16:48:12.090806 61713 net.cpp:129] Top shape: 32 1000 (32000)
I1225 16:48:12.090814 61713 net.cpp:137] Memory required for data: 437848320
I1225 16:48:12.090822 61713 layer_factory.hpp:77] Creating layer loss
I1225 16:48:12.090837 61713 net.cpp:84] Creating Layer loss
I1225 16:48:12.090847 61713 net.cpp:406] loss <- quantized_fc8_quantized_fc8_0_split_1
I1225 16:48:12.090857 61713 net.cpp:406] loss <- label_data_1_split_0
I1225 16:48:12.090867 61713 net.cpp:380] loss -> loss
I1225 16:48:12.090889 61713 layer_factory.hpp:77] Creating layer loss
I1225 16:48:12.091043 61713 net.cpp:122] Setting up loss
I1225 16:48:12.091059 61713 net.cpp:129] Top shape: (1)
I1225 16:48:12.091068 61713 net.cpp:132]     with loss weight 1
I1225 16:48:12.091104 61713 net.cpp:137] Memory required for data: 437848324
I1225 16:48:12.091115 61713 layer_factory.hpp:77] Creating layer acc_top1
I1225 16:48:12.091132 61713 net.cpp:84] Creating Layer acc_top1
I1225 16:48:12.091141 61713 net.cpp:406] acc_top1 <- quantized_fc8_quantized_fc8_0_split_2
I1225 16:48:12.091151 61713 net.cpp:406] acc_top1 <- label_data_1_split_1
I1225 16:48:12.091164 61713 net.cpp:380] acc_top1 -> acc_top1
I1225 16:48:12.091182 61713 net.cpp:122] Setting up acc_top1
I1225 16:48:12.091192 61713 net.cpp:129] Top shape: (1)
I1225 16:48:12.091200 61713 net.cpp:137] Memory required for data: 437848328
I1225 16:48:12.091208 61713 layer_factory.hpp:77] Creating layer acc_top5
I1225 16:48:12.091218 61713 net.cpp:84] Creating Layer acc_top5
I1225 16:48:12.091228 61713 net.cpp:406] acc_top5 <- quantized_fc8_quantized_fc8_0_split_3
I1225 16:48:12.091236 61713 net.cpp:406] acc_top5 <- label_data_1_split_2
I1225 16:48:12.091246 61713 net.cpp:380] acc_top5 -> acc_top5
I1225 16:48:12.091259 61713 net.cpp:122] Setting up acc_top5
I1225 16:48:12.091269 61713 net.cpp:129] Top shape: (1)
I1225 16:48:12.091275 61713 net.cpp:137] Memory required for data: 437848332
I1225 16:48:12.091284 61713 net.cpp:200] acc_top5 does not need backward computation.
I1225 16:48:12.091295 61713 net.cpp:200] acc_top1 does not need backward computation.
I1225 16:48:12.091305 61713 net.cpp:198] loss needs backward computation.
I1225 16:48:12.091312 61713 net.cpp:200] probs does not need backward computation.
I1225 16:48:12.091321 61713 net.cpp:198] quantized_fc8_quantized_fc8_0_split needs backward computation.
I1225 16:48:12.091331 61713 net.cpp:198] quantized_fc8 needs backward computation.
I1225 16:48:12.091338 61713 net.cpp:198] fc8 needs backward computation.
I1225 16:48:12.091346 61713 net.cpp:198] quantized_relu7 needs backward computation.
I1225 16:48:12.091356 61713 net.cpp:198] relu7 needs backward computation.
I1225 16:48:12.091364 61713 net.cpp:198] quantized_fc7 needs backward computation.
I1225 16:48:12.091385 61713 net.cpp:198] fc7 needs backward computation.
I1225 16:48:12.091395 61713 net.cpp:198] quantized_relu6 needs backward computation.
I1225 16:48:12.091409 61713 net.cpp:198] relu6 needs backward computation.
I1225 16:48:12.091419 61713 net.cpp:198] quantized_fc6 needs backward computation.
I1225 16:48:12.091428 61713 net.cpp:198] fc6 needs backward computation.
I1225 16:48:12.091436 61713 net.cpp:198] quantized_pool5 needs backward computation.
I1225 16:48:12.091444 61713 net.cpp:198] pool5 needs backward computation.
I1225 16:48:12.091452 61713 net.cpp:198] quantized_relu5 needs backward computation.
I1225 16:48:12.091461 61713 net.cpp:198] relu5 needs backward computation.
I1225 16:48:12.091470 61713 net.cpp:198] quantized_conv5 needs backward computation.
I1225 16:48:12.091477 61713 net.cpp:198] conv5 needs backward computation.
I1225 16:48:12.091485 61713 net.cpp:198] quantized_relu4 needs backward computation.
I1225 16:48:12.091493 61713 net.cpp:198] relu4 needs backward computation.
I1225 16:48:12.091502 61713 net.cpp:198] quantized_conv4 needs backward computation.
I1225 16:48:12.091511 61713 net.cpp:198] conv4 needs backward computation.
I1225 16:48:12.091518 61713 net.cpp:198] quantized_relu3 needs backward computation.
I1225 16:48:12.091526 61713 net.cpp:198] relu3 needs backward computation.
I1225 16:48:12.091536 61713 net.cpp:198] quantized_conv3 needs backward computation.
I1225 16:48:12.091543 61713 net.cpp:198] conv3 needs backward computation.
I1225 16:48:12.091552 61713 net.cpp:198] quantized_norm2 needs backward computation.
I1225 16:48:12.091560 61713 net.cpp:198] norm2 needs backward computation.
I1225 16:48:12.091568 61713 net.cpp:198] quantized_pool2 needs backward computation.
I1225 16:48:12.091576 61713 net.cpp:198] pool2 needs backward computation.
I1225 16:48:12.091585 61713 net.cpp:198] quantized_relu2 needs backward computation.
I1225 16:48:12.091593 61713 net.cpp:198] relu2 needs backward computation.
I1225 16:48:12.091601 61713 net.cpp:198] quantized_conv2 needs backward computation.
I1225 16:48:12.091610 61713 net.cpp:198] conv2 needs backward computation.
I1225 16:48:12.091619 61713 net.cpp:198] quantized_norm1 needs backward computation.
I1225 16:48:12.091626 61713 net.cpp:198] norm1 needs backward computation.
I1225 16:48:12.091634 61713 net.cpp:198] quantized_pool1 needs backward computation.
I1225 16:48:12.091642 61713 net.cpp:198] pool1 needs backward computation.
I1225 16:48:12.091650 61713 net.cpp:198] quantized_relu1 needs backward computation.
I1225 16:48:12.091658 61713 net.cpp:198] relu1 needs backward computation.
I1225 16:48:12.091666 61713 net.cpp:198] quantized_conv1 needs backward computation.
I1225 16:48:12.091675 61713 net.cpp:198] conv1 needs backward computation.
I1225 16:48:12.091683 61713 net.cpp:200] quantized_data does not need backward computation.
I1225 16:48:12.091694 61713 net.cpp:200] label_data_1_split does not need backward computation.
I1225 16:48:12.091703 61713 net.cpp:200] data does not need backward computation.
I1225 16:48:12.091711 61713 net.cpp:242] This network produces output acc_top1
I1225 16:48:12.091719 61713 net.cpp:242] This network produces output acc_top5
I1225 16:48:12.091727 61713 net.cpp:242] This network produces output loss
I1225 16:48:12.091735 61713 net.cpp:242] This network produces output probs
I1225 16:48:12.091771 61713 net.cpp:255] Network initialization done.
I1225 16:48:12.092694 61713 solver.cpp:172] Creating test net (#0) specified by net file: qnn_try1/4bit-v1_train_quantized_caffenet.prototxt
I1225 16:48:12.092759 61713 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1225 16:48:12.093088 61713 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/ydwu/database/imagenet/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/ydwu/database/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_val_lmdb/"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "quantized_data"
  type: "Quantization"
  bottom: "data"
  top: "quantized_data"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -129.93526
    range: 160.78912
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "quantized_data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 0
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv1"
  type: "Quantization"
  bottom: "conv1"
  top: "quantized_conv1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -2732.7351
    range: 2531.042
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "quantized_conv1"
  top: "relu1"
}
layer {
  name: "quantized_relu1"
  type: "Quantization"
  bottom: "relu1"
  top: "quantized_relu1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 2531.042
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "quantized_relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool1"
  type: "Quantization"
  bottom: "pool1"
  top: "quantized_pool1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 2531.042
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "quantized_pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "quantized_norm1"
  type: "Quantization"
  bottom: "norm1"
  top: "quantized_norm1"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 138.70576
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "quantized_norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv2"
  type: "Quantization"
  bottom: "conv2"
  top: "quantized_conv2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -647.61908
    range: 492.23111
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "quantized_conv2"
  top: "relu2"
}
layer {
  name: "quantized_relu2"
  type: "Quantization"
  bottom: "relu2"
  top: "quantized_relu2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 492.23111
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "quantized_relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool2"
  type: "Quantization"
  bottom: "pool2"
  top: "quantized_pool2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 492.23111
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "quantized_pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "quantized_norm2"
  type: "Quantization"
  bottom: "norm2"
  top: "quantized_norm2"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 138.72636
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "quantized_norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv3"
  type: "Quantization"
  bottom: "conv3"
  top: "quantized_conv3"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -389.56516
    range: 331.98178
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "quantized_conv3"
  top: "relu3"
}
layer {
  name: "quantized_relu3"
  type: "Quantization"
  bottom: "relu3"
  top: "quantized_relu3"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 331.98178
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "quantized_relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv4"
  type: "Quantization"
  bottom: "conv4"
  top: "quantized_conv4"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -231.20598
    range: 283.87189
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "quantized_conv4"
  top: "relu4"
}
layer {
  name: "quantized_relu4"
  type: "Quantization"
  bottom: "relu4"
  top: "quantized_relu4"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 283.87189
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "quantized_relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 1.1e+13
    }
    bias_filler {
      type: "constant"
      std: 0.1
    }
  }
}
layer {
  name: "quantized_conv5"
  type: "Quantization"
  bottom: "conv5"
  top: "quantized_conv5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -172.60567
    range: 272.57315
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "quantized_conv5"
  top: "relu5"
}
layer {
  name: "quantized_relu5"
  type: "Quantization"
  bottom: "relu5"
  top: "quantized_relu5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 272.57315
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "quantized_relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "quantized_pool5"
  type: "Quantization"
  bottom: "pool5"
  top: "quantized_pool5"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 272.57315
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "quantized_pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1.05e+13
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "quantized_fc6"
  type: "Quantization"
  bottom: "fc6"
  top: "quantized_fc6"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -114.02487
    range: 58.541733
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "quantized_fc6"
  top: "relu6"
}
layer {
  name: "quantized_relu6"
  type: "Quantization"
  bottom: "relu6"
  top: "quantized_relu6"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 58.541733
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "quantized_relu6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 1.05e+13
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "quantized_fc7"
  type: "Quantization"
  bottom: "fc7"
  top: "quantized_fc7"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -26.019335
    range: 19.125257
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "quantized_fc7"
  top: "relu7"
}
layer {
  name: "quantized_relu7"
  type: "Quantization"
  bottom: "relu7"
  top: "quantized_relu7"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: 1
    range: 19.125257
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "quantized_relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "quantized_fc8"
  type: "Quantization"
  bottom: "fc8"
  top: "quantized_fc8"
  quantization_param {
    round_method: FLOOR
    round_strategy: AGGRESSIVE
    bit_width: 4
    range: -9.849781
    range: 45.688446
  }
}
layer {
  name: "probs"
  type: "Softmax"
  bottom: "quantized_fc8"
  top: "probs"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc_top1"
  type: "Accuracy"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "acc_top1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc_top5"
  type: "Accuracy"
  bottom: "quantized_fc8"
  bottom: "label"
  top: "acc_top5"
  accuracy_param {
    top_k: 5
  }
}
I1225 16:48:12.093304 61713 layer_factory.hpp:77] Creating layer data
I1225 16:48:12.093381 61713 db_lmdb.cpp:35] Opened lmdb /home/ydwu/database/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_val_lmdb/
I1225 16:48:12.093421 61713 net.cpp:84] Creating Layer data
I1225 16:48:12.093436 61713 net.cpp:380] data -> data
I1225 16:48:12.093449 61713 net.cpp:380] data -> label
I1225 16:48:12.093464 61713 data_transformer.cpp:25] Loading mean file from: /home/ydwu/database/imagenet/ilsvrc12/imagenet_mean.binaryproto
I1225 16:48:12.095603 61713 data_layer.cpp:45] output data size: 20,3,227,227
I1225 16:48:12.108371 61713 net.cpp:122] Setting up data
I1225 16:48:12.108428 61713 net.cpp:129] Top shape: 20 3 227 227 (3091740)
I1225 16:48:12.108440 61713 net.cpp:129] Top shape: 20 (20)
I1225 16:48:12.108448 61713 net.cpp:137] Memory required for data: 12367040
I1225 16:48:12.108461 61713 layer_factory.hpp:77] Creating layer label_data_1_split
I1225 16:48:12.108484 61713 net.cpp:84] Creating Layer label_data_1_split
I1225 16:48:12.108494 61713 net.cpp:406] label_data_1_split <- label
I1225 16:48:12.108507 61713 net.cpp:380] label_data_1_split -> label_data_1_split_0
I1225 16:48:12.108525 61713 net.cpp:380] label_data_1_split -> label_data_1_split_1
I1225 16:48:12.108538 61713 net.cpp:380] label_data_1_split -> label_data_1_split_2
I1225 16:48:12.108556 61713 net.cpp:122] Setting up label_data_1_split
I1225 16:48:12.108567 61713 net.cpp:129] Top shape: 20 (20)
I1225 16:48:12.108577 61713 net.cpp:129] Top shape: 20 (20)
I1225 16:48:12.108587 61713 net.cpp:129] Top shape: 20 (20)
I1225 16:48:12.108594 61713 net.cpp:137] Memory required for data: 12367280
I1225 16:48:12.108603 61713 layer_factory.hpp:77] Creating layer quantized_data
I1225 16:48:12.108616 61713 net.cpp:84] Creating Layer quantized_data
I1225 16:48:12.108625 61713 net.cpp:406] quantized_data <- data
I1225 16:48:12.108636 61713 net.cpp:380] quantized_data -> quantized_data
I1225 16:48:12.108649 61713 net.cpp:122] Setting up quantized_data
I1225 16:48:12.108659 61713 net.cpp:129] Top shape: 20 3 227 227 (3091740)
I1225 16:48:12.108667 61713 net.cpp:137] Memory required for data: 24734240
I1225 16:48:12.108676 61713 layer_factory.hpp:77] Creating layer conv1
I1225 16:48:12.108695 61713 net.cpp:84] Creating Layer conv1
I1225 16:48:12.108742 61713 net.cpp:406] conv1 <- quantized_data
I1225 16:48:12.108757 61713 net.cpp:380] conv1 -> conv1
I1225 16:48:12.109814 61713 net.cpp:122] Setting up conv1
I1225 16:48:12.109833 61713 net.cpp:129] Top shape: 20 96 55 55 (5808000)
I1225 16:48:12.109840 61713 net.cpp:137] Memory required for data: 47966240
I1225 16:48:12.109856 61713 layer_factory.hpp:77] Creating layer quantized_conv1
I1225 16:48:12.109872 61713 net.cpp:84] Creating Layer quantized_conv1
I1225 16:48:12.109881 61713 net.cpp:406] quantized_conv1 <- conv1
I1225 16:48:12.109894 61713 net.cpp:380] quantized_conv1 -> quantized_conv1
I1225 16:48:12.109908 61713 net.cpp:122] Setting up quantized_conv1
I1225 16:48:12.109918 61713 net.cpp:129] Top shape: 20 96 55 55 (5808000)
I1225 16:48:12.109926 61713 net.cpp:137] Memory required for data: 71198240
I1225 16:48:12.109935 61713 layer_factory.hpp:77] Creating layer relu1
I1225 16:48:12.109946 61713 net.cpp:84] Creating Layer relu1
I1225 16:48:12.109956 61713 net.cpp:406] relu1 <- quantized_conv1
I1225 16:48:12.109966 61713 net.cpp:380] relu1 -> relu1
I1225 16:48:12.109977 61713 net.cpp:122] Setting up relu1
I1225 16:48:12.109988 61713 net.cpp:129] Top shape: 20 96 55 55 (5808000)
I1225 16:48:12.109997 61713 net.cpp:137] Memory required for data: 94430240
I1225 16:48:12.110005 61713 layer_factory.hpp:77] Creating layer quantized_relu1
I1225 16:48:12.110019 61713 net.cpp:84] Creating Layer quantized_relu1
I1225 16:48:12.110029 61713 net.cpp:406] quantized_relu1 <- relu1
I1225 16:48:12.110039 61713 net.cpp:380] quantized_relu1 -> quantized_relu1
I1225 16:48:12.110051 61713 net.cpp:122] Setting up quantized_relu1
I1225 16:48:12.110062 61713 net.cpp:129] Top shape: 20 96 55 55 (5808000)
I1225 16:48:12.110069 61713 net.cpp:137] Memory required for data: 117662240
I1225 16:48:12.110077 61713 layer_factory.hpp:77] Creating layer pool1
I1225 16:48:12.110092 61713 net.cpp:84] Creating Layer pool1
I1225 16:48:12.110101 61713 net.cpp:406] pool1 <- quantized_relu1
I1225 16:48:12.110111 61713 net.cpp:380] pool1 -> pool1
I1225 16:48:12.110126 61713 net.cpp:122] Setting up pool1
I1225 16:48:12.110137 61713 net.cpp:129] Top shape: 20 96 27 27 (1399680)
I1225 16:48:12.110144 61713 net.cpp:137] Memory required for data: 123260960
I1225 16:48:12.110153 61713 layer_factory.hpp:77] Creating layer quantized_pool1
I1225 16:48:12.110168 61713 net.cpp:84] Creating Layer quantized_pool1
I1225 16:48:12.110177 61713 net.cpp:406] quantized_pool1 <- pool1
I1225 16:48:12.110188 61713 net.cpp:380] quantized_pool1 -> quantized_pool1
I1225 16:48:12.110200 61713 net.cpp:122] Setting up quantized_pool1
I1225 16:48:12.110211 61713 net.cpp:129] Top shape: 20 96 27 27 (1399680)
I1225 16:48:12.110219 61713 net.cpp:137] Memory required for data: 128859680
I1225 16:48:12.110227 61713 layer_factory.hpp:77] Creating layer norm1
I1225 16:48:12.110242 61713 net.cpp:84] Creating Layer norm1
I1225 16:48:12.110251 61713 net.cpp:406] norm1 <- quantized_pool1
I1225 16:48:12.110261 61713 net.cpp:380] norm1 -> norm1
I1225 16:48:12.110275 61713 net.cpp:122] Setting up norm1
I1225 16:48:12.110285 61713 net.cpp:129] Top shape: 20 96 27 27 (1399680)
I1225 16:48:12.110292 61713 net.cpp:137] Memory required for data: 134458400
I1225 16:48:12.110301 61713 layer_factory.hpp:77] Creating layer quantized_norm1
I1225 16:48:12.110313 61713 net.cpp:84] Creating Layer quantized_norm1
I1225 16:48:12.110321 61713 net.cpp:406] quantized_norm1 <- norm1
I1225 16:48:12.110333 61713 net.cpp:380] quantized_norm1 -> quantized_norm1
I1225 16:48:12.110347 61713 net.cpp:122] Setting up quantized_norm1
I1225 16:48:12.110357 61713 net.cpp:129] Top shape: 20 96 27 27 (1399680)
I1225 16:48:12.110364 61713 net.cpp:137] Memory required for data: 140057120
I1225 16:48:12.110373 61713 layer_factory.hpp:77] Creating layer conv2
I1225 16:48:12.110385 61713 net.cpp:84] Creating Layer conv2
I1225 16:48:12.110395 61713 net.cpp:406] conv2 <- quantized_norm1
I1225 16:48:12.110409 61713 net.cpp:380] conv2 -> conv2
I1225 16:48:12.119472 61713 net.cpp:122] Setting up conv2
I1225 16:48:12.119527 61713 net.cpp:129] Top shape: 20 256 27 27 (3732480)
I1225 16:48:12.119537 61713 net.cpp:137] Memory required for data: 154987040
I1225 16:48:12.119551 61713 layer_factory.hpp:77] Creating layer quantized_conv2
I1225 16:48:12.119570 61713 net.cpp:84] Creating Layer quantized_conv2
I1225 16:48:12.119580 61713 net.cpp:406] quantized_conv2 <- conv2
I1225 16:48:12.119590 61713 net.cpp:380] quantized_conv2 -> quantized_conv2
I1225 16:48:12.119612 61713 net.cpp:122] Setting up quantized_conv2
I1225 16:48:12.119623 61713 net.cpp:129] Top shape: 20 256 27 27 (3732480)
I1225 16:48:12.119632 61713 net.cpp:137] Memory required for data: 169916960
I1225 16:48:12.119639 61713 layer_factory.hpp:77] Creating layer relu2
I1225 16:48:12.119649 61713 net.cpp:84] Creating Layer relu2
I1225 16:48:12.119658 61713 net.cpp:406] relu2 <- quantized_conv2
I1225 16:48:12.119668 61713 net.cpp:380] relu2 -> relu2
I1225 16:48:12.119680 61713 net.cpp:122] Setting up relu2
I1225 16:48:12.119691 61713 net.cpp:129] Top shape: 20 256 27 27 (3732480)
I1225 16:48:12.119700 61713 net.cpp:137] Memory required for data: 184846880
I1225 16:48:12.119709 61713 layer_factory.hpp:77] Creating layer quantized_relu2
I1225 16:48:12.119721 61713 net.cpp:84] Creating Layer quantized_relu2
I1225 16:48:12.119730 61713 net.cpp:406] quantized_relu2 <- relu2
I1225 16:48:12.119740 61713 net.cpp:380] quantized_relu2 -> quantized_relu2
I1225 16:48:12.119752 61713 net.cpp:122] Setting up quantized_relu2
I1225 16:48:12.119763 61713 net.cpp:129] Top shape: 20 256 27 27 (3732480)
I1225 16:48:12.119774 61713 net.cpp:137] Memory required for data: 199776800
I1225 16:48:12.119783 61713 layer_factory.hpp:77] Creating layer pool2
I1225 16:48:12.119802 61713 net.cpp:84] Creating Layer pool2
I1225 16:48:12.119812 61713 net.cpp:406] pool2 <- quantized_relu2
I1225 16:48:12.119822 61713 net.cpp:380] pool2 -> pool2
I1225 16:48:12.119837 61713 net.cpp:122] Setting up pool2
I1225 16:48:12.119848 61713 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1225 16:48:12.119855 61713 net.cpp:137] Memory required for data: 203237920
I1225 16:48:12.119864 61713 layer_factory.hpp:77] Creating layer quantized_pool2
I1225 16:48:12.119879 61713 net.cpp:84] Creating Layer quantized_pool2
I1225 16:48:12.119889 61713 net.cpp:406] quantized_pool2 <- pool2
I1225 16:48:12.119900 61713 net.cpp:380] quantized_pool2 -> quantized_pool2
I1225 16:48:12.120023 61713 net.cpp:122] Setting up quantized_pool2
I1225 16:48:12.120043 61713 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1225 16:48:12.120061 61713 net.cpp:137] Memory required for data: 206699040
I1225 16:48:12.120067 61713 layer_factory.hpp:77] Creating layer norm2
I1225 16:48:12.120080 61713 net.cpp:84] Creating Layer norm2
I1225 16:48:12.120090 61713 net.cpp:406] norm2 <- quantized_pool2
I1225 16:48:12.120105 61713 net.cpp:380] norm2 -> norm2
I1225 16:48:12.120118 61713 net.cpp:122] Setting up norm2
I1225 16:48:12.120128 61713 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1225 16:48:12.120136 61713 net.cpp:137] Memory required for data: 210160160
I1225 16:48:12.120144 61713 layer_factory.hpp:77] Creating layer quantized_norm2
I1225 16:48:12.120156 61713 net.cpp:84] Creating Layer quantized_norm2
I1225 16:48:12.120163 61713 net.cpp:406] quantized_norm2 <- norm2
I1225 16:48:12.120175 61713 net.cpp:380] quantized_norm2 -> quantized_norm2
I1225 16:48:12.120188 61713 net.cpp:122] Setting up quantized_norm2
I1225 16:48:12.120198 61713 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1225 16:48:12.120206 61713 net.cpp:137] Memory required for data: 213621280
I1225 16:48:12.120214 61713 layer_factory.hpp:77] Creating layer conv3
I1225 16:48:12.120231 61713 net.cpp:84] Creating Layer conv3
I1225 16:48:12.120241 61713 net.cpp:406] conv3 <- quantized_norm2
I1225 16:48:12.120251 61713 net.cpp:380] conv3 -> conv3
I1225 16:48:12.145666 61713 net.cpp:122] Setting up conv3
I1225 16:48:12.145712 61713 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1225 16:48:12.145721 61713 net.cpp:137] Memory required for data: 218812960
I1225 16:48:12.145740 61713 layer_factory.hpp:77] Creating layer quantized_conv3
I1225 16:48:12.145790 61713 net.cpp:84] Creating Layer quantized_conv3
I1225 16:48:12.145802 61713 net.cpp:406] quantized_conv3 <- conv3
I1225 16:48:12.145818 61713 net.cpp:380] quantized_conv3 -> quantized_conv3
I1225 16:48:12.145838 61713 net.cpp:122] Setting up quantized_conv3
I1225 16:48:12.145849 61713 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1225 16:48:12.145858 61713 net.cpp:137] Memory required for data: 224004640
I1225 16:48:12.145865 61713 layer_factory.hpp:77] Creating layer relu3
I1225 16:48:12.145876 61713 net.cpp:84] Creating Layer relu3
I1225 16:48:12.145885 61713 net.cpp:406] relu3 <- quantized_conv3
I1225 16:48:12.145898 61713 net.cpp:380] relu3 -> relu3
I1225 16:48:12.145910 61713 net.cpp:122] Setting up relu3
I1225 16:48:12.145922 61713 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1225 16:48:12.145929 61713 net.cpp:137] Memory required for data: 229196320
I1225 16:48:12.145937 61713 layer_factory.hpp:77] Creating layer quantized_relu3
I1225 16:48:12.145947 61713 net.cpp:84] Creating Layer quantized_relu3
I1225 16:48:12.145956 61713 net.cpp:406] quantized_relu3 <- relu3
I1225 16:48:12.145965 61713 net.cpp:380] quantized_relu3 -> quantized_relu3
I1225 16:48:12.145977 61713 net.cpp:122] Setting up quantized_relu3
I1225 16:48:12.145987 61713 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1225 16:48:12.145994 61713 net.cpp:137] Memory required for data: 234388000
I1225 16:48:12.146003 61713 layer_factory.hpp:77] Creating layer conv4
I1225 16:48:12.146021 61713 net.cpp:84] Creating Layer conv4
I1225 16:48:12.146030 61713 net.cpp:406] conv4 <- quantized_relu3
I1225 16:48:12.146041 61713 net.cpp:380] conv4 -> conv4
I1225 16:48:12.165526 61713 net.cpp:122] Setting up conv4
I1225 16:48:12.165567 61713 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1225 16:48:12.165577 61713 net.cpp:137] Memory required for data: 239579680
I1225 16:48:12.165591 61713 layer_factory.hpp:77] Creating layer quantized_conv4
I1225 16:48:12.165607 61713 net.cpp:84] Creating Layer quantized_conv4
I1225 16:48:12.165617 61713 net.cpp:406] quantized_conv4 <- conv4
I1225 16:48:12.165632 61713 net.cpp:380] quantized_conv4 -> quantized_conv4
I1225 16:48:12.165649 61713 net.cpp:122] Setting up quantized_conv4
I1225 16:48:12.165659 61713 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1225 16:48:12.165668 61713 net.cpp:137] Memory required for data: 244771360
I1225 16:48:12.165675 61713 layer_factory.hpp:77] Creating layer relu4
I1225 16:48:12.165685 61713 net.cpp:84] Creating Layer relu4
I1225 16:48:12.165694 61713 net.cpp:406] relu4 <- quantized_conv4
I1225 16:48:12.165704 61713 net.cpp:380] relu4 -> relu4
I1225 16:48:12.165714 61713 net.cpp:122] Setting up relu4
I1225 16:48:12.165724 61713 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1225 16:48:12.165732 61713 net.cpp:137] Memory required for data: 249963040
I1225 16:48:12.165740 61713 layer_factory.hpp:77] Creating layer quantized_relu4
I1225 16:48:12.165752 61713 net.cpp:84] Creating Layer quantized_relu4
I1225 16:48:12.165761 61713 net.cpp:406] quantized_relu4 <- relu4
I1225 16:48:12.165771 61713 net.cpp:380] quantized_relu4 -> quantized_relu4
I1225 16:48:12.165782 61713 net.cpp:122] Setting up quantized_relu4
I1225 16:48:12.165793 61713 net.cpp:129] Top shape: 20 384 13 13 (1297920)
I1225 16:48:12.165801 61713 net.cpp:137] Memory required for data: 255154720
I1225 16:48:12.165808 61713 layer_factory.hpp:77] Creating layer conv5
I1225 16:48:12.165825 61713 net.cpp:84] Creating Layer conv5
I1225 16:48:12.165835 61713 net.cpp:406] conv5 <- quantized_relu4
I1225 16:48:12.165848 61713 net.cpp:380] conv5 -> conv5
I1225 16:48:12.178908 61713 net.cpp:122] Setting up conv5
I1225 16:48:12.178944 61713 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1225 16:48:12.178953 61713 net.cpp:137] Memory required for data: 258615840
I1225 16:48:12.179087 61713 layer_factory.hpp:77] Creating layer quantized_conv5
I1225 16:48:12.179103 61713 net.cpp:84] Creating Layer quantized_conv5
I1225 16:48:12.179113 61713 net.cpp:406] quantized_conv5 <- conv5
I1225 16:48:12.179163 61713 net.cpp:380] quantized_conv5 -> quantized_conv5
I1225 16:48:12.179180 61713 net.cpp:122] Setting up quantized_conv5
I1225 16:48:12.179190 61713 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1225 16:48:12.179198 61713 net.cpp:137] Memory required for data: 262076960
I1225 16:48:12.179206 61713 layer_factory.hpp:77] Creating layer relu5
I1225 16:48:12.179219 61713 net.cpp:84] Creating Layer relu5
I1225 16:48:12.179227 61713 net.cpp:406] relu5 <- quantized_conv5
I1225 16:48:12.179237 61713 net.cpp:380] relu5 -> relu5
I1225 16:48:12.179253 61713 net.cpp:122] Setting up relu5
I1225 16:48:12.179265 61713 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1225 16:48:12.179273 61713 net.cpp:137] Memory required for data: 265538080
I1225 16:48:12.179281 61713 layer_factory.hpp:77] Creating layer quantized_relu5
I1225 16:48:12.179291 61713 net.cpp:84] Creating Layer quantized_relu5
I1225 16:48:12.179299 61713 net.cpp:406] quantized_relu5 <- relu5
I1225 16:48:12.179309 61713 net.cpp:380] quantized_relu5 -> quantized_relu5
I1225 16:48:12.179322 61713 net.cpp:122] Setting up quantized_relu5
I1225 16:48:12.179332 61713 net.cpp:129] Top shape: 20 256 13 13 (865280)
I1225 16:48:12.179339 61713 net.cpp:137] Memory required for data: 268999200
I1225 16:48:12.179347 61713 layer_factory.hpp:77] Creating layer pool5
I1225 16:48:12.179360 61713 net.cpp:84] Creating Layer pool5
I1225 16:48:12.179368 61713 net.cpp:406] pool5 <- quantized_relu5
I1225 16:48:12.179378 61713 net.cpp:380] pool5 -> pool5
I1225 16:48:12.179396 61713 net.cpp:122] Setting up pool5
I1225 16:48:12.179407 61713 net.cpp:129] Top shape: 20 256 6 6 (184320)
I1225 16:48:12.179415 61713 net.cpp:137] Memory required for data: 269736480
I1225 16:48:12.179422 61713 layer_factory.hpp:77] Creating layer quantized_pool5
I1225 16:48:12.179436 61713 net.cpp:84] Creating Layer quantized_pool5
I1225 16:48:12.179445 61713 net.cpp:406] quantized_pool5 <- pool5
I1225 16:48:12.179457 61713 net.cpp:380] quantized_pool5 -> quantized_pool5
I1225 16:48:12.179469 61713 net.cpp:122] Setting up quantized_pool5
I1225 16:48:12.179479 61713 net.cpp:129] Top shape: 20 256 6 6 (184320)
I1225 16:48:12.179487 61713 net.cpp:137] Memory required for data: 270473760
I1225 16:48:12.179496 61713 layer_factory.hpp:77] Creating layer fc6
I1225 16:48:12.179508 61713 net.cpp:84] Creating Layer fc6
I1225 16:48:12.179517 61713 net.cpp:406] fc6 <- quantized_pool5
I1225 16:48:12.179528 61713 net.cpp:380] fc6 -> fc6
I1225 16:48:13.259779 61713 net.cpp:122] Setting up fc6
I1225 16:48:13.259836 61713 net.cpp:129] Top shape: 20 4096 (81920)
I1225 16:48:13.259845 61713 net.cpp:137] Memory required for data: 270801440
I1225 16:48:13.259863 61713 layer_factory.hpp:77] Creating layer quantized_fc6
I1225 16:48:13.259891 61713 net.cpp:84] Creating Layer quantized_fc6
I1225 16:48:13.259902 61713 net.cpp:406] quantized_fc6 <- fc6
I1225 16:48:13.259918 61713 net.cpp:380] quantized_fc6 -> quantized_fc6
I1225 16:48:13.259938 61713 net.cpp:122] Setting up quantized_fc6
I1225 16:48:13.259949 61713 net.cpp:129] Top shape: 20 4096 (81920)
I1225 16:48:13.259958 61713 net.cpp:137] Memory required for data: 271129120
I1225 16:48:13.259965 61713 layer_factory.hpp:77] Creating layer relu6
I1225 16:48:13.259977 61713 net.cpp:84] Creating Layer relu6
I1225 16:48:13.259985 61713 net.cpp:406] relu6 <- quantized_fc6
I1225 16:48:13.259996 61713 net.cpp:380] relu6 -> relu6
I1225 16:48:13.260009 61713 net.cpp:122] Setting up relu6
I1225 16:48:13.260018 61713 net.cpp:129] Top shape: 20 4096 (81920)
I1225 16:48:13.260026 61713 net.cpp:137] Memory required for data: 271456800
I1225 16:48:13.260035 61713 layer_factory.hpp:77] Creating layer quantized_relu6
I1225 16:48:13.260046 61713 net.cpp:84] Creating Layer quantized_relu6
I1225 16:48:13.260053 61713 net.cpp:406] quantized_relu6 <- relu6
I1225 16:48:13.260067 61713 net.cpp:380] quantized_relu6 -> quantized_relu6
I1225 16:48:13.260080 61713 net.cpp:122] Setting up quantized_relu6
I1225 16:48:13.260092 61713 net.cpp:129] Top shape: 20 4096 (81920)
I1225 16:48:13.260099 61713 net.cpp:137] Memory required for data: 271784480
I1225 16:48:13.260149 61713 layer_factory.hpp:77] Creating layer fc7
I1225 16:48:13.260164 61713 net.cpp:84] Creating Layer fc7
I1225 16:48:13.260174 61713 net.cpp:406] fc7 <- quantized_relu6
I1225 16:48:13.260185 61713 net.cpp:380] fc7 -> fc7
I1225 16:48:13.741212 61713 net.cpp:122] Setting up fc7
I1225 16:48:13.741278 61713 net.cpp:129] Top shape: 20 4096 (81920)
I1225 16:48:13.741288 61713 net.cpp:137] Memory required for data: 272112160
I1225 16:48:13.741305 61713 layer_factory.hpp:77] Creating layer quantized_fc7
I1225 16:48:13.741327 61713 net.cpp:84] Creating Layer quantized_fc7
I1225 16:48:13.741338 61713 net.cpp:406] quantized_fc7 <- fc7
I1225 16:48:13.741354 61713 net.cpp:380] quantized_fc7 -> quantized_fc7
I1225 16:48:13.741374 61713 net.cpp:122] Setting up quantized_fc7
I1225 16:48:13.741385 61713 net.cpp:129] Top shape: 20 4096 (81920)
I1225 16:48:13.741394 61713 net.cpp:137] Memory required for data: 272439840
I1225 16:48:13.741402 61713 layer_factory.hpp:77] Creating layer relu7
I1225 16:48:13.741413 61713 net.cpp:84] Creating Layer relu7
I1225 16:48:13.741421 61713 net.cpp:406] relu7 <- quantized_fc7
I1225 16:48:13.741432 61713 net.cpp:380] relu7 -> relu7
I1225 16:48:13.741444 61713 net.cpp:122] Setting up relu7
I1225 16:48:13.741454 61713 net.cpp:129] Top shape: 20 4096 (81920)
I1225 16:48:13.741462 61713 net.cpp:137] Memory required for data: 272767520
I1225 16:48:13.741470 61713 layer_factory.hpp:77] Creating layer quantized_relu7
I1225 16:48:13.741483 61713 net.cpp:84] Creating Layer quantized_relu7
I1225 16:48:13.741493 61713 net.cpp:406] quantized_relu7 <- relu7
I1225 16:48:13.741504 61713 net.cpp:380] quantized_relu7 -> quantized_relu7
I1225 16:48:13.741516 61713 net.cpp:122] Setting up quantized_relu7
I1225 16:48:13.741528 61713 net.cpp:129] Top shape: 20 4096 (81920)
I1225 16:48:13.741535 61713 net.cpp:137] Memory required for data: 273095200
I1225 16:48:13.741544 61713 layer_factory.hpp:77] Creating layer fc8
I1225 16:48:13.741556 61713 net.cpp:84] Creating Layer fc8
I1225 16:48:13.741565 61713 net.cpp:406] fc8 <- quantized_relu7
I1225 16:48:13.741576 61713 net.cpp:380] fc8 -> fc8
I1225 16:48:13.748270 61713 net.cpp:122] Setting up fc8
I1225 16:48:13.748335 61713 net.cpp:129] Top shape: 20 1000 (20000)
I1225 16:48:13.748345 61713 net.cpp:137] Memory required for data: 273175200
I1225 16:48:13.748361 61713 layer_factory.hpp:77] Creating layer quantized_fc8
I1225 16:48:13.748380 61713 net.cpp:84] Creating Layer quantized_fc8
I1225 16:48:13.748392 61713 net.cpp:406] quantized_fc8 <- fc8
I1225 16:48:13.748410 61713 net.cpp:380] quantized_fc8 -> quantized_fc8
I1225 16:48:13.748430 61713 net.cpp:122] Setting up quantized_fc8
I1225 16:48:13.748441 61713 net.cpp:129] Top shape: 20 1000 (20000)
I1225 16:48:13.748450 61713 net.cpp:137] Memory required for data: 273255200
I1225 16:48:13.748458 61713 layer_factory.hpp:77] Creating layer quantized_fc8_quantized_fc8_0_split
I1225 16:48:13.748471 61713 net.cpp:84] Creating Layer quantized_fc8_quantized_fc8_0_split
I1225 16:48:13.748478 61713 net.cpp:406] quantized_fc8_quantized_fc8_0_split <- quantized_fc8
I1225 16:48:13.748492 61713 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_0
I1225 16:48:13.748504 61713 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_1
I1225 16:48:13.748517 61713 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_2
I1225 16:48:13.748528 61713 net.cpp:380] quantized_fc8_quantized_fc8_0_split -> quantized_fc8_quantized_fc8_0_split_3
I1225 16:48:13.748541 61713 net.cpp:122] Setting up quantized_fc8_quantized_fc8_0_split
I1225 16:48:13.748554 61713 net.cpp:129] Top shape: 20 1000 (20000)
I1225 16:48:13.748565 61713 net.cpp:129] Top shape: 20 1000 (20000)
I1225 16:48:13.748575 61713 net.cpp:129] Top shape: 20 1000 (20000)
I1225 16:48:13.748584 61713 net.cpp:129] Top shape: 20 1000 (20000)
I1225 16:48:13.748594 61713 net.cpp:137] Memory required for data: 273575200
I1225 16:48:13.748601 61713 layer_factory.hpp:77] Creating layer probs
I1225 16:48:13.748654 61713 net.cpp:84] Creating Layer probs
I1225 16:48:13.748664 61713 net.cpp:406] probs <- quantized_fc8_quantized_fc8_0_split_0
I1225 16:48:13.748674 61713 net.cpp:380] probs -> probs
I1225 16:48:13.748697 61713 net.cpp:122] Setting up probs
I1225 16:48:13.748708 61713 net.cpp:129] Top shape: 20 1000 (20000)
I1225 16:48:13.748716 61713 net.cpp:137] Memory required for data: 273655200
I1225 16:48:13.748725 61713 layer_factory.hpp:77] Creating layer loss
I1225 16:48:13.748739 61713 net.cpp:84] Creating Layer loss
I1225 16:48:13.748747 61713 net.cpp:406] loss <- quantized_fc8_quantized_fc8_0_split_1
I1225 16:48:13.748757 61713 net.cpp:406] loss <- label_data_1_split_0
I1225 16:48:13.748769 61713 net.cpp:380] loss -> loss
I1225 16:48:13.748785 61713 layer_factory.hpp:77] Creating layer loss
I1225 16:48:13.748857 61713 net.cpp:122] Setting up loss
I1225 16:48:13.748872 61713 net.cpp:129] Top shape: (1)
I1225 16:48:13.748880 61713 net.cpp:132]     with loss weight 1
I1225 16:48:13.748900 61713 net.cpp:137] Memory required for data: 273655204
I1225 16:48:13.748908 61713 layer_factory.hpp:77] Creating layer acc_top1
I1225 16:48:13.748921 61713 net.cpp:84] Creating Layer acc_top1
I1225 16:48:13.748930 61713 net.cpp:406] acc_top1 <- quantized_fc8_quantized_fc8_0_split_2
I1225 16:48:13.748940 61713 net.cpp:406] acc_top1 <- label_data_1_split_1
I1225 16:48:13.748950 61713 net.cpp:380] acc_top1 -> acc_top1
I1225 16:48:13.748965 61713 net.cpp:122] Setting up acc_top1
I1225 16:48:13.748975 61713 net.cpp:129] Top shape: (1)
I1225 16:48:13.748981 61713 net.cpp:137] Memory required for data: 273655208
I1225 16:48:13.748991 61713 layer_factory.hpp:77] Creating layer acc_top5
I1225 16:48:13.749002 61713 net.cpp:84] Creating Layer acc_top5
I1225 16:48:13.749011 61713 net.cpp:406] acc_top5 <- quantized_fc8_quantized_fc8_0_split_3
I1225 16:48:13.749020 61713 net.cpp:406] acc_top5 <- label_data_1_split_2
I1225 16:48:13.749032 61713 net.cpp:380] acc_top5 -> acc_top5
I1225 16:48:13.749045 61713 net.cpp:122] Setting up acc_top5
I1225 16:48:13.749055 61713 net.cpp:129] Top shape: (1)
I1225 16:48:13.749063 61713 net.cpp:137] Memory required for data: 273655212
I1225 16:48:13.749071 61713 net.cpp:200] acc_top5 does not need backward computation.
I1225 16:48:13.749080 61713 net.cpp:200] acc_top1 does not need backward computation.
I1225 16:48:13.749089 61713 net.cpp:198] loss needs backward computation.
I1225 16:48:13.749096 61713 net.cpp:200] probs does not need backward computation.
I1225 16:48:13.749105 61713 net.cpp:198] quantized_fc8_quantized_fc8_0_split needs backward computation.
I1225 16:48:13.749114 61713 net.cpp:198] quantized_fc8 needs backward computation.
I1225 16:48:13.749122 61713 net.cpp:198] fc8 needs backward computation.
I1225 16:48:13.749130 61713 net.cpp:198] quantized_relu7 needs backward computation.
I1225 16:48:13.749140 61713 net.cpp:198] relu7 needs backward computation.
I1225 16:48:13.749147 61713 net.cpp:198] quantized_fc7 needs backward computation.
I1225 16:48:13.749156 61713 net.cpp:198] fc7 needs backward computation.
I1225 16:48:13.749164 61713 net.cpp:198] quantized_relu6 needs backward computation.
I1225 16:48:13.749173 61713 net.cpp:198] relu6 needs backward computation.
I1225 16:48:13.749181 61713 net.cpp:198] quantized_fc6 needs backward computation.
I1225 16:48:13.749191 61713 net.cpp:198] fc6 needs backward computation.
I1225 16:48:13.749198 61713 net.cpp:198] quantized_pool5 needs backward computation.
I1225 16:48:13.749207 61713 net.cpp:198] pool5 needs backward computation.
I1225 16:48:13.749215 61713 net.cpp:198] quantized_relu5 needs backward computation.
I1225 16:48:13.749223 61713 net.cpp:198] relu5 needs backward computation.
I1225 16:48:13.749233 61713 net.cpp:198] quantized_conv5 needs backward computation.
I1225 16:48:13.749240 61713 net.cpp:198] conv5 needs backward computation.
I1225 16:48:13.749249 61713 net.cpp:198] quantized_relu4 needs backward computation.
I1225 16:48:13.749258 61713 net.cpp:198] relu4 needs backward computation.
I1225 16:48:13.749284 61713 net.cpp:198] quantized_conv4 needs backward computation.
I1225 16:48:13.749294 61713 net.cpp:198] conv4 needs backward computation.
I1225 16:48:13.749303 61713 net.cpp:198] quantized_relu3 needs backward computation.
I1225 16:48:13.749311 61713 net.cpp:198] relu3 needs backward computation.
I1225 16:48:13.749320 61713 net.cpp:198] quantized_conv3 needs backward computation.
I1225 16:48:13.749328 61713 net.cpp:198] conv3 needs backward computation.
I1225 16:48:13.749336 61713 net.cpp:198] quantized_norm2 needs backward computation.
I1225 16:48:13.749346 61713 net.cpp:198] norm2 needs backward computation.
I1225 16:48:13.749353 61713 net.cpp:198] quantized_pool2 needs backward computation.
I1225 16:48:13.749362 61713 net.cpp:198] pool2 needs backward computation.
I1225 16:48:13.749370 61713 net.cpp:198] quantized_relu2 needs backward computation.
I1225 16:48:13.749379 61713 net.cpp:198] relu2 needs backward computation.
I1225 16:48:13.749387 61713 net.cpp:198] quantized_conv2 needs backward computation.
I1225 16:48:13.749397 61713 net.cpp:198] conv2 needs backward computation.
I1225 16:48:13.749404 61713 net.cpp:198] quantized_norm1 needs backward computation.
I1225 16:48:13.749413 61713 net.cpp:198] norm1 needs backward computation.
I1225 16:48:13.749421 61713 net.cpp:198] quantized_pool1 needs backward computation.
I1225 16:48:13.749430 61713 net.cpp:198] pool1 needs backward computation.
I1225 16:48:13.749439 61713 net.cpp:198] quantized_relu1 needs backward computation.
I1225 16:48:13.749447 61713 net.cpp:198] relu1 needs backward computation.
I1225 16:48:13.749455 61713 net.cpp:198] quantized_conv1 needs backward computation.
I1225 16:48:13.749464 61713 net.cpp:198] conv1 needs backward computation.
I1225 16:48:13.749472 61713 net.cpp:200] quantized_data does not need backward computation.
I1225 16:48:13.749481 61713 net.cpp:200] label_data_1_split does not need backward computation.
I1225 16:48:13.749490 61713 net.cpp:200] data does not need backward computation.
I1225 16:48:13.749498 61713 net.cpp:242] This network produces output acc_top1
I1225 16:48:13.749506 61713 net.cpp:242] This network produces output acc_top5
I1225 16:48:13.749516 61713 net.cpp:242] This network produces output loss
I1225 16:48:13.749523 61713 net.cpp:242] This network produces output probs
I1225 16:48:13.749559 61713 net.cpp:255] Network initialization done.
I1225 16:48:13.749734 61713 solver.cpp:56] Solver scaffolding done.
I1225 16:48:13.749797 61713 caffe.cpp:155] Finetuning from ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1225 16:48:14.229962 61713 upgrade_proto.cpp:44] Attempting to upgrade input file specified using deprecated transformation parameters: ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1225 16:48:14.230027 61713 upgrade_proto.cpp:47] Successfully upgraded file specified using deprecated data transformation parameters.
W1225 16:48:14.230039 61713 upgrade_proto.cpp:49] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1225 16:48:14.230183 61713 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1225 16:48:14.462357 61713 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I1225 16:48:14.512642 61713 net.cpp:744] Ignoring source layer drop6
I1225 16:48:14.533493 61713 net.cpp:744] Ignoring source layer drop7
I1225 16:48:15.014155 61713 upgrade_proto.cpp:44] Attempting to upgrade input file specified using deprecated transformation parameters: ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1225 16:48:15.014216 61713 upgrade_proto.cpp:47] Successfully upgraded file specified using deprecated data transformation parameters.
W1225 16:48:15.014226 61713 upgrade_proto.cpp:49] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1225 16:48:15.014258 61713 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./qnn_try1/bvlc_reference_caffenet.caffemodel
I1225 16:48:15.243695 61713 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I1225 16:48:15.290457 61713 net.cpp:744] Ignoring source layer drop6
I1225 16:48:15.309903 61713 net.cpp:744] Ignoring source layer drop7
I1225 16:48:15.317301 61713 caffe.cpp:248] Starting Optimization
I1225 16:48:15.317360 61713 solver.cpp:273] Solving 
I1225 16:48:15.317370 61713 solver.cpp:274] Learning Rate Policy: step
I1225 16:48:15.408841 61713 solver.cpp:331] Iteration 0, Testing net (#0)
I1225 16:48:40.386040 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 16:48:40.386322 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 16:48:40.386345 61713 solver.cpp:400]     Test net output #2: loss = 8.35525 (* 1 = 8.35525 loss)
I1225 16:48:50.946787 61713 solver.cpp:218] Iteration 0 (0 iter/s, 35.629s/50 iters), loss = 8.34025
I1225 16:48:50.946856 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 16:48:50.946871 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 16:48:50.946888 61713 solver.cpp:238]     Train net output #2: loss = 8.34025 (* 1 = 8.34025 loss)
I1225 16:48:50.957237 61713 sgd_solver.cpp:105] Iteration 0, lr = 0.0001
I1225 16:57:38.217355 61713 solver.cpp:218] Iteration 50 (0.0948281 iter/s, 527.27s/50 iters), loss = 7.59025
I1225 16:57:38.217535 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 16:57:38.217550 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 16:57:38.217569 61713 solver.cpp:238]     Train net output #2: loss = 7.59025 (* 1 = 7.59025 loss)
I1225 16:57:38.227895 61713 sgd_solver.cpp:105] Iteration 50, lr = 0.0001
I1225 17:06:13.592558 61713 solver.cpp:331] Iteration 100, Testing net (#0)
I1225 17:06:37.680986 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 17:06:37.681057 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 17:06:37.681080 61713 solver.cpp:400]     Test net output #2: loss = 8.27502 (* 1 = 8.27502 loss)
I1225 17:06:47.565547 61713 solver.cpp:218] Iteration 100 (0.0910172 iter/s, 549.347s/50 iters), loss = 8.59025
I1225 17:06:47.565786 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 17:06:47.565810 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 17:06:47.565831 61713 solver.cpp:238]     Train net output #2: loss = 8.59025 (* 1 = 8.59025 loss)
I1225 17:06:47.576038 61713 sgd_solver.cpp:105] Iteration 100, lr = 0.0001
I1225 17:15:25.392777 61713 solver.cpp:218] Iteration 150 (0.0965575 iter/s, 517.826s/50 iters), loss = 8.59417
I1225 17:15:25.393052 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 17:15:25.393088 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 17:15:25.393116 61713 solver.cpp:238]     Train net output #2: loss = 8.59417 (* 1 = 8.59417 loss)
I1225 17:15:25.403715 61713 sgd_solver.cpp:105] Iteration 150, lr = 0.0001
I1225 17:23:52.620357 61713 solver.cpp:331] Iteration 200, Testing net (#0)
I1225 17:24:16.734923 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 17:24:16.734999 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 17:24:16.735031 61713 solver.cpp:400]     Test net output #2: loss = 8.25917 (* 1 = 8.25917 loss)
I1225 17:24:26.643847 61713 solver.cpp:218] Iteration 200 (0.0923788 iter/s, 541.25s/50 iters), loss = 7.96917
I1225 17:24:26.644115 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 17:24:26.644140 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 17:24:26.644155 61713 solver.cpp:238]     Train net output #2: loss = 7.96917 (* 1 = 7.96917 loss)
I1225 17:24:26.654433 61713 sgd_solver.cpp:105] Iteration 200, lr = 0.0001
I1225 17:33:05.492333 61713 solver.cpp:218] Iteration 250 (0.0963673 iter/s, 518.848s/50 iters), loss = 8.09416
I1225 17:33:05.492588 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 17:33:05.492607 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 17:33:05.492625 61713 solver.cpp:238]     Train net output #2: loss = 8.09416 (* 1 = 8.09416 loss)
I1225 17:33:05.502635 61713 sgd_solver.cpp:105] Iteration 250, lr = 0.0001
I1225 17:41:43.726406 61713 solver.cpp:331] Iteration 300, Testing net (#0)
I1225 17:42:07.724853 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 17:42:07.724963 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 17:42:07.724987 61713 solver.cpp:400]     Test net output #2: loss = 8.31917 (* 1 = 8.31917 loss)
I1225 17:42:17.621460 61713 solver.cpp:218] Iteration 300 (0.0905587 iter/s, 552.128s/50 iters), loss = 8.34417
I1225 17:42:17.621800 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 17:42:17.621816 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 17:42:17.621835 61713 solver.cpp:238]     Train net output #2: loss = 8.34417 (* 1 = 8.34417 loss)
I1225 17:42:17.631844 61713 sgd_solver.cpp:105] Iteration 300, lr = 0.0001
I1225 17:50:58.488548 61713 solver.cpp:218] Iteration 350 (0.095994 iter/s, 520.866s/50 iters), loss = 8.34417
I1225 17:50:58.488950 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 17:50:58.488984 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 17:50:58.489018 61713 solver.cpp:238]     Train net output #2: loss = 8.34417 (* 1 = 8.34417 loss)
I1225 17:50:58.499608 61713 sgd_solver.cpp:105] Iteration 350, lr = 0.0001
I1225 17:59:28.728265 61713 solver.cpp:331] Iteration 400, Testing net (#0)
I1225 17:59:52.630692 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 17:59:52.630823 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 17:59:52.630844 61713 solver.cpp:400]     Test net output #2: loss = 8.01721 (* 1 = 8.01721 loss)
I1225 18:00:02.402556 61713 solver.cpp:218] Iteration 400 (0.0919265 iter/s, 543.913s/50 iters), loss = 8.09221
I1225 18:00:02.402876 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 18:00:02.402894 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 18:00:02.402912 61713 solver.cpp:238]     Train net output #2: loss = 8.09221 (* 1 = 8.09221 loss)
I1225 18:00:02.412878 61713 sgd_solver.cpp:105] Iteration 400, lr = 0.0001
I1225 18:09:02.730839 61713 solver.cpp:218] Iteration 450 (0.0925366 iter/s, 540.327s/50 iters), loss = 8.71721
I1225 18:09:02.731082 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 18:09:02.731098 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 18:09:02.731117 61713 solver.cpp:238]     Train net output #2: loss = 8.71721 (* 1 = 8.71721 loss)
I1225 18:09:02.741204 61713 sgd_solver.cpp:105] Iteration 450, lr = 0.0001
I1225 18:17:46.179810 61713 solver.cpp:331] Iteration 500, Testing net (#0)
I1225 18:18:11.053328 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 18:18:11.053463 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 18:18:11.053483 61713 solver.cpp:400]     Test net output #2: loss = 8.17329 (* 1 = 8.17329 loss)
I1225 18:18:21.336307 61713 solver.cpp:218] Iteration 500 (0.0895087 iter/s, 558.605s/50 iters), loss = 8.58829
I1225 18:18:21.336508 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 18:18:21.336524 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 18:18:21.336542 61713 solver.cpp:238]     Train net output #2: loss = 8.58829 (* 1 = 8.58829 loss)
I1225 18:18:21.346567 61713 sgd_solver.cpp:105] Iteration 500, lr = 0.0001
I1225 18:27:11.825748 61713 solver.cpp:218] Iteration 550 (0.0942527 iter/s, 530.489s/50 iters), loss = 8.97283
I1225 18:27:11.826073 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 18:27:11.826092 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 18:27:11.826110 61713 solver.cpp:238]     Train net output #2: loss = 8.97283 (* 1 = 8.97283 loss)
I1225 18:27:11.836719 61713 sgd_solver.cpp:105] Iteration 550, lr = 0.0001
I1225 18:35:42.439805 61713 solver.cpp:331] Iteration 600, Testing net (#0)
I1225 18:36:06.931191 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 18:36:06.931309 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 18:36:06.931329 61713 solver.cpp:400]     Test net output #2: loss = 8.06055 (* 1 = 8.06055 loss)
I1225 18:36:16.809357 61713 solver.cpp:218] Iteration 600 (0.091746 iter/s, 544.983s/50 iters), loss = 8.34612
I1225 18:36:16.809670 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 18:36:16.809689 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 18:36:16.809707 61713 solver.cpp:238]     Train net output #2: loss = 8.34612 (* 1 = 8.34612 loss)
I1225 18:36:16.819705 61713 sgd_solver.cpp:105] Iteration 600, lr = 0.0001
I1225 18:44:53.831187 61713 solver.cpp:218] Iteration 650 (0.0967079 iter/s, 517.021s/50 iters), loss = 9.08829
I1225 18:44:53.831548 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 18:44:53.831573 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 18:44:53.831588 61713 solver.cpp:238]     Train net output #2: loss = 9.08829 (* 1 = 9.08829 loss)
I1225 18:44:53.841924 61713 sgd_solver.cpp:105] Iteration 650, lr = 0.0001
I1225 18:53:31.873059 61713 solver.cpp:331] Iteration 700, Testing net (#0)
I1225 18:53:55.897814 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 18:53:55.897940 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 18:53:55.897959 61713 solver.cpp:400]     Test net output #2: loss = 8.40112 (* 1 = 8.40112 loss)
I1225 18:54:05.762490 61713 solver.cpp:218] Iteration 700 (0.0905912 iter/s, 551.93s/50 iters), loss = 9.09612
I1225 18:54:05.762769 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 18:54:05.762784 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 18:54:05.762801 61713 solver.cpp:238]     Train net output #2: loss = 9.09612 (* 1 = 9.09612 loss)
I1225 18:54:05.772912 61713 sgd_solver.cpp:105] Iteration 700, lr = 0.0001
I1225 19:02:45.760141 61713 solver.cpp:218] Iteration 750 (0.0961544 iter/s, 519.997s/50 iters), loss = 8.59221
I1225 19:02:45.760385 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 19:02:45.760401 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 19:02:45.760417 61713 solver.cpp:238]     Train net output #2: loss = 8.59221 (* 1 = 8.59221 loss)
I1225 19:02:45.770450 61713 sgd_solver.cpp:105] Iteration 750, lr = 0.0001
I1225 19:11:17.062530 61713 solver.cpp:331] Iteration 800, Testing net (#0)
I1225 19:11:41.137761 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 19:11:41.137838 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 19:11:41.137857 61713 solver.cpp:400]     Test net output #2: loss = 8.17885 (* 1 = 8.17885 loss)
I1225 19:11:50.924898 61713 solver.cpp:218] Iteration 800 (0.0917155 iter/s, 545.164s/50 iters), loss = 7.96917
I1225 19:11:50.925165 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 19:11:50.925179 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 19:11:50.925197 61713 solver.cpp:238]     Train net output #2: loss = 7.96917 (* 1 = 7.96917 loss)
I1225 19:11:50.935055 61713 sgd_solver.cpp:105] Iteration 800, lr = 0.0001
I1225 19:21:26.553159 61713 solver.cpp:218] Iteration 850 (0.0868618 iter/s, 575.627s/50 iters), loss = 8.59221
I1225 19:21:26.553469 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 19:21:26.553503 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 19:21:26.553537 61713 solver.cpp:238]     Train net output #2: loss = 8.59221 (* 1 = 8.59221 loss)
I1225 19:21:26.564128 61713 sgd_solver.cpp:105] Iteration 850, lr = 0.0001
I1225 19:29:54.679420 61713 solver.cpp:331] Iteration 900, Testing net (#0)
I1225 19:30:18.568435 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 19:30:18.568522 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 19:30:18.568541 61713 solver.cpp:400]     Test net output #2: loss = 8.20507 (* 1 = 8.20507 loss)
I1225 19:30:28.318549 61713 solver.cpp:218] Iteration 900 (0.0922909 iter/s, 541.765s/50 iters), loss = 8.22501
I1225 19:30:28.318928 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 19:30:28.318953 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 19:30:28.318987 61713 solver.cpp:238]     Train net output #2: loss = 8.22501 (* 1 = 8.22501 loss)
I1225 19:30:28.328905 61713 sgd_solver.cpp:105] Iteration 900, lr = 0.0001
I1225 19:39:02.260614 61713 solver.cpp:218] Iteration 950 (0.0972874 iter/s, 513.941s/50 iters), loss = 8.09807
I1225 19:39:02.261052 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 19:39:02.261078 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 19:39:02.261092 61713 solver.cpp:238]     Train net output #2: loss = 8.09807 (* 1 = 8.09807 loss)
I1225 19:39:02.271189 61713 sgd_solver.cpp:105] Iteration 950, lr = 0.0001
I1225 19:47:26.336038 61713 solver.cpp:450] Snapshotting to binary proto file qnn_try1/QNN-train_iter_1000.caffemodel
I1225 19:47:29.072522 61713 sgd_solver.cpp:273] Snapshotting solver state to binary proto file qnn_try1/QNN-train_iter_1000.solverstate
I1225 19:47:31.401890 61713 solver.cpp:331] Iteration 1000, Testing net (#0)
I1225 19:47:55.565582 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 19:47:55.565659 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 19:47:55.565677 61713 solver.cpp:400]     Test net output #2: loss = 8.02501 (* 1 = 8.02501 loss)
I1225 19:48:05.321133 61713 solver.cpp:218] Iteration 1000 (0.0920709 iter/s, 543.06s/50 iters), loss = 8.35001
I1225 19:48:05.321499 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 19:48:05.321526 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 19:48:05.321539 61713 solver.cpp:238]     Train net output #2: loss = 8.35001 (* 1 = 8.35001 loss)
I1225 19:48:05.331547 61713 sgd_solver.cpp:105] Iteration 1000, lr = 0.0001
I1225 19:57:02.224378 61713 solver.cpp:218] Iteration 1050 (0.0931269 iter/s, 536.902s/50 iters), loss = 8.47501
I1225 19:57:02.224606 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 19:57:02.224629 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 19:57:02.224649 61713 solver.cpp:238]     Train net output #2: loss = 8.47501 (* 1 = 8.47501 loss)
I1225 19:57:02.234727 61713 sgd_solver.cpp:105] Iteration 1050, lr = 0.0001
I1225 20:05:51.677853 61713 solver.cpp:331] Iteration 1100, Testing net (#0)
I1225 20:06:16.430537 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 20:06:16.430608 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 20:06:16.430631 61713 solver.cpp:400]     Test net output #2: loss = 8.14618 (* 1 = 8.14618 loss)
I1225 20:06:26.990032 61713 solver.cpp:218] Iteration 1100 (0.0885324 iter/s, 564.765s/50 iters), loss = 7.97696
I1225 20:06:26.990311 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 20:06:26.990334 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 20:06:26.990355 61713 solver.cpp:238]     Train net output #2: loss = 7.97696 (* 1 = 7.97696 loss)
I1225 20:06:27.000375 61713 sgd_solver.cpp:105] Iteration 1100, lr = 0.0001
I1225 20:15:13.524828 61713 solver.cpp:218] Iteration 1150 (0.0949606 iter/s, 526.534s/50 iters), loss = 8.59417
I1225 20:15:13.525095 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 20:15:13.525117 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 20:15:13.525135 61713 solver.cpp:238]     Train net output #2: loss = 8.59417 (* 1 = 8.59417 loss)
I1225 20:15:13.535212 61713 sgd_solver.cpp:105] Iteration 1150, lr = 0.0001
I1225 20:23:46.031869 61713 solver.cpp:331] Iteration 1200, Testing net (#0)
I1225 20:24:17.903630 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 20:24:17.903970 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 20:24:17.904000 61713 solver.cpp:400]     Test net output #2: loss = 8.23242 (* 1 = 8.23242 loss)
I1225 20:24:36.960465 61713 solver.cpp:218] Iteration 1200 (0.0887414 iter/s, 563.435s/50 iters), loss = 7.85776
I1225 20:24:36.960543 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 20:24:36.960563 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 20:24:36.960588 61713 solver.cpp:238]     Train net output #2: loss = 7.85776 (* 1 = 7.85776 loss)
I1225 20:24:36.979226 61713 sgd_solver.cpp:105] Iteration 1200, lr = 0.0001
I1225 20:33:40.112237 61713 solver.cpp:218] Iteration 1250 (0.0920554 iter/s, 543.151s/50 iters), loss = 8.59417
I1225 20:33:40.112546 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 20:33:40.112565 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 20:33:40.112583 61713 solver.cpp:238]     Train net output #2: loss = 8.59417 (* 1 = 8.59417 loss)
I1225 20:33:40.122591 61713 sgd_solver.cpp:105] Iteration 1250, lr = 0.0001
I1225 20:42:18.653842 61713 solver.cpp:331] Iteration 1300, Testing net (#0)
I1225 20:42:42.743515 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 20:42:42.743584 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 20:42:42.743607 61713 solver.cpp:400]     Test net output #2: loss = 8.28112 (* 1 = 8.28112 loss)
I1225 20:42:52.716267 61713 solver.cpp:218] Iteration 1300 (0.0904809 iter/s, 552.603s/50 iters), loss = 7.72112
I1225 20:42:52.716572 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 20:42:52.716594 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 20:42:52.716614 61713 solver.cpp:238]     Train net output #2: loss = 7.72112 (* 1 = 7.72112 loss)
I1225 20:42:52.726853 61713 sgd_solver.cpp:105] Iteration 1300, lr = 0.0001
I1225 20:52:02.080955 61713 solver.cpp:218] Iteration 1350 (0.0910143 iter/s, 549.364s/50 iters), loss = 8.35196
I1225 20:52:02.081248 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 20:52:02.081266 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 20:52:02.081284 61713 solver.cpp:238]     Train net output #2: loss = 8.35196 (* 1 = 8.35196 loss)
I1225 20:52:02.091266 61713 sgd_solver.cpp:105] Iteration 1350, lr = 0.0001
I1225 21:01:02.277153 61713 solver.cpp:331] Iteration 1400, Testing net (#0)
I1225 21:01:26.159067 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 21:01:26.159176 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 21:01:26.159199 61713 solver.cpp:400]     Test net output #2: loss = 8.24501 (* 1 = 8.24501 loss)
I1225 21:01:35.994108 61713 solver.cpp:218] Iteration 1400 (0.0871214 iter/s, 573.912s/50 iters), loss = 8.22501
I1225 21:01:35.994364 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 21:01:35.994379 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 21:01:35.994396 61713 solver.cpp:238]     Train net output #2: loss = 8.22501 (* 1 = 8.22501 loss)
I1225 21:01:36.004425 61713 sgd_solver.cpp:105] Iteration 1400, lr = 0.0001
I1225 21:10:15.399663 61713 solver.cpp:218] Iteration 1450 (0.096264 iter/s, 519.405s/50 iters), loss = 7.84612
I1225 21:10:15.399982 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 21:10:15.400018 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 21:10:15.400045 61713 solver.cpp:238]     Train net output #2: loss = 7.84612 (* 1 = 7.84612 loss)
I1225 21:10:15.410022 61713 sgd_solver.cpp:105] Iteration 1450, lr = 0.0001
I1225 21:18:39.245033 61713 solver.cpp:331] Iteration 1500, Testing net (#0)
I1225 21:19:03.094801 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 21:19:03.094908 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 21:19:03.094926 61713 solver.cpp:400]     Test net output #2: loss = 8.47917 (* 1 = 8.47917 loss)
I1225 21:19:12.914283 61713 solver.cpp:218] Iteration 1500 (0.0930208 iter/s, 537.514s/50 iters), loss = 7.71917
I1225 21:19:12.914541 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 21:19:12.914554 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 21:19:12.914572 61713 solver.cpp:238]     Train net output #2: loss = 7.71917 (* 1 = 7.71917 loss)
I1225 21:19:12.924491 61713 sgd_solver.cpp:105] Iteration 1500, lr = 0.0001
I1225 21:27:44.796389 61713 solver.cpp:218] Iteration 1550 (0.097679 iter/s, 511.881s/50 iters), loss = 8.23082
I1225 21:27:44.796602 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 21:27:44.796617 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 21:27:44.796654 61713 solver.cpp:238]     Train net output #2: loss = 8.23082 (* 1 = 8.23082 loss)
I1225 21:27:44.806550 61713 sgd_solver.cpp:105] Iteration 1550, lr = 0.0001
I1225 21:36:06.266893 61713 solver.cpp:331] Iteration 1600, Testing net (#0)
I1225 21:36:30.065721 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 21:36:30.065788 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 21:36:30.065805 61713 solver.cpp:400]     Test net output #2: loss = 8.51917 (* 1 = 8.51917 loss)
I1225 21:36:39.826756 61713 solver.cpp:218] Iteration 1600 (0.0934527 iter/s, 535.03s/50 iters), loss = 8.34453
I1225 21:36:39.827004 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 21:36:39.827029 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 21:36:39.827049 61713 solver.cpp:238]     Train net output #2: loss = 8.34453 (* 1 = 8.34453 loss)
I1225 21:36:39.836937 61713 sgd_solver.cpp:105] Iteration 1600, lr = 0.0001
I1225 21:45:11.565064 61713 solver.cpp:218] Iteration 1650 (0.0977062 iter/s, 511.738s/50 iters), loss = 8.59612
I1225 21:45:11.565366 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 21:45:11.565400 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 21:45:11.565418 61713 solver.cpp:238]     Train net output #2: loss = 8.59612 (* 1 = 8.59612 loss)
I1225 21:45:11.576005 61713 sgd_solver.cpp:105] Iteration 1650, lr = 0.0001
I1225 21:53:35.826925 61713 solver.cpp:331] Iteration 1700, Testing net (#0)
I1225 21:53:59.586851 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 21:53:59.586920 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 21:53:59.586937 61713 solver.cpp:400]     Test net output #2: loss = 8.63083 (* 1 = 8.63083 loss)
I1225 21:54:09.303958 61713 solver.cpp:218] Iteration 1700 (0.0929821 iter/s, 537.738s/50 iters), loss = 8.23082
I1225 21:54:09.304225 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 21:54:09.304251 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 21:54:09.304265 61713 solver.cpp:238]     Train net output #2: loss = 8.23082 (* 1 = 8.23082 loss)
I1225 21:54:09.314541 61713 sgd_solver.cpp:105] Iteration 1700, lr = 0.0001
I1225 22:02:48.005276 61713 solver.cpp:218] Iteration 1750 (0.0963947 iter/s, 518.701s/50 iters), loss = 8.20737
I1225 22:02:48.005581 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 22:02:48.005597 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 22:02:48.005615 61713 solver.cpp:238]     Train net output #2: loss = 8.20737 (* 1 = 8.20737 loss)
I1225 22:02:48.015457 61713 sgd_solver.cpp:105] Iteration 1750, lr = 0.0001
I1225 22:11:22.557376 61713 solver.cpp:331] Iteration 1800, Testing net (#0)
I1225 22:11:46.852108 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 22:11:46.852183 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 22:11:46.852206 61713 solver.cpp:400]     Test net output #2: loss = 8.20935 (* 1 = 8.20935 loss)
I1225 22:11:56.869652 61713 solver.cpp:218] Iteration 1800 (0.0910972 iter/s, 548.864s/50 iters), loss = 8.58435
I1225 22:11:56.869901 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 22:11:56.869916 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 22:11:56.869935 61713 solver.cpp:238]     Train net output #2: loss = 8.58435 (* 1 = 8.58435 loss)
I1225 22:11:56.880080 61713 sgd_solver.cpp:105] Iteration 1800, lr = 0.0001
I1225 22:20:40.425230 61713 solver.cpp:218] Iteration 1850 (0.095501 iter/s, 523.555s/50 iters), loss = 8.10196
I1225 22:20:40.425479 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 22:20:40.425495 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 22:20:40.425513 61713 solver.cpp:238]     Train net output #2: loss = 8.10196 (* 1 = 8.10196 loss)
I1225 22:20:40.435591 61713 sgd_solver.cpp:105] Iteration 1850, lr = 0.0001
I1225 22:29:12.149119 61713 solver.cpp:331] Iteration 1900, Testing net (#0)
I1225 22:29:36.479827 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 22:29:36.479902 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 22:29:36.479924 61713 solver.cpp:400]     Test net output #2: loss = 8.24889 (* 1 = 8.24889 loss)
I1225 22:29:46.478325 61713 solver.cpp:218] Iteration 1900 (0.0915664 iter/s, 546.052s/50 iters), loss = 7.97889
I1225 22:29:46.478605 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 22:29:46.478623 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 22:29:46.478641 61713 solver.cpp:238]     Train net output #2: loss = 7.97889 (* 1 = 7.97889 loss)
I1225 22:29:46.488770 61713 sgd_solver.cpp:105] Iteration 1900, lr = 0.0001
I1225 22:38:28.462347 61713 solver.cpp:218] Iteration 1950 (0.0957886 iter/s, 521.983s/50 iters), loss = 8.47501
I1225 22:38:28.462591 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 22:38:28.462608 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 22:38:28.462626 61713 solver.cpp:238]     Train net output #2: loss = 8.47501 (* 1 = 8.47501 loss)
I1225 22:38:28.472723 61713 sgd_solver.cpp:105] Iteration 1950, lr = 0.0001
I1225 22:47:01.290426 61713 solver.cpp:450] Snapshotting to binary proto file qnn_try1/QNN-train_iter_2000.caffemodel
I1225 22:47:04.070849 61713 sgd_solver.cpp:273] Snapshotting solver state to binary proto file qnn_try1/QNN-train_iter_2000.solverstate
I1225 22:47:06.533013 61713 solver.cpp:331] Iteration 2000, Testing net (#0)
I1225 22:47:30.503633 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 22:47:30.503765 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 22:47:30.503784 61713 solver.cpp:400]     Test net output #2: loss = 8.07706 (* 1 = 8.07706 loss)
I1225 22:47:40.255776 61713 solver.cpp:218] Iteration 2000 (0.0906137 iter/s, 551.793s/50 iters), loss = 8.21473
I1225 22:47:40.256034 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 22:47:40.256050 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 22:47:40.256067 61713 solver.cpp:238]     Train net output #2: loss = 8.21473 (* 1 = 8.21473 loss)
I1225 22:47:40.265931 61713 sgd_solver.cpp:105] Iteration 2000, lr = 0.0001
I1225 22:56:21.787212 61713 solver.cpp:218] Iteration 2050 (0.0958716 iter/s, 521.531s/50 iters), loss = 8.21917
I1225 22:56:21.787494 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 22:56:21.787513 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 22:56:21.787530 61713 solver.cpp:238]     Train net output #2: loss = 8.21917 (* 1 = 8.21917 loss)
I1225 22:56:21.797518 61713 sgd_solver.cpp:105] Iteration 2050, lr = 0.0001
I1225 23:04:52.784612 61713 solver.cpp:331] Iteration 2100, Testing net (#0)
I1225 23:05:16.995470 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 23:05:16.995581 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 23:05:16.995600 61713 solver.cpp:400]     Test net output #2: loss = 8.48695 (* 1 = 8.48695 loss)
I1225 23:05:26.978269 61713 solver.cpp:218] Iteration 2100 (0.0917111 iter/s, 545.19s/50 iters), loss = 8.72696
I1225 23:05:26.978549 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 23:05:26.978569 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 23:05:26.978587 61713 solver.cpp:238]     Train net output #2: loss = 8.72696 (* 1 = 8.72696 loss)
I1225 23:05:26.988646 61713 sgd_solver.cpp:105] Iteration 2100, lr = 0.0001
I1225 23:14:07.588979 61713 solver.cpp:218] Iteration 2150 (0.0960412 iter/s, 520.61s/50 iters), loss = 8.46721
I1225 23:14:07.589329 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 23:14:07.589362 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 23:14:07.589385 61713 solver.cpp:238]     Train net output #2: loss = 8.46721 (* 1 = 8.46721 loss)
I1225 23:14:07.599975 61713 sgd_solver.cpp:105] Iteration 2150, lr = 0.0001
I1225 23:22:38.270000 61713 solver.cpp:331] Iteration 2200, Testing net (#0)
I1225 23:23:02.431972 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 23:23:02.432049 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 23:23:02.432070 61713 solver.cpp:400]     Test net output #2: loss = 8.23721 (* 1 = 8.23721 loss)
I1225 23:23:12.382263 61713 solver.cpp:218] Iteration 2200 (0.0917781 iter/s, 544.792s/50 iters), loss = 8.09221
I1225 23:23:12.382475 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 23:23:12.382490 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 23:23:12.382508 61713 solver.cpp:238]     Train net output #2: loss = 8.09221 (* 1 = 8.09221 loss)
I1225 23:23:12.392581 61713 sgd_solver.cpp:105] Iteration 2200, lr = 0.0001
I1225 23:31:55.244201 61713 solver.cpp:218] Iteration 2250 (0.0956277 iter/s, 522.861s/50 iters), loss = 8.47696
I1225 23:31:55.244477 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 23:31:55.244493 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 23:31:55.244510 61713 solver.cpp:238]     Train net output #2: loss = 8.47696 (* 1 = 8.47696 loss)
I1225 23:31:55.254547 61713 sgd_solver.cpp:105] Iteration 2250, lr = 0.0001
I1225 23:40:25.934897 61713 solver.cpp:331] Iteration 2300, Testing net (#0)
I1225 23:40:49.811266 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 23:40:49.811339 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 23:40:49.811357 61713 solver.cpp:400]     Test net output #2: loss = 8.24695 (* 1 = 8.24695 loss)
I1225 23:40:59.685353 61713 solver.cpp:218] Iteration 2300 (0.0918375 iter/s, 544.44s/50 iters), loss = 8.72696
I1225 23:40:59.685600 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 23:40:59.685614 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 23:40:59.685631 61713 solver.cpp:238]     Train net output #2: loss = 8.72696 (* 1 = 8.72696 loss)
I1225 23:40:59.695763 61713 sgd_solver.cpp:105] Iteration 2300, lr = 0.0001
I1225 23:49:37.987366 61713 solver.cpp:218] Iteration 2350 (0.096469 iter/s, 518.301s/50 iters), loss = 8.34417
I1225 23:49:37.987658 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 23:49:37.987673 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 23:49:37.987689 61713 solver.cpp:238]     Train net output #2: loss = 8.34417 (* 1 = 8.34417 loss)
I1225 23:49:37.997711 61713 sgd_solver.cpp:105] Iteration 2350, lr = 0.0001
I1225 23:58:04.271090 61713 solver.cpp:331] Iteration 2400, Testing net (#0)
I1225 23:58:27.980481 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1225 23:58:27.980554 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1225 23:58:27.980571 61713 solver.cpp:400]     Test net output #2: loss = 7.83917 (* 1 = 7.83917 loss)
I1225 23:58:37.709220 61713 solver.cpp:218] Iteration 2400 (0.0926405 iter/s, 539.721s/50 iters), loss = 7.96916
I1225 23:58:37.709517 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1225 23:58:37.709552 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1225 23:58:37.709584 61713 solver.cpp:238]     Train net output #2: loss = 7.96916 (* 1 = 7.96916 loss)
I1225 23:58:37.720170 61713 sgd_solver.cpp:105] Iteration 2400, lr = 0.0001
I1226 00:07:11.507992 61713 solver.cpp:218] Iteration 2450 (0.0973145 iter/s, 513.798s/50 iters), loss = 7.71703
I1226 00:07:11.521741 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 00:07:11.521760 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 00:07:11.521780 61713 solver.cpp:238]     Train net output #2: loss = 7.71703 (* 1 = 7.71703 loss)
I1226 00:07:11.532034 61713 sgd_solver.cpp:105] Iteration 2450, lr = 0.0001
I1226 00:15:35.112998 61713 solver.cpp:331] Iteration 2500, Testing net (#0)
I1226 00:15:58.834725 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 00:15:58.834795 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 00:15:58.834817 61713 solver.cpp:400]     Test net output #2: loss = 8.57917 (* 1 = 8.57917 loss)
I1226 00:16:08.634194 61713 solver.cpp:218] Iteration 2500 (0.0930905 iter/s, 537.112s/50 iters), loss = 8.71917
I1226 00:16:08.634464 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 00:16:08.634490 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 00:16:08.634508 61713 solver.cpp:238]     Train net output #2: loss = 8.71917 (* 1 = 8.71917 loss)
I1226 00:16:08.644626 61713 sgd_solver.cpp:105] Iteration 2500, lr = 0.0001
I1226 00:25:00.898527 61713 solver.cpp:218] Iteration 2550 (0.0939384 iter/s, 532.264s/50 iters), loss = 8.22307
I1226 00:25:00.902616 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 00:25:00.902637 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 00:25:00.902655 61713 solver.cpp:238]     Train net output #2: loss = 8.22307 (* 1 = 8.22307 loss)
I1226 00:25:00.912746 61713 sgd_solver.cpp:105] Iteration 2550, lr = 0.0001
I1226 00:33:48.665254 61713 solver.cpp:331] Iteration 2600, Testing net (#0)
I1226 00:34:12.485411 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 00:34:12.485486 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 00:34:12.485507 61713 solver.cpp:400]     Test net output #2: loss = 7.98889 (* 1 = 7.98889 loss)
I1226 00:34:22.354656 61713 solver.cpp:218] Iteration 2600 (0.0890548 iter/s, 561.452s/50 iters), loss = 8.72889
I1226 00:34:22.354872 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 00:34:22.354894 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 00:34:22.354912 61713 solver.cpp:238]     Train net output #2: loss = 8.72889 (* 1 = 8.72889 loss)
I1226 00:34:22.365068 61713 sgd_solver.cpp:105] Iteration 2600, lr = 0.0001
I1226 00:43:05.028322 61713 solver.cpp:218] Iteration 2650 (0.0956621 iter/s, 522.673s/50 iters), loss = 8.23276
I1226 00:43:05.028611 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 00:43:05.028645 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 00:43:05.028673 61713 solver.cpp:238]     Train net output #2: loss = 8.23276 (* 1 = 8.23276 loss)
I1226 00:43:05.038506 61713 sgd_solver.cpp:105] Iteration 2650, lr = 0.0001
I1226 00:51:34.724932 61713 solver.cpp:331] Iteration 2700, Testing net (#0)
I1226 00:51:58.994401 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 00:51:58.994513 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 00:51:58.994534 61713 solver.cpp:400]     Test net output #2: loss = 8.41651 (* 1 = 8.41651 loss)
I1226 00:52:09.031157 61713 solver.cpp:218] Iteration 2700 (0.0919114 iter/s, 544.002s/50 iters), loss = 8.71721
I1226 00:52:09.031432 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 00:52:09.031458 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 00:52:09.031473 61713 solver.cpp:238]     Train net output #2: loss = 8.71721 (* 1 = 8.71721 loss)
I1226 00:52:09.041564 61713 sgd_solver.cpp:105] Iteration 2700, lr = 0.0001
I1226 01:00:47.787194 61713 solver.cpp:218] Iteration 2750 (0.0963846 iter/s, 518.755s/50 iters), loss = 8.10001
I1226 01:00:47.787514 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 01:00:47.787540 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 01:00:47.787554 61713 solver.cpp:238]     Train net output #2: loss = 8.10001 (* 1 = 8.10001 loss)
I1226 01:00:47.799674 61713 sgd_solver.cpp:105] Iteration 2750, lr = 0.0001
I1226 01:09:14.709321 61713 solver.cpp:331] Iteration 2800, Testing net (#0)
I1226 01:09:40.173218 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 01:09:40.173336 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 01:09:40.173359 61713 solver.cpp:400]     Test net output #2: loss = 8.23468 (* 1 = 8.23468 loss)
I1226 01:09:50.104956 61713 solver.cpp:218] Iteration 2800 (0.092197 iter/s, 542.317s/50 iters), loss = 8.48468
I1226 01:09:50.105211 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 01:09:50.105248 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 01:09:50.105267 61713 solver.cpp:238]     Train net output #2: loss = 8.48468 (* 1 = 8.48468 loss)
I1226 01:09:50.115870 61713 sgd_solver.cpp:105] Iteration 2800, lr = 0.0001
I1226 01:18:27.753934 61713 solver.cpp:218] Iteration 2850 (0.0965907 iter/s, 517.648s/50 iters), loss = 7.48852
I1226 01:18:27.754230 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 01:18:27.754266 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 01:18:27.754298 61713 solver.cpp:238]     Train net output #2: loss = 7.48852 (* 1 = 7.48852 loss)
I1226 01:18:27.764889 61713 sgd_solver.cpp:105] Iteration 2850, lr = 0.0001
I1226 01:26:52.584575 61713 solver.cpp:331] Iteration 2900, Testing net (#0)
I1226 01:27:16.395581 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 01:27:16.395711 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 01:27:16.395735 61713 solver.cpp:400]     Test net output #2: loss = 8.23082 (* 1 = 8.23082 loss)
I1226 01:27:26.123400 61713 solver.cpp:218] Iteration 2900 (0.0928731 iter/s, 538.369s/50 iters), loss = 8.48082
I1226 01:27:26.123711 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 01:27:26.123749 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 01:27:26.123766 61713 solver.cpp:238]     Train net output #2: loss = 8.48082 (* 1 = 8.48082 loss)
I1226 01:27:26.134348 61713 sgd_solver.cpp:105] Iteration 2900, lr = 0.0001
I1226 01:36:04.277014 61713 solver.cpp:218] Iteration 2950 (0.0964966 iter/s, 518.153s/50 iters), loss = 9.08829
I1226 01:36:04.277200 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 01:36:04.277235 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 01:36:04.277268 61713 solver.cpp:238]     Train net output #2: loss = 9.08829 (* 1 = 9.08829 loss)
I1226 01:36:04.287866 61713 sgd_solver.cpp:105] Iteration 2950, lr = 0.0001
I1226 01:44:38.665662 61713 solver.cpp:450] Snapshotting to binary proto file qnn_try1/QNN-train_iter_3000.caffemodel
I1226 01:44:41.164876 61713 sgd_solver.cpp:273] Snapshotting solver state to binary proto file qnn_try1/QNN-train_iter_3000.solverstate
I1226 01:44:43.450120 61713 solver.cpp:331] Iteration 3000, Testing net (#0)
I1226 01:45:07.337644 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 01:45:07.337716 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 01:45:07.337738 61713 solver.cpp:400]     Test net output #2: loss = 8.22112 (* 1 = 8.22112 loss)
I1226 01:45:17.162607 61713 solver.cpp:218] Iteration 3000 (0.0904347 iter/s, 552.885s/50 iters), loss = 8.59612
I1226 01:45:17.162906 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 01:45:17.162922 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 01:45:17.162940 61713 solver.cpp:238]     Train net output #2: loss = 8.59612 (* 1 = 8.59612 loss)
I1226 01:45:17.173012 61713 sgd_solver.cpp:105] Iteration 3000, lr = 0.0001
I1226 01:53:55.696908 61713 solver.cpp:218] Iteration 3050 (0.0964259 iter/s, 518.533s/50 iters), loss = 7.47696
I1226 01:53:55.697181 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 01:53:55.697196 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 01:53:55.697213 61713 solver.cpp:238]     Train net output #2: loss = 7.47696 (* 1 = 7.47696 loss)
I1226 01:53:55.707213 61713 sgd_solver.cpp:105] Iteration 3050, lr = 0.0001
I1226 02:02:27.511338 61713 solver.cpp:331] Iteration 3100, Testing net (#0)
I1226 02:02:51.531710 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 02:02:51.531800 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 02:02:51.531818 61713 solver.cpp:400]     Test net output #2: loss = 8.22112 (* 1 = 8.22112 loss)
I1226 02:03:01.474256 61713 solver.cpp:218] Iteration 3100 (0.0916125 iter/s, 545.777s/50 iters), loss = 8.47106
I1226 02:03:01.474536 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 02:03:01.474552 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 02:03:01.474570 61713 solver.cpp:238]     Train net output #2: loss = 8.47106 (* 1 = 8.47106 loss)
I1226 02:03:01.484577 61713 sgd_solver.cpp:105] Iteration 3100, lr = 0.0001
I1226 02:11:44.377825 61713 solver.cpp:218] Iteration 3150 (0.09562 iter/s, 522.903s/50 iters), loss = 8.10776
I1226 02:11:44.466369 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 02:11:44.466387 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 02:11:44.466405 61713 solver.cpp:238]     Train net output #2: loss = 8.10776 (* 1 = 8.10776 loss)
I1226 02:11:44.476347 61713 sgd_solver.cpp:105] Iteration 3150, lr = 0.0001
I1226 02:20:13.746273 61713 solver.cpp:331] Iteration 3200, Testing net (#0)
I1226 02:20:37.940238 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 02:20:37.940354 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 02:20:37.940377 61713 solver.cpp:400]     Test net output #2: loss = 8.26889 (* 1 = 8.26889 loss)
I1226 02:20:47.923616 61713 solver.cpp:218] Iteration 3200 (0.0920036 iter/s, 543.457s/50 iters), loss = 7.60341
I1226 02:20:47.923884 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 02:20:47.923902 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 02:20:47.923920 61713 solver.cpp:238]     Train net output #2: loss = 7.60341 (* 1 = 7.60341 loss)
I1226 02:20:47.933912 61713 sgd_solver.cpp:105] Iteration 3200, lr = 0.0001
I1226 02:29:27.920392 61713 solver.cpp:218] Iteration 3250 (0.0961546 iter/s, 519.996s/50 iters), loss = 8.34025
I1226 02:29:27.920639 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 02:29:27.920660 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 02:29:27.920677 61713 solver.cpp:238]     Train net output #2: loss = 8.34025 (* 1 = 8.34025 loss)
I1226 02:29:27.930752 61713 sgd_solver.cpp:105] Iteration 3250, lr = 0.0001
I1226 02:37:51.319473 61713 solver.cpp:331] Iteration 3300, Testing net (#0)
I1226 02:38:15.248270 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 02:38:15.248342 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 02:38:15.248360 61713 solver.cpp:400]     Test net output #2: loss = 8.14235 (* 1 = 8.14235 loss)
I1226 02:38:25.003255 61713 solver.cpp:218] Iteration 3300 (0.0930957 iter/s, 537.082s/50 iters), loss = 7.99235
I1226 02:38:25.003496 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 02:38:25.003522 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 02:38:25.003537 61713 solver.cpp:238]     Train net output #2: loss = 7.99235 (* 1 = 7.99235 loss)
I1226 02:38:25.013809 61713 sgd_solver.cpp:105] Iteration 3300, lr = 0.0001
I1226 02:47:05.473845 61713 solver.cpp:218] Iteration 3350 (0.096067 iter/s, 520.47s/50 iters), loss = 7.73009
I1226 02:47:05.474155 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 02:47:05.474171 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 02:47:05.474187 61713 solver.cpp:238]     Train net output #2: loss = 7.73009 (* 1 = 7.73009 loss)
I1226 02:47:05.484364 61713 sgd_solver.cpp:105] Iteration 3350, lr = 0.0001
I1226 02:55:36.300719 61713 solver.cpp:331] Iteration 3400, Testing net (#0)
I1226 02:56:00.477061 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 02:56:00.477134 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 02:56:00.477154 61713 solver.cpp:400]     Test net output #2: loss = 8.41276 (* 1 = 8.41276 loss)
I1226 02:56:10.432382 61713 solver.cpp:218] Iteration 3400 (0.0917502 iter/s, 544.958s/50 iters), loss = 8.23276
I1226 02:56:10.432641 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 02:56:10.432662 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 02:56:10.432679 61713 solver.cpp:238]     Train net output #2: loss = 8.23276 (* 1 = 8.23276 loss)
I1226 02:56:10.442733 61713 sgd_solver.cpp:105] Iteration 3400, lr = 0.0001
I1226 03:04:51.094591 61713 solver.cpp:218] Iteration 3450 (0.0960318 iter/s, 520.661s/50 iters), loss = 8.2366
I1226 03:04:51.094859 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 03:04:51.094875 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 03:04:51.094892 61713 solver.cpp:238]     Train net output #2: loss = 8.2366 (* 1 = 8.2366 loss)
I1226 03:04:51.104729 61713 sgd_solver.cpp:105] Iteration 3450, lr = 0.0001
I1226 03:13:25.027047 61713 solver.cpp:331] Iteration 3500, Testing net (#0)
I1226 03:13:49.000044 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 03:13:49.000118 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 03:13:49.000138 61713 solver.cpp:400]     Test net output #2: loss = 8.09921 (* 1 = 8.09921 loss)
I1226 03:13:58.781844 61713 solver.cpp:218] Iteration 3500 (0.0912932 iter/s, 547.686s/50 iters), loss = 8.71917
I1226 03:13:58.782068 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 03:13:58.782104 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 03:13:58.782138 61713 solver.cpp:238]     Train net output #2: loss = 8.71917 (* 1 = 8.71917 loss)
I1226 03:13:58.792738 61713 sgd_solver.cpp:105] Iteration 3500, lr = 0.0001
I1226 03:22:48.451282 61713 solver.cpp:218] Iteration 3550 (0.0943986 iter/s, 529.669s/50 iters), loss = 7.84417
I1226 03:22:48.451601 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 03:22:48.451637 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 03:22:48.451670 61713 solver.cpp:238]     Train net output #2: loss = 7.84417 (* 1 = 7.84417 loss)
I1226 03:22:48.462239 61713 sgd_solver.cpp:105] Iteration 3550, lr = 0.0001
I1226 03:31:14.946668 61713 solver.cpp:331] Iteration 3600, Testing net (#0)
I1226 03:31:39.774369 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 03:31:39.774446 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 03:31:39.774464 61713 solver.cpp:400]     Test net output #2: loss = 8.11509 (* 1 = 8.11509 loss)
I1226 03:31:49.799633 61713 solver.cpp:218] Iteration 3600 (0.092362 iter/s, 541.348s/50 iters), loss = 7.71525
I1226 03:31:49.799875 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 03:31:49.799893 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 03:31:49.799911 61713 solver.cpp:238]     Train net output #2: loss = 7.71525 (* 1 = 7.71525 loss)
I1226 03:31:49.809792 61713 sgd_solver.cpp:105] Iteration 3600, lr = 0.0001
I1226 03:40:34.789044 61713 solver.cpp:218] Iteration 3650 (0.0952401 iter/s, 524.989s/50 iters), loss = 8.59807
I1226 03:40:34.789352 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 03:40:34.789383 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 03:40:34.789400 61713 solver.cpp:238]     Train net output #2: loss = 8.59807 (* 1 = 8.59807 loss)
I1226 03:40:34.799986 61713 sgd_solver.cpp:105] Iteration 3650, lr = 0.0001
I1226 03:49:04.325889 61713 solver.cpp:331] Iteration 3700, Testing net (#0)
I1226 03:49:28.553591 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 03:49:28.553724 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 03:49:28.553743 61713 solver.cpp:400]     Test net output #2: loss = 8.05721 (* 1 = 8.05721 loss)
I1226 03:49:38.515341 61713 solver.cpp:218] Iteration 3700 (0.0919583 iter/s, 543.725s/50 iters), loss = 8.09221
I1226 03:49:38.515614 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 03:49:38.515627 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 03:49:38.515646 61713 solver.cpp:238]     Train net output #2: loss = 8.09221 (* 1 = 8.09221 loss)
I1226 03:49:38.525724 61713 sgd_solver.cpp:105] Iteration 3700, lr = 0.0001
I1226 03:58:20.117728 61713 solver.cpp:218] Iteration 3750 (0.0958585 iter/s, 521.602s/50 iters), loss = 8.22112
I1226 03:58:20.117947 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 03:58:20.117969 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 03:58:20.117990 61713 solver.cpp:238]     Train net output #2: loss = 8.22112 (* 1 = 8.22112 loss)
I1226 03:58:20.128114 61713 sgd_solver.cpp:105] Iteration 3750, lr = 0.0001
I1226 04:06:49.216233 61713 solver.cpp:331] Iteration 3800, Testing net (#0)
I1226 04:07:13.348707 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 04:07:13.348785 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 04:07:13.348803 61713 solver.cpp:400]     Test net output #2: loss = 8.12501 (* 1 = 8.12501 loss)
I1226 04:07:23.125982 61713 solver.cpp:218] Iteration 3800 (0.0920797 iter/s, 543.008s/50 iters), loss = 7.72501
I1226 04:07:23.126277 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 04:07:23.126307 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 04:07:23.126340 61713 solver.cpp:238]     Train net output #2: loss = 7.72501 (* 1 = 7.72501 loss)
I1226 04:07:23.136927 61713 sgd_solver.cpp:105] Iteration 3800, lr = 0.0001
I1226 04:16:03.835774 61713 solver.cpp:218] Iteration 3850 (0.0960229 iter/s, 520.709s/50 iters), loss = 8.23852
I1226 04:16:03.912408 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 04:16:03.912425 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 04:16:03.912438 61713 solver.cpp:238]     Train net output #2: loss = 8.23852 (* 1 = 8.23852 loss)
I1226 04:16:03.922494 61713 sgd_solver.cpp:105] Iteration 3850, lr = 0.0001
I1226 04:24:41.791900 61713 solver.cpp:331] Iteration 3900, Testing net (#0)
I1226 04:25:05.917163 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 04:25:05.917240 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 04:25:05.917263 61713 solver.cpp:400]     Test net output #2: loss = 8.05721 (* 1 = 8.05721 loss)
I1226 04:25:15.736690 61713 solver.cpp:218] Iteration 3900 (0.0906086 iter/s, 551.824s/50 iters), loss = 7.71721
I1226 04:25:15.736891 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 04:25:15.736913 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 04:25:15.736933 61713 solver.cpp:238]     Train net output #2: loss = 7.71721 (* 1 = 7.71721 loss)
I1226 04:25:15.746786 61713 sgd_solver.cpp:105] Iteration 3900, lr = 0.0001
I1226 04:33:58.634078 61713 solver.cpp:218] Iteration 3950 (0.0956211 iter/s, 522.897s/50 iters), loss = 7.72889
I1226 04:33:58.634348 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 04:33:58.634373 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 04:33:58.634393 61713 solver.cpp:238]     Train net output #2: loss = 7.72889 (* 1 = 7.72889 loss)
I1226 04:33:58.644469 61713 sgd_solver.cpp:105] Iteration 3950, lr = 0.0001
I1226 04:42:30.418835 61713 solver.cpp:450] Snapshotting to binary proto file qnn_try1/QNN-train_iter_4000.caffemodel
I1226 04:42:33.423620 61713 sgd_solver.cpp:273] Snapshotting solver state to binary proto file qnn_try1/QNN-train_iter_4000.solverstate
I1226 04:42:35.164139 61713 solver.cpp:331] Iteration 4000, Testing net (#0)
I1226 04:42:59.343508 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 04:42:59.343585 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 04:42:59.343607 61713 solver.cpp:400]     Test net output #2: loss = 8.37696 (* 1 = 8.37696 loss)
I1226 04:43:09.301496 61713 solver.cpp:218] Iteration 4000 (0.090799 iter/s, 550.667s/50 iters), loss = 8.59221
I1226 04:43:09.301695 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 04:43:09.301717 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 04:43:09.301735 61713 solver.cpp:238]     Train net output #2: loss = 8.59221 (* 1 = 8.59221 loss)
I1226 04:43:09.311822 61713 sgd_solver.cpp:105] Iteration 4000, lr = 0.0001
I1226 04:51:51.940610 61713 solver.cpp:218] Iteration 4050 (0.0956685 iter/s, 522.638s/50 iters), loss = 8.09612
I1226 04:51:51.940874 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 04:51:51.940891 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 04:51:51.940907 61713 solver.cpp:238]     Train net output #2: loss = 8.09612 (* 1 = 8.09612 loss)
I1226 04:51:51.951117 61713 sgd_solver.cpp:105] Iteration 4050, lr = 0.0001
I1226 05:00:25.721598 61713 solver.cpp:331] Iteration 4100, Testing net (#0)
I1226 05:00:50.035900 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 05:00:50.035967 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 05:00:50.035990 61713 solver.cpp:400]     Test net output #2: loss = 8.02889 (* 1 = 8.02889 loss)
I1226 05:01:00.046017 61713 solver.cpp:218] Iteration 4100 (0.0912234 iter/s, 548.105s/50 iters), loss = 7.97889
I1226 05:01:00.046249 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 05:01:00.046265 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 05:01:00.046283 61713 solver.cpp:238]     Train net output #2: loss = 7.97889 (* 1 = 7.97889 loss)
I1226 05:01:00.056434 61713 sgd_solver.cpp:105] Iteration 4100, lr = 0.0001
I1226 05:09:43.166244 61713 solver.cpp:218] Iteration 4150 (0.0955805 iter/s, 523.119s/50 iters), loss = 8.08435
I1226 05:09:43.244489 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 05:09:43.244509 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 05:09:43.244527 61713 solver.cpp:238]     Train net output #2: loss = 8.08435 (* 1 = 8.08435 loss)
I1226 05:09:43.254513 61713 sgd_solver.cpp:105] Iteration 4150, lr = 0.0001
I1226 05:18:15.025027 61713 solver.cpp:331] Iteration 4200, Testing net (#0)
I1226 05:18:39.210573 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 05:18:39.210680 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 05:18:39.210700 61713 solver.cpp:400]     Test net output #2: loss = 8.17723 (* 1 = 8.17723 loss)
I1226 05:18:49.172489 61713 solver.cpp:218] Iteration 4200 (0.0915873 iter/s, 545.927s/50 iters), loss = 7.84221
I1226 05:18:49.172791 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 05:18:49.172821 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 05:18:49.172842 61713 solver.cpp:238]     Train net output #2: loss = 7.84221 (* 1 = 7.84221 loss)
I1226 05:18:49.182790 61713 sgd_solver.cpp:105] Iteration 4200, lr = 0.0001
I1226 05:27:32.085661 61713 solver.cpp:218] Iteration 4250 (0.0956184 iter/s, 522.912s/50 iters), loss = 8.21525
I1226 05:27:32.085889 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 05:27:32.085904 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 05:27:32.085922 61713 solver.cpp:238]     Train net output #2: loss = 8.21525 (* 1 = 8.21525 loss)
I1226 05:27:32.095751 61713 sgd_solver.cpp:105] Iteration 4250, lr = 0.0001
I1226 05:36:03.207558 61713 solver.cpp:331] Iteration 4300, Testing net (#0)
I1226 05:36:26.942490 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 05:36:26.942625 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 05:36:26.942646 61713 solver.cpp:400]     Test net output #2: loss = 8.22112 (* 1 = 8.22112 loss)
I1226 05:36:36.711654 61713 solver.cpp:218] Iteration 4300 (0.0918063 iter/s, 544.625s/50 iters), loss = 8.47112
I1226 05:36:36.711876 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 05:36:36.711902 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 05:36:36.711920 61713 solver.cpp:238]     Train net output #2: loss = 8.47112 (* 1 = 8.47112 loss)
I1226 05:36:36.722476 61713 sgd_solver.cpp:105] Iteration 4300, lr = 0.0001
I1226 05:45:17.870368 61713 solver.cpp:218] Iteration 4350 (0.0959402 iter/s, 521.158s/50 iters), loss = 8.46132
I1226 05:45:17.870661 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 05:45:17.870683 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 05:45:17.870702 61713 solver.cpp:238]     Train net output #2: loss = 8.46132 (* 1 = 8.46132 loss)
I1226 05:45:17.880875 61713 sgd_solver.cpp:105] Iteration 4350, lr = 0.0001
I1226 05:53:48.359433 61713 solver.cpp:331] Iteration 4400, Testing net (#0)
I1226 05:54:12.605077 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 05:54:12.605175 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 05:54:12.605192 61713 solver.cpp:400]     Test net output #2: loss = 8.25132 (* 1 = 8.25132 loss)
I1226 05:54:22.499163 61713 solver.cpp:218] Iteration 4400 (0.0918058 iter/s, 544.628s/50 iters), loss = 8.08632
I1226 05:54:22.499460 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 05:54:22.499481 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 05:54:22.499500 61713 solver.cpp:238]     Train net output #2: loss = 8.08632 (* 1 = 8.08632 loss)
I1226 05:54:22.510118 61713 sgd_solver.cpp:105] Iteration 4400, lr = 0.0001
I1226 06:03:00.810708 61713 solver.cpp:218] Iteration 4450 (0.0964672 iter/s, 518.311s/50 iters), loss = 8.59417
I1226 06:03:00.811005 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 06:03:00.811039 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 06:03:00.811071 61713 solver.cpp:238]     Train net output #2: loss = 8.59417 (* 1 = 8.59417 loss)
I1226 06:03:00.820955 61713 sgd_solver.cpp:105] Iteration 4450, lr = 0.0001
I1226 06:11:30.241291 61713 solver.cpp:331] Iteration 4500, Testing net (#0)
I1226 06:11:54.423526 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 06:11:54.423646 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 06:11:54.423669 61713 solver.cpp:400]     Test net output #2: loss = 8.18501 (* 1 = 8.18501 loss)
I1226 06:12:04.153676 61713 solver.cpp:218] Iteration 4500 (0.0920231 iter/s, 543.342s/50 iters), loss = 8.22501
I1226 06:12:04.154116 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 06:12:04.154150 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 06:12:04.154181 61713 solver.cpp:238]     Train net output #2: loss = 8.22501 (* 1 = 8.22501 loss)
I1226 06:12:04.164716 61713 sgd_solver.cpp:105] Iteration 4500, lr = 0.0001
I1226 06:20:43.626169 61713 solver.cpp:218] Iteration 4550 (0.0962516 iter/s, 519.472s/50 iters), loss = 8.47307
I1226 06:20:43.626462 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 06:20:43.626484 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 06:20:43.626503 61713 solver.cpp:238]     Train net output #2: loss = 8.47307 (* 1 = 8.47307 loss)
I1226 06:20:43.636430 61713 sgd_solver.cpp:105] Iteration 4550, lr = 0.0001
I1226 06:29:07.542918 61713 solver.cpp:331] Iteration 4600, Testing net (#0)
I1226 06:29:31.333326 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 06:29:31.333451 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 06:29:31.333472 61713 solver.cpp:400]     Test net output #2: loss = 8.30889 (* 1 = 8.30889 loss)
I1226 06:29:41.062589 61713 solver.cpp:218] Iteration 4600 (0.0930343 iter/s, 537.436s/50 iters), loss = 8.10389
I1226 06:29:41.062863 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 06:29:41.062880 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 06:29:41.062896 61713 solver.cpp:238]     Train net output #2: loss = 8.10389 (* 1 = 8.10389 loss)
I1226 06:29:41.072741 61713 sgd_solver.cpp:105] Iteration 4600, lr = 0.0001
I1226 06:38:14.370225 61713 solver.cpp:218] Iteration 4650 (0.0974076 iter/s, 513.307s/50 iters), loss = 7.97696
I1226 06:38:14.370568 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 06:38:14.370604 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 06:38:14.370637 61713 solver.cpp:238]     Train net output #2: loss = 7.97696 (* 1 = 7.97696 loss)
I1226 06:38:14.381238 61713 sgd_solver.cpp:105] Iteration 4650, lr = 0.0001
I1226 06:46:42.033742 61713 solver.cpp:331] Iteration 4700, Testing net (#0)
I1226 06:47:07.242951 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 06:47:07.243036 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 06:47:07.243054 61713 solver.cpp:400]     Test net output #2: loss = 8.13276 (* 1 = 8.13276 loss)
I1226 06:47:17.316654 61713 solver.cpp:218] Iteration 4700 (0.0920902 iter/s, 542.946s/50 iters), loss = 8.10776
I1226 06:47:17.316962 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 06:47:17.316998 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 06:47:17.317031 61713 solver.cpp:238]     Train net output #2: loss = 8.10776 (* 1 = 8.10776 loss)
I1226 06:47:17.327625 61713 sgd_solver.cpp:105] Iteration 4700, lr = 0.0001
I1226 06:56:07.093724 61713 solver.cpp:218] Iteration 4750 (0.0943795 iter/s, 529.776s/50 iters), loss = 8.22307
I1226 06:56:07.093946 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 06:56:07.093969 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 06:56:07.093989 61713 solver.cpp:238]     Train net output #2: loss = 8.22307 (* 1 = 8.22307 loss)
I1226 06:56:07.104202 61713 sgd_solver.cpp:105] Iteration 4750, lr = 0.0001
I1226 07:04:42.988543 61713 solver.cpp:331] Iteration 4800, Testing net (#0)
I1226 07:05:07.242558 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 07:05:07.242668 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 07:05:07.242686 61713 solver.cpp:400]     Test net output #2: loss = 8.28087 (* 1 = 8.28087 loss)
I1226 07:05:17.252236 61713 solver.cpp:218] Iteration 4800 (0.090883 iter/s, 550.158s/50 iters), loss = 8.09612
I1226 07:05:17.252476 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 07:05:17.252501 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 07:05:17.252518 61713 solver.cpp:238]     Train net output #2: loss = 8.09612 (* 1 = 8.09612 loss)
I1226 07:05:17.262470 61713 sgd_solver.cpp:105] Iteration 4800, lr = 0.0001
I1226 07:14:00.261250 61713 solver.cpp:218] Iteration 4850 (0.0956008 iter/s, 523.008s/50 iters), loss = 8.47696
I1226 07:14:00.267944 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 07:14:00.267958 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 07:14:00.267972 61713 solver.cpp:238]     Train net output #2: loss = 8.47696 (* 1 = 8.47696 loss)
I1226 07:14:00.278556 61713 sgd_solver.cpp:105] Iteration 4850, lr = 0.0001
I1226 07:22:31.955690 61713 solver.cpp:331] Iteration 4900, Testing net (#0)
I1226 07:22:56.151445 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 07:22:56.151541 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 07:22:56.151559 61713 solver.cpp:400]     Test net output #2: loss = 8.10533 (* 1 = 8.10533 loss)
I1226 07:23:06.124449 61713 solver.cpp:218] Iteration 4900 (0.0915992 iter/s, 545.856s/50 iters), loss = 8.20539
I1226 07:23:06.124742 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 07:23:06.124760 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 07:23:06.124778 61713 solver.cpp:238]     Train net output #2: loss = 8.20539 (* 1 = 8.20539 loss)
I1226 07:23:06.134660 61713 sgd_solver.cpp:105] Iteration 4900, lr = 0.0001
I1226 07:31:48.593812 61713 solver.cpp:218] Iteration 4950 (0.0956995 iter/s, 522.469s/50 iters), loss = 7.96721
I1226 07:31:48.594149 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 07:31:48.594182 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 07:31:48.594199 61713 solver.cpp:238]     Train net output #2: loss = 7.96721 (* 1 = 7.96721 loss)
I1226 07:31:48.604790 61713 sgd_solver.cpp:105] Iteration 4950, lr = 0.0001
I1226 07:40:20.211966 61713 solver.cpp:450] Snapshotting to binary proto file qnn_try1/QNN-train_iter_5000.caffemodel
I1226 07:40:22.794524 61713 sgd_solver.cpp:273] Snapshotting solver state to binary proto file qnn_try1/QNN-train_iter_5000.solverstate
I1226 07:40:24.925671 61713 solver.cpp:331] Iteration 5000, Testing net (#0)
I1226 07:40:49.217628 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 07:40:49.217753 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 07:40:49.217772 61713 solver.cpp:400]     Test net output #2: loss = 8.57743 (* 1 = 8.57743 loss)
I1226 07:40:59.052451 61713 solver.cpp:218] Iteration 5000 (0.0908334 iter/s, 550.458s/50 iters), loss = 8.44743
I1226 07:40:59.052683 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 07:40:59.052700 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 07:40:59.052717 61713 solver.cpp:238]     Train net output #2: loss = 8.44743 (* 1 = 8.44743 loss)
I1226 07:40:59.062642 61713 sgd_solver.cpp:105] Iteration 5000, lr = 0.0001
I1226 07:49:48.245982 61713 solver.cpp:218] Iteration 5050 (0.0944835 iter/s, 529.193s/50 iters), loss = 8.36352
I1226 07:49:48.246354 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 07:49:48.246373 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 07:49:48.246392 61713 solver.cpp:238]     Train net output #2: loss = 8.36352 (* 1 = 8.36352 loss)
I1226 07:49:48.256409 61713 sgd_solver.cpp:105] Iteration 5050, lr = 0.0001
I1226 07:58:23.361604 61713 solver.cpp:331] Iteration 5100, Testing net (#0)
I1226 07:58:47.702333 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 07:58:47.702450 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 07:58:47.702472 61713 solver.cpp:400]     Test net output #2: loss = 8.31468 (* 1 = 8.31468 loss)
I1226 07:58:57.717456 61713 solver.cpp:218] Iteration 5100 (0.0909966 iter/s, 549.471s/50 iters), loss = 8.23468
I1226 07:58:57.717720 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 07:58:57.717738 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 07:58:57.717756 61713 solver.cpp:238]     Train net output #2: loss = 8.23468 (* 1 = 8.23468 loss)
I1226 07:58:57.727798 61713 sgd_solver.cpp:105] Iteration 5100, lr = 0.0001
I1226 08:07:40.575709 61713 solver.cpp:218] Iteration 5150 (0.0956284 iter/s, 522.857s/50 iters), loss = 7.85582
I1226 08:07:40.591383 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 08:07:40.591398 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 08:07:40.591411 61713 solver.cpp:238]     Train net output #2: loss = 7.85582 (* 1 = 7.85582 loss)
I1226 08:07:40.602041 61713 sgd_solver.cpp:105] Iteration 5150, lr = 0.0001
I1226 08:16:08.938750 61713 solver.cpp:331] Iteration 5200, Testing net (#0)
I1226 08:16:33.103598 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 08:16:33.103662 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 08:16:33.103680 61713 solver.cpp:400]     Test net output #2: loss = 8.27083 (* 1 = 8.27083 loss)
I1226 08:16:42.925194 61713 solver.cpp:218] Iteration 5200 (0.0921943 iter/s, 542.333s/50 iters), loss = 8.23082
I1226 08:16:42.925432 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 08:16:42.925467 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 08:16:42.925499 61713 solver.cpp:238]     Train net output #2: loss = 8.23082 (* 1 = 8.23082 loss)
I1226 08:16:42.936117 61713 sgd_solver.cpp:105] Iteration 5200, lr = 0.0001
I1226 08:25:20.084316 61713 solver.cpp:218] Iteration 5250 (0.0966823 iter/s, 517.158s/50 iters), loss = 8.47112
I1226 08:25:20.084576 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 08:25:20.084610 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 08:25:20.084645 61713 solver.cpp:238]     Train net output #2: loss = 8.47112 (* 1 = 8.47112 loss)
I1226 08:25:20.095201 61713 sgd_solver.cpp:105] Iteration 5250, lr = 0.0001
I1226 08:33:49.159451 61713 solver.cpp:331] Iteration 5300, Testing net (#0)
I1226 08:34:13.362298 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 08:34:13.362429 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 08:34:13.362453 61713 solver.cpp:400]     Test net output #2: loss = 8.26044 (* 1 = 8.26044 loss)
I1226 08:34:23.381778 61713 solver.cpp:218] Iteration 5300 (0.0920307 iter/s, 543.297s/50 iters), loss = 7.98872
I1226 08:34:23.381973 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 08:34:23.381989 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 08:34:23.382005 61713 solver.cpp:238]     Train net output #2: loss = 7.98872 (* 1 = 7.98872 loss)
I1226 08:34:23.392042 61713 sgd_solver.cpp:105] Iteration 5300, lr = 0.0001
I1226 08:43:06.197314 61713 solver.cpp:218] Iteration 5350 (0.0956361 iter/s, 522.815s/50 iters), loss = 7.85389
I1226 08:43:06.197571 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 08:43:06.197587 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 08:43:06.197602 61713 solver.cpp:238]     Train net output #2: loss = 7.85389 (* 1 = 7.85389 loss)
I1226 08:43:06.207448 61713 sgd_solver.cpp:105] Iteration 5350, lr = 0.0001
I1226 08:51:33.257483 61713 solver.cpp:331] Iteration 5400, Testing net (#0)
I1226 08:51:57.446233 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 08:51:57.446290 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 08:51:57.446307 61713 solver.cpp:400]     Test net output #2: loss = 8.37917 (* 1 = 8.37917 loss)
I1226 08:52:07.326042 61713 solver.cpp:218] Iteration 5400 (0.0923996 iter/s, 541.128s/50 iters), loss = 8.46917
I1226 08:52:07.326153 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 08:52:07.326169 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 08:52:07.326185 61713 solver.cpp:238]     Train net output #2: loss = 8.46917 (* 1 = 8.46917 loss)
I1226 08:52:07.336253 61713 sgd_solver.cpp:105] Iteration 5400, lr = 0.0001
I1226 09:00:42.818091 61713 solver.cpp:218] Iteration 5450 (0.0969949 iter/s, 515.491s/50 iters), loss = 8.49044
I1226 09:00:42.818457 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 09:00:42.818491 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 09:00:42.818516 61713 solver.cpp:238]     Train net output #2: loss = 8.49044 (* 1 = 8.49044 loss)
I1226 09:00:42.829064 61713 sgd_solver.cpp:105] Iteration 5450, lr = 0.0001
I1226 09:09:30.360906 61713 solver.cpp:331] Iteration 5500, Testing net (#0)
I1226 09:09:54.612432 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 09:09:54.612571 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 09:09:54.612589 61713 solver.cpp:400]     Test net output #2: loss = 8.52501 (* 1 = 8.52501 loss)
I1226 09:10:04.434624 61713 solver.cpp:218] Iteration 5500 (0.0890288 iter/s, 561.616s/50 iters), loss = 7.60001
I1226 09:10:04.434895 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 09:10:04.434909 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 09:10:04.434927 61713 solver.cpp:238]     Train net output #2: loss = 7.60001 (* 1 = 7.60001 loss)
I1226 09:10:04.444769 61713 sgd_solver.cpp:105] Iteration 5500, lr = 0.0001
I1226 09:18:41.510738 61713 solver.cpp:218] Iteration 5550 (0.0966978 iter/s, 517.075s/50 iters), loss = 8.45341
I1226 09:18:41.511013 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 09:18:41.511039 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 09:18:41.511054 61713 solver.cpp:238]     Train net output #2: loss = 8.45341 (* 1 = 8.45341 loss)
I1226 09:18:41.521311 61713 sgd_solver.cpp:105] Iteration 5550, lr = 0.0001
I1226 09:27:16.904899 61713 solver.cpp:331] Iteration 5600, Testing net (#0)
I1226 09:27:41.224535 61713 solver.cpp:400]     Test net output #0: acc_top1 = 0
I1226 09:27:41.224607 61713 solver.cpp:400]     Test net output #1: acc_top5 = 0
I1226 09:27:41.224625 61713 solver.cpp:400]     Test net output #2: loss = 8.24501 (* 1 = 8.24501 loss)
I1226 09:27:51.092470 61713 solver.cpp:218] Iteration 5600 (0.0909784 iter/s, 549.581s/50 iters), loss = 7.97333
I1226 09:27:51.092782 61713 solver.cpp:238]     Train net output #0: acc_top1 = 0
I1226 09:27:51.092818 61713 solver.cpp:238]     Train net output #1: acc_top5 = 0
I1226 09:27:51.092851 61713 solver.cpp:238]     Train net output #2: loss = 7.97333 (* 1 = 7.97333 loss)
I1226 09:27:51.103432 61713 sgd_solver.cpp:105] Iteration 5600, lr = 0.0001
  C-c C-cI1226 09:33:41.009624 61713 solver.cpp:450] Snapshotting to binary proto file qnn_try1/QNN-train_iter_5634.caffemodel
I1226 09:33:45.135432 61713 sgd_solver.cpp:273] Snapshotting solver state to binary proto file qnn_try1/QNN-train_iter_5634.solverstate
I1226 09:33:45.595033 61713 solver.cpp:295] Optimization stopped early.
I1226 09:33:45.595129 61713 caffe.cpp:259] Optimization Done.
ydwu@aries:~/work/QNN-Caffe/caffe$ 